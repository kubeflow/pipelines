{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FfDL Kubeflow Pipeline Notebook demo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the necessary environment variables and install the KubeFlow Pipeline SDK\n",
    "We assume this notebook kernel has access to Python's site-packages and is in Python3.\n",
    "\n",
    "**Please fill in the below environment variables with you own settings.**\n",
    "\n",
    "- **EXPERIMENT_NAME**: A unique experiment name that will be created for this notebook demo.\n",
    "- **KFP_PACKAGE**: The latest release of kubeflow pipeline platform library.\n",
    "- **KUBEFLOW_PIPELINE_LINK**: The link to access the KubeFlow pipeline API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = 'jupyter-demo'\n",
    "KFP_PACKAGE = 'https://storage.googleapis.com/ml-pipeline/release/0.1.6/kfp.tar.gz'\n",
    "KUBEFLOW_PIPELINE_LINK = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then, define the GitHub credentials manaully or load it from the credentials folder\n",
    "- **config_file_url**: GitHub raw content link to the pipeline credentials file\n",
    "- **github_token**: GitHub Token that can access your private repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read('credentials/github-creds.ini')\n",
    "config_file_url = config['CREDENTIALS']['config_file_url']\n",
    "github_token = config['CREDENTIALS']['github_token']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the necessary python packages\n",
    "\n",
    "Note: Please change pip3 to the package manager that's used for this Notebook Kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install ai_pipeline_params --upgrade\n",
    "!pip3 install $KFP_PACKAGE --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the KubeFlow Pipeline library and define the client and experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import compiler\n",
    "import kfp.dsl as dsl\n",
    "import kfp.notebook\n",
    "import kfp.gcp as gcp\n",
    "\n",
    "client = kfp.Client(KUBEFLOW_PIPELINE_LINK)\n",
    "\n",
    "# Uncomment the below line if you want to create an experiment, \n",
    "# else we will assume the EXPERIMENT_NAME is already exist.\n",
    "\n",
    "# exp = client.create_experiment(name=EXPERIMENT_NAME)\n",
    "\n",
    "exp = client.get_experiment(experiment_name=EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define pipeline tasks using the kfp library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp.dsl as dsl\n",
    "import ai_pipeline_params as params\n",
    "\n",
    "# generate default secret name\n",
    "secret_name = 'kfp-creds'\n",
    "\n",
    "\n",
    "# create pipeline\n",
    "@dsl.pipeline(\n",
    "  name='FfDL pipeline',\n",
    "  description='A pipeline for machine learning workflow using Fabric for Deep Learning and Seldon.'\n",
    ")\n",
    "def ffdlPipeline(\n",
    "    GITHUB_TOKEN=dsl.PipelineParam(name='github-token'),\n",
    "    CONFIG_FILE_URL=dsl.PipelineParam(name='config-file-url'),\n",
    "    model_def_file_path=dsl.PipelineParam(name='model-def-file-path',\n",
    "                                          value='gender-classification.zip'),\n",
    "    manifest_file_path=dsl.PipelineParam(name='manifest-file-path',\n",
    "                                         value='manifest.yml'),\n",
    "    model_deployment_name=dsl.PipelineParam(name='model-deployment-name',\n",
    "                                            value='gender-classifier'),\n",
    "    model_class_name=dsl.PipelineParam(name='model-class-name',\n",
    "                                       value='ThreeLayerCNN'),\n",
    "    model_class_file=dsl.PipelineParam(name='model-class-file',\n",
    "                                       value='gender_classification.py')\n",
    "):\n",
    "    \"\"\"A pipeline for end to end machine learning workflow.\"\"\"\n",
    "    config_op = dsl.ContainerOp(\n",
    "        name=\"config\",\n",
    "        image=\"aipipeline/wml-config\",\n",
    "        command=['python3'],\n",
    "        arguments=['/app/config.py',\n",
    "                   '--token', GITHUB_TOKEN,\n",
    "                   '--url', CONFIG_FILE_URL,\n",
    "                   '--name', secret_name],\n",
    "        file_outputs={'secret-name': '/tmp/' + secret_name}\n",
    "    )\n",
    "\n",
    "    train = dsl.ContainerOp(\n",
    "     name='train',\n",
    "     image='aipipeline/ffdl-train:0.6',\n",
    "     command=['sh', '-c'],\n",
    "     arguments=['echo %s > /tmp/logs.txt; python -u train.py --model_def_file_path %s --manifest_file_path %s;'\n",
    "                % (config_op.output, model_def_file_path, manifest_file_path)],\n",
    "     file_outputs={'output': '/tmp/training_id.txt'}).apply(params.use_ai_pipeline_params(secret_name))\n",
    "\n",
    "    serve = dsl.ContainerOp(\n",
    "     name='serve',\n",
    "     image='aipipeline/ffdl-serve:0.11',\n",
    "     command=['sh', '-c'],\n",
    "     arguments=['python -u serve.py --model_id %s --deployment_name %s --model_class_name %s --model_class_file %s;'\n",
    "                % (train.output, model_deployment_name, model_class_name, model_class_file)],\n",
    "     file_outputs={'output': '/tmp/deployment_result.txt'}).apply(params.use_ai_pipeline_params(secret_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below are the default parameters for the above pipeline, \n",
    "# you can customize these parameters for each pipeline run.\n",
    "\n",
    "parameters={'config-file-url': config_file_url,\n",
    "            'github-token': github_token,\n",
    "            'model-def-file-path': 'gender-classification.zip',\n",
    "            'manifest-file-path': 'manifest.yml',\n",
    "            'model-deployment-name': 'gender-classifier',\n",
    "            'model-class-name': 'ThreeLayerCNN',\n",
    "            'model-class-file': 'gender_classification.py'}\n",
    "\n",
    "\n",
    "compiler.Compiler().compile(ffdlPipeline,  'ffdl-pipeline.tar.gz')\n",
    "\n",
    "run = client.run_pipeline(exp.id, 'ffdl-pipeline', 'ffdl-pipeline.tar.gz', \n",
    "                          params=parameters)\n",
    "\n",
    "print('The above run link is assuming you ran this cell on JupyterHub that is deployed on the same cluster. ' +\n",
    "      'The actual run link is ' + KUBEFLOW_PIPELINE_LINK + '/#/runs/details/' + run.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
