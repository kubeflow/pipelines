apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: runtime-resource-request-pipeline-
  annotations:
    pipelines.kubeflow.org/kfp_sdk_version: 1.6.3
    pipelines.kubeflow.org/pipeline_compilation_time: '2021-06-04T23:19:16.577527'
    pipelines.kubeflow.org/pipeline_spec: '{"description": "An example on how to make
      resource requests at runtime.", "inputs": [{"default": "11234567", "name": "n",
      "optional": true, "type": "Integer"}, {"default": "", "name": "pipeline-output-directory"},
      {"default": "Runtime resource request pipeline", "name": "pipeline-name"}],
      "name": "Runtime resource request pipeline"}'
    pipelines.kubeflow.org/v2_pipeline: "true"
  labels:
    pipelines.kubeflow.org/v2_pipeline: "true"
    pipelines.kubeflow.org/kfp_sdk_version: 1.6.3
spec:
  entrypoint: runtime-resource-request-pipeline
  templates:
  - name: generate-resouce-request
    container:
      args:
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - |
        def generate_resouce_request():
            '''Returns the memory and cpu request'''
            from collections import namedtuple

            resouce_output = namedtuple('output', ['memory', 'cpu'])
            return resouce_output('500Mi', '200m')

        def _serialize_str(str_value: str) -> str:
            if not isinstance(str_value, str):
                raise TypeError('Value "{}" has type "{}" instead of str.'.format(str(str_value), str(type(str_value))))
            return str_value

        import argparse
        _parser = argparse.ArgumentParser(prog='Generate resouce request', description='Returns the memory and cpu request')
        _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=2)
        _parsed_args = vars(_parser.parse_args())
        _output_files = _parsed_args.pop("_output_paths", [])

        _outputs = generate_resouce_request(**_parsed_args)

        _output_serializers = [
            _serialize_str,
            _serialize_str,

        ]

        import os
        for idx, output_file in enumerate(_output_files):
            try:
                os.makedirs(os.path.dirname(output_file))
            except OSError:
                pass
            with open(output_file, 'w') as f:
                f.write(_output_serializers[idx](_outputs[idx]))
      - '----output-paths'
      - '{{$.outputs.parameters[''memory''].output_file}}'
      - '{{$.outputs.parameters[''cpu''].output_file}}'
      command: [/kfp-launcher/launch, --mlmd_server_address, $(METADATA_GRPC_SERVICE_HOST),
        --mlmd_server_port, $(METADATA_GRPC_SERVICE_PORT), --runtime_info_json, $(KFP_V2_RUNTIME_INFO),
        --container_image, $(KFP_V2_IMAGE), --task_name, generate-resouce-request,
        --pipeline_name, '{{inputs.parameters.pipeline-name}}', --pipeline_run_id,
        $(WORKFLOW_ID), --pipeline_task_id, $(KFP_POD_NAME), --pipeline_root, '{{inputs.parameters.pipeline-output-directory}}']
      env:
      - name: KFP_POD_NAME
        valueFrom:
          fieldRef: {fieldPath: metadata.name}
      - name: KFP_NAMESPACE
        valueFrom:
          fieldRef: {fieldPath: metadata.namespace}
      - name: WORKFLOW_ID
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''workflows.argoproj.io/workflow'']'}
      - {name: KFP_V2_IMAGE, value: 'python:3.7'}
      - {name: KFP_V2_RUNTIME_INFO, value: '{"inputParameters": {}, "inputArtifacts":
          {}, "outputParameters": {"cpu": {"type": "STRING", "path": "/tmp/outputs/cpu/data"},
          "memory": {"type": "STRING", "path": "/tmp/outputs/memory/data"}}, "outputArtifacts":
          {}}'}
      envFrom:
      - configMapRef: {name: metadata-grpc-configmap, optional: true}
      image: python:3.7
      volumeMounts:
      - {mountPath: /kfp-launcher, name: kfp-launcher}
    inputs:
      parameters:
      - {name: pipeline-name}
      - {name: pipeline-output-directory}
    outputs:
      artifacts:
      - {name: generate-resouce-request-cpu, path: /tmp/outputs/cpu/data}
      - {name: generate-resouce-request-memory, path: /tmp/outputs/memory/data}
    metadata:
      annotations:
        pipelines.kubeflow.org/v2_component: "true"
        pipelines.kubeflow.org/component_ref: '{}'
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.6.3
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/v2_component: "true"
    initContainers:
    - command: [/bin/mount_launcher.sh]
      image: gcr.io/ml-pipeline/kfp-launcher:1.6.3
      name: kfp-launcher
      mirrorVolumeMounts: true
    volumes:
    - {name: kfp-launcher}
  - name: runtime-resource-request-pipeline
    inputs:
      parameters:
      - name: "n"
      - {name: pipeline-name}
      - {name: pipeline-output-directory}
    dag:
      tasks:
      - name: generate-resouce-request
        template: generate-resouce-request
        arguments:
          parameters:
          - {name: pipeline-name, value: '{{inputs.parameters.pipeline-name}}'}
          - {name: pipeline-output-directory, value: '{{inputs.parameters.pipeline-output-directory}}'}
      - name: training-op
        template: training-op
        dependencies: [generate-resouce-request]
        arguments:
          parameters:
          - name: "n"
            value: '{{inputs.parameters.n}}'
          - {name: generate-resouce-request-cpu, value: '{{tasks.generate-resouce-request.outputs.parameters.generate-resouce-request-cpu}}'}
          - {name: generate-resouce-request-memory, value: '{{tasks.generate-resouce-request.outputs.parameters.generate-resouce-request-memory}}'}
  - name: training-op
    container:
      args:
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - |
        def training_op(n):
            # quickly allocate a lot of memory to verify memory is enough
            a = [i for i in range(n)]
            return len(a)

        def _serialize_int(int_value: int) -> str:
            if isinstance(int_value, str):
                return int_value
            if not isinstance(int_value, int):
                raise TypeError('Value "{}" has type "{}" instead of int.'.format(str(int_value), str(type(int_value))))
            return str(int_value)

        import argparse
        _parser = argparse.ArgumentParser(prog='Training op', description='')
        _parser.add_argument("--n", dest="n", type=int, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=1)
        _parsed_args = vars(_parser.parse_args())
        _output_files = _parsed_args.pop("_output_paths", [])

        _outputs = training_op(**_parsed_args)

        _outputs = [_outputs]

        _output_serializers = [
            _serialize_int,

        ]

        import os
        for idx, output_file in enumerate(_output_files):
            try:
                os.makedirs(os.path.dirname(output_file))
            except OSError:
                pass
            with open(output_file, 'w') as f:
                f.write(_output_serializers[idx](_outputs[idx]))
      - --n
      - '{{$.inputs.parameters[''n'']}}'
      - '----output-paths'
      - '{{$.outputs.parameters[''Output''].output_file}}'
      command: [/kfp-launcher/launch, --mlmd_server_address, $(METADATA_GRPC_SERVICE_HOST),
        --mlmd_server_port, $(METADATA_GRPC_SERVICE_PORT), --runtime_info_json, $(KFP_V2_RUNTIME_INFO),
        --container_image, $(KFP_V2_IMAGE), --task_name, training-op, --pipeline_name,
        '{{inputs.parameters.pipeline-name}}', --pipeline_run_id, $(WORKFLOW_ID),
        --pipeline_task_id, $(KFP_POD_NAME), --pipeline_root, '{{inputs.parameters.pipeline-output-directory}}']
      env:
      - name: KFP_POD_NAME
        valueFrom:
          fieldRef: {fieldPath: metadata.name}
      - name: KFP_NAMESPACE
        valueFrom:
          fieldRef: {fieldPath: metadata.namespace}
      - name: WORKFLOW_ID
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''workflows.argoproj.io/workflow'']'}
      - {name: KFP_V2_IMAGE, value: 'python:3.7'}
      - {name: KFP_V2_RUNTIME_INFO, value: '{"inputParameters": {"n": {"type": "INT",
          "value": "BEGIN-KFP-PARAM[{{inputs.parameters.n}}]END-KFP-PARAM"}}, "inputArtifacts":
          {}, "outputParameters": {"Output": {"type": "INT", "path": "/tmp/outputs/Output/data"}},
          "outputArtifacts": {}}'}
      envFrom:
      - configMapRef: {name: metadata-grpc-configmap, optional: true}
      image: python:3.7
      resources:
        requests: {cpu: 200m}
      volumeMounts:
      - {mountPath: /kfp-launcher, name: kfp-launcher}
    inputs:
      parameters:
      - name: "n"
      - {name: pipeline-name}
      - {name: pipeline-output-directory}
    outputs:
      artifacts:
      - {name: training-op-Output, path: /tmp/outputs/Output/data}
    metadata:
      annotations:
        pipelines.kubeflow.org/v2_component: "true"
        pipelines.kubeflow.org/component_ref: '{}'
        pipelines.kubeflow.org/arguments.parameters: '{"n": "{{inputs.parameters.n}}"}'
        pipelines.kubeflow.org/max_cache_staleness: P0D
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.6.3
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/v2_component: "true"
    initContainers:
    - command: [/bin/mount_launcher.sh]
      image: gcr.io/ml-pipeline/kfp-launcher:1.6.3
      name: kfp-launcher
      mirrorVolumeMounts: true
    volumes:
    - {name: kfp-launcher}
    podSpecPatch: '{"containers": [{"name": "main", "resources": {"limits": {"memory":
      "{{inputs.parameters.generate-resouce-request-memory}}", "cpu": "{{inputs.parameters.generate-resouce-request-cpu}}"}}}]}'
  arguments:
    parameters:
    - name: "n"
      value: '11234567'
    - {name: pipeline-output-directory, value: ''}
    - {name: pipeline-name, value: Runtime resource request pipeline}
  serviceAccountName: pipeline-runner
