{
  "pipelineSpec": {
    "deploymentSpec": {
      "executors": {
        "exec-chicago-taxi-trips-dataset": {
          "container": {
            "command": [
              "sh",
              "-c",
              "set -e -x -o pipefail\noutput_path=\"$0\"\nselect=\"$1\"\nwhere=\"$2\"\nlimit=\"$3\"\nformat=\"$4\"\nmkdir -p \"$(dirname \"$output_path\")\"\ncurl --get 'https://data.cityofchicago.org/resource/wrvz-psew.'\"${format}\" \\\n    --data-urlencode '$limit='\"${limit}\" \\\n    --data-urlencode '$where='\"${where}\" \\\n    --data-urlencode '$select='\"${select}\" \\\n    | tr -d '\"' > \"$output_path\"  # Removing unneeded quotes around all numbers\n",
              "{{$.outputs.artifacts['Table'].path}}",
              "{{$.inputs.parameters['Select']}}",
              "{{$.inputs.parameters['Where']}}",
              "{{$.inputs.parameters['Limit']}}",
              "{{$.inputs.parameters['Format']}}"
            ],
            "image": "byrnedo/alpine-curl@sha256:548379d0a4a0c08b9e55d9d87a592b7d35d9ab3037f4936f5ccd09d0b625a342"
          }
        },
        "exec-xgboost-train-2": {
          "container": {
            "image": "python:3.7",
            "command": [
              "sh",
              "-c",
              "(PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'xgboost==1.1.1' 'pandas==1.0.5' 'pyarrow==0.17.1' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'xgboost==1.1.1' 'pandas==1.0.5' 'pyarrow==0.17.1' --user) && \"$0\" \"$@\"",
              "python3",
              "-u",
              "-c",
              "def _make_parent_dirs_and_return_path(file_path: str):\n    import os\n    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n    return file_path\n\ndef xgboost_train(\n    training_data_path,\n    model_path,\n    model_config_path,\n    label_column_name,\n\n    starting_model_path = None,\n\n    num_iterations = 10,\n    booster_params = None,\n\n    # Booster parameters\n    objective = 'reg:squarederror',\n    booster = 'gbtree',\n    learning_rate = 0.3,\n    min_split_loss = 0,\n    max_depth = 6,\n):\n    '''Train an XGBoost model.\n\n    Args:\n        training_data_path: Path for the training data in Apache Parquet format.\n        model_path: Output path for the trained model in binary XGBoost format.\n        model_config_path: Output path for the internal parameter configuration of Booster as a JSON string.\n        starting_model_path: Path for the existing trained model to start from.\n        label_column_name: Name of the column containing the label data.\n        num_boost_rounds: Number of boosting iterations.\n        booster_params: Parameters for the booster. See https://xgboost.readthedocs.io/en/latest/parameter.html\n        objective: The learning task and the corresponding learning objective.\n            See https://xgboost.readthedocs.io/en/latest/parameter.html#learning-task-parameters\n            The most common values are:\n            \"reg:squarederror\" - Regression with squared loss (default).\n            \"reg:logistic\" - Logistic regression.\n            \"binary:logistic\" - Logistic regression for binary classification, output probability.\n            \"binary:logitraw\" - Logistic regression for binary classification, output score before logistic transformation\n            \"rank:pairwise\" - Use LambdaMART to perform pairwise ranking where the pairwise loss is minimized\n            \"rank:ndcg\" - Use LambdaMART to perform list-wise ranking where Normalized Discounted Cumulative Gain (NDCG) is maximized\n\n    Annotations:\n        author: Alexey Volkov <alexey.volkov@ark-kun.com>\n    '''\n    import pandas\n    import xgboost\n\n    # Loading data\n    df = pandas.read_parquet(training_data_path)\n    training_data = xgboost.DMatrix(\n        data=df.drop(columns=[label_column_name]),\n        label=df[[label_column_name]],\n    )\n    # Training\n    booster_params = booster_params or {}\n    booster_params.setdefault('objective', objective)\n    booster_params.setdefault('booster', booster)\n    booster_params.setdefault('learning_rate', learning_rate)\n    booster_params.setdefault('min_split_loss', min_split_loss)\n    booster_params.setdefault('max_depth', max_depth)\n\n    starting_model = None\n    if starting_model_path:\n        starting_model = xgboost.Booster(model_file=starting_model_path)\n\n    model = xgboost.train(\n        params=booster_params,\n        dtrain=training_data,\n        num_boost_round=num_iterations,\n        xgb_model=starting_model\n    )\n\n    # Saving the model in binary format\n    model.save_model(model_path)\n\n    model_config_str = model.save_config()\n    with open(model_config_path, 'w') as model_config_file:\n        model_config_file.write(model_config_str)\n\nimport json\nimport argparse\n_parser = argparse.ArgumentParser(prog='Xgboost train', description='Train an XGBoost model.\\n\\n    Args:\\n        training_data_path: Path for the training data in Apache Parquet format.\\n        model_path: Output path for the trained model in binary XGBoost format.\\n        model_config_path: Output path for the internal parameter configuration of Booster as a JSON string.\\n        starting_model_path: Path for the existing trained model to start from.\\n        label_column_name: Name of the column containing the label data.\\n        num_boost_rounds: Number of boosting iterations.\\n        booster_params: Parameters for the booster. See https://xgboost.readthedocs.io/en/latest/parameter.html\\n        objective: The learning task and the corresponding learning objective.\\n            See https://xgboost.readthedocs.io/en/latest/parameter.html#learning-task-parameters\\n            The most common values are:\\n            \"reg:squarederror\" - Regression with squared loss (default).\\n            \"reg:logistic\" - Logistic regression.\\n            \"binary:logistic\" - Logistic regression for binary classification, output probability.\\n            \"binary:logitraw\" - Logistic regression for binary classification, output score before logistic transformation\\n            \"rank:pairwise\" - Use LambdaMART to perform pairwise ranking where the pairwise loss is minimized\\n            \"rank:ndcg\" - Use LambdaMART to perform list-wise ranking where Normalized Discounted Cumulative Gain (NDCG) is maximized\\n\\n    Annotations:\\n        author: Alexey Volkov <alexey.volkov@ark-kun.com>')\n_parser.add_argument(\"--training-data\", dest=\"training_data_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--label-column-name\", dest=\"label_column_name\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--starting-model\", dest=\"starting_model_path\", type=str, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--num-iterations\", dest=\"num_iterations\", type=int, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--booster-params\", dest=\"booster_params\", type=json.loads, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--objective\", dest=\"objective\", type=str, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--booster\", dest=\"booster\", type=str, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--learning-rate\", dest=\"learning_rate\", type=float, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--min-split-loss\", dest=\"min_split_loss\", type=float, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--max-depth\", dest=\"max_depth\", type=int, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--model\", dest=\"model_path\", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--model-config\", dest=\"model_config_path\", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\n_outputs = xgboost_train(**_parsed_args)\n"
            ],
            "args": [
              "--training-data",
              "{{$.inputs.artifacts['training_data'].path}}",
              "--label-column-name",
              "{{$.inputs.parameters['label_column_name']}}",
              "--num-iterations",
              "{{$.inputs.parameters['num_iterations']}}",
              "--objective",
              "{{$.inputs.parameters['objective']}}",
              "--model",
              "{{$.outputs.artifacts['model'].path}}",
              "--model-config",
              "{{$.outputs.artifacts['model_config'].path}}"
            ]
          }
        },
        "exec-xgboost-predict-2": {
          "container": {
            "image": "python:3.7",
            "command": [
              "sh",
              "-c",
              "(PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'xgboost==1.1.1' 'pandas==1.0.5' 'pyarrow==0.17.1' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'xgboost==1.1.1' 'pandas==1.0.5' 'pyarrow==0.17.1' --user) && \"$0\" \"$@\"",
              "python3",
              "-u",
              "-c",
              "def _make_parent_dirs_and_return_path(file_path: str):\n    import os\n    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n    return file_path\n\ndef xgboost_predict(\n    data_path,\n    model_path,\n    predictions_path,\n    label_column_name = None,\n):\n    '''Make predictions using a trained XGBoost model.\n\n    Args:\n        data_path: Path for the feature data in Apache Parquet format.\n        model_path: Path for the trained model in binary XGBoost format.\n        predictions_path: Output path for the predictions.\n        label_column_name: Optional. Name of the column containing the label data that is excluded during the prediction.\n\n    Annotations:\n        author: Alexey Volkov <alexey.volkov@ark-kun.com>\n    '''\n    from pathlib import Path\n\n    import numpy\n    import pandas\n    import xgboost\n\n    # Loading data\n    df = pandas.read_parquet(data_path)\n    if label_column_name:\n        df = df.drop(columns=[label_column_name])\n\n    evaluation_data = xgboost.DMatrix(\n        data=df,\n    )\n\n    # Training\n    model = xgboost.Booster(model_file=model_path)\n\n    predictions = model.predict(evaluation_data)\n\n    Path(predictions_path).parent.mkdir(parents=True, exist_ok=True)\n    numpy.savetxt(predictions_path, predictions)\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Xgboost predict', description='Make predictions using a trained XGBoost model.\\n\\n    Args:\\n        data_path: Path for the feature data in Apache Parquet format.\\n        model_path: Path for the trained model in binary XGBoost format.\\n        predictions_path: Output path for the predictions.\\n        label_column_name: Optional. Name of the column containing the label data that is excluded during the prediction.\\n\\n    Annotations:\\n        author: Alexey Volkov <alexey.volkov@ark-kun.com>')\n_parser.add_argument(\"--data\", dest=\"data_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--model\", dest=\"model_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--label-column-name\", dest=\"label_column_name\", type=str, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--predictions\", dest=\"predictions_path\", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\n_outputs = xgboost_predict(**_parsed_args)\n"
            ],
            "args": [
              "--data",
              "{{$.inputs.artifacts['data'].path}}",
              "--model",
              "{{$.inputs.artifacts['model'].path}}",
              "--label-column-name",
              "{{$.inputs.parameters['label_column_name']}}",
              "--predictions",
              "{{$.outputs.parameters['predictions'].output_file}}"
            ]
          }
        },
        "exec-xgboost-predict-3": {
          "container": {
            "args": [
              "--data",
              "{{$.inputs.artifacts['data'].path}}",
              "--model",
              "{{$.inputs.artifacts['model'].path}}",
              "--label-column-name",
              "{{$.inputs.parameters['label_column_name']}}",
              "--predictions",
              "{{$.outputs.parameters['predictions'].output_file}}"
            ],
            "image": "python:3.7",
            "command": [
              "sh",
              "-c",
              "(PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'xgboost==1.1.1' 'pandas==1.0.5' 'pyarrow==0.17.1' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'xgboost==1.1.1' 'pandas==1.0.5' 'pyarrow==0.17.1' --user) && \"$0\" \"$@\"",
              "python3",
              "-u",
              "-c",
              "def _make_parent_dirs_and_return_path(file_path: str):\n    import os\n    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n    return file_path\n\ndef xgboost_predict(\n    data_path,\n    model_path,\n    predictions_path,\n    label_column_name = None,\n):\n    '''Make predictions using a trained XGBoost model.\n\n    Args:\n        data_path: Path for the feature data in Apache Parquet format.\n        model_path: Path for the trained model in binary XGBoost format.\n        predictions_path: Output path for the predictions.\n        label_column_name: Optional. Name of the column containing the label data that is excluded during the prediction.\n\n    Annotations:\n        author: Alexey Volkov <alexey.volkov@ark-kun.com>\n    '''\n    from pathlib import Path\n\n    import numpy\n    import pandas\n    import xgboost\n\n    # Loading data\n    df = pandas.read_parquet(data_path)\n    if label_column_name:\n        df = df.drop(columns=[label_column_name])\n\n    evaluation_data = xgboost.DMatrix(\n        data=df,\n    )\n\n    # Training\n    model = xgboost.Booster(model_file=model_path)\n\n    predictions = model.predict(evaluation_data)\n\n    Path(predictions_path).parent.mkdir(parents=True, exist_ok=True)\n    numpy.savetxt(predictions_path, predictions)\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Xgboost predict', description='Make predictions using a trained XGBoost model.\\n\\n    Args:\\n        data_path: Path for the feature data in Apache Parquet format.\\n        model_path: Path for the trained model in binary XGBoost format.\\n        predictions_path: Output path for the predictions.\\n        label_column_name: Optional. Name of the column containing the label data that is excluded during the prediction.\\n\\n    Annotations:\\n        author: Alexey Volkov <alexey.volkov@ark-kun.com>')\n_parser.add_argument(\"--data\", dest=\"data_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--model\", dest=\"model_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--label-column-name\", dest=\"label_column_name\", type=str, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--predictions\", dest=\"predictions_path\", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\n_outputs = xgboost_predict(**_parsed_args)\n"
            ]
          }
        },
        "exec-xgboost-predict-4": {
          "container": {
            "args": [
              "--data",
              "{{$.inputs.artifacts['data'].path}}",
              "--model",
              "{{$.inputs.artifacts['model'].path}}",
              "--label-column",
              "{{$.inputs.parameters['label_column']}}",
              "--predictions",
              "{{$.outputs.parameters['predictions'].output_file}}"
            ],
            "image": "python:3.7",
            "command": [
              "sh",
              "-c",
              "(PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'xgboost==1.1.1' 'pandas==1.0.5' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'xgboost==1.1.1' 'pandas==1.0.5' --user) && \"$0\" \"$@\"",
              "python3",
              "-u",
              "-c",
              "def _make_parent_dirs_and_return_path(file_path: str):\n    import os\n    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n    return file_path\n\ndef xgboost_predict(\n    data_path,  # Also supports LibSVM\n    model_path,\n    predictions_path,\n    label_column = None,\n):\n    '''Make predictions using a trained XGBoost model.\n\n    Args:\n        data_path: Path for the feature data in CSV format.\n        model_path: Path for the trained model in binary XGBoost format.\n        predictions_path: Output path for the predictions.\n        label_column: Column containing the label data.\n\n    Annotations:\n        author: Alexey Volkov <alexey.volkov@ark-kun.com>\n    '''\n    from pathlib import Path\n\n    import numpy\n    import pandas\n    import xgboost\n\n    df = pandas.read_csv(\n        data_path,\n    )\n\n    if label_column is not None:\n        df = df.drop(columns=[df.columns[label_column]])\n\n    testing_data = xgboost.DMatrix(\n        data=df,\n    )\n\n    model = xgboost.Booster(model_file=model_path)\n\n    predictions = model.predict(testing_data)\n\n    Path(predictions_path).parent.mkdir(parents=True, exist_ok=True)\n    numpy.savetxt(predictions_path, predictions)\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Xgboost predict', description='Make predictions using a trained XGBoost model.\\n\\n    Args:\\n        data_path: Path for the feature data in CSV format.\\n        model_path: Path for the trained model in binary XGBoost format.\\n        predictions_path: Output path for the predictions.\\n        label_column: Column containing the label data.\\n\\n    Annotations:\\n        author: Alexey Volkov <alexey.volkov@ark-kun.com>')\n_parser.add_argument(\"--data\", dest=\"data_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--model\", dest=\"model_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--label-column\", dest=\"label_column\", type=int, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--predictions\", dest=\"predictions_path\", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\n_outputs = xgboost_predict(**_parsed_args)\n"
            ]
          }
        },
        "exec-convert-csv-to-apache-parquet": {
          "container": {
            "command": [
              "sh",
              "-c",
              "(PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'pyarrow==0.17.1' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'pyarrow==0.17.1' --user) && \"$0\" \"$@\"",
              "python3",
              "-u",
              "-c",
              "def _make_parent_dirs_and_return_path(file_path: str):\n    import os\n    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n    return file_path\n\ndef convert_csv_to_apache_parquet(\n    data_path,\n    output_data_path,\n):\n    '''Converts CSV table to Apache Parquet.\n\n    [Apache Parquet](https://parquet.apache.org/)\n\n    Annotations:\n        author: Alexey Volkov <alexey.volkov@ark-kun.com>\n    '''\n    from pyarrow import csv, parquet\n\n    table = csv.read_csv(data_path)\n    parquet.write_table(table, output_data_path)\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Convert csv to apache parquet', description='Converts CSV table to Apache Parquet.\\n\\n    [Apache Parquet](https://parquet.apache.org/)\\n\\n    Annotations:\\n        author: Alexey Volkov <alexey.volkov@ark-kun.com>')\n_parser.add_argument(\"--data\", dest=\"data_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--output-data\", dest=\"output_data_path\", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n_output_files = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = convert_csv_to_apache_parquet(**_parsed_args)\n\n_output_serializers = [\n\n]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n    try:\n        os.makedirs(os.path.dirname(output_file))\n    except OSError:\n        pass\n    with open(output_file, 'w') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"
            ],
            "args": [
              "--data",
              "{{$.inputs.artifacts['data'].path}}",
              "--output-data",
              "{{$.outputs.artifacts['output_data'].path}}"
            ],
            "image": "python:3.7"
          }
        },
        "exec-xgboost-train": {
          "container": {
            "command": [
              "sh",
              "-c",
              "(PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'xgboost==1.1.1' 'pandas==1.0.5' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'xgboost==1.1.1' 'pandas==1.0.5' --user) && \"$0\" \"$@\"",
              "python3",
              "-u",
              "-c",
              "def _make_parent_dirs_and_return_path(file_path: str):\n    import os\n    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n    return file_path\n\ndef xgboost_train(\n    training_data_path,  # Also supports LibSVM\n    model_path,\n    model_config_path,\n    starting_model_path = None,\n\n    label_column = 0,\n    num_iterations = 10,\n    booster_params = None,\n\n    # Booster parameters\n    objective = 'reg:squarederror',\n    booster = 'gbtree',\n    learning_rate = 0.3,\n    min_split_loss = 0,\n    max_depth = 6,\n):\n    '''Train an XGBoost model.\n\n    Args:\n        training_data_path: Path for the training data in CSV format.\n        model_path: Output path for the trained model in binary XGBoost format.\n        model_config_path: Output path for the internal parameter configuration of Booster as a JSON string.\n        starting_model_path: Path for the existing trained model to start from.\n        label_column: Column containing the label data.\n        num_boost_rounds: Number of boosting iterations.\n        booster_params: Parameters for the booster. See https://xgboost.readthedocs.io/en/latest/parameter.html\n        objective: The learning task and the corresponding learning objective.\n            See https://xgboost.readthedocs.io/en/latest/parameter.html#learning-task-parameters\n            The most common values are:\n            \"reg:squarederror\" - Regression with squared loss (default).\n            \"reg:logistic\" - Logistic regression.\n            \"binary:logistic\" - Logistic regression for binary classification, output probability.\n            \"binary:logitraw\" - Logistic regression for binary classification, output score before logistic transformation\n            \"rank:pairwise\" - Use LambdaMART to perform pairwise ranking where the pairwise loss is minimized\n            \"rank:ndcg\" - Use LambdaMART to perform list-wise ranking where Normalized Discounted Cumulative Gain (NDCG) is maximized\n\n    Annotations:\n        author: Alexey Volkov <alexey.volkov@ark-kun.com>\n    '''\n    import pandas\n    import xgboost\n\n    df = pandas.read_csv(\n        training_data_path,\n    )\n\n    training_data = xgboost.DMatrix(\n        data=df.drop(columns=[df.columns[label_column]]),\n        label=df[df.columns[label_column]],\n    )\n\n    booster_params = booster_params or {}\n    booster_params.setdefault('objective', objective)\n    booster_params.setdefault('booster', booster)\n    booster_params.setdefault('learning_rate', learning_rate)\n    booster_params.setdefault('min_split_loss', min_split_loss)\n    booster_params.setdefault('max_depth', max_depth)\n\n    starting_model = None\n    if starting_model_path:\n        starting_model = xgboost.Booster(model_file=starting_model_path)\n\n    model = xgboost.train(\n        params=booster_params,\n        dtrain=training_data,\n        num_boost_round=num_iterations,\n        xgb_model=starting_model\n    )\n\n    # Saving the model in binary format\n    model.save_model(model_path)\n\n    model_config_str = model.save_config()\n    with open(model_config_path, 'w') as model_config_file:\n        model_config_file.write(model_config_str)\n\nimport json\nimport argparse\n_parser = argparse.ArgumentParser(prog='Xgboost train', description='Train an XGBoost model.\\n\\n    Args:\\n        training_data_path: Path for the training data in CSV format.\\n        model_path: Output path for the trained model in binary XGBoost format.\\n        model_config_path: Output path for the internal parameter configuration of Booster as a JSON string.\\n        starting_model_path: Path for the existing trained model to start from.\\n        label_column: Column containing the label data.\\n        num_boost_rounds: Number of boosting iterations.\\n        booster_params: Parameters for the booster. See https://xgboost.readthedocs.io/en/latest/parameter.html\\n        objective: The learning task and the corresponding learning objective.\\n            See https://xgboost.readthedocs.io/en/latest/parameter.html#learning-task-parameters\\n            The most common values are:\\n            \"reg:squarederror\" - Regression with squared loss (default).\\n            \"reg:logistic\" - Logistic regression.\\n            \"binary:logistic\" - Logistic regression for binary classification, output probability.\\n            \"binary:logitraw\" - Logistic regression for binary classification, output score before logistic transformation\\n            \"rank:pairwise\" - Use LambdaMART to perform pairwise ranking where the pairwise loss is minimized\\n            \"rank:ndcg\" - Use LambdaMART to perform list-wise ranking where Normalized Discounted Cumulative Gain (NDCG) is maximized\\n\\n    Annotations:\\n        author: Alexey Volkov <alexey.volkov@ark-kun.com>')\n_parser.add_argument(\"--training-data\", dest=\"training_data_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--starting-model\", dest=\"starting_model_path\", type=str, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--label-column\", dest=\"label_column\", type=int, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--num-iterations\", dest=\"num_iterations\", type=int, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--booster-params\", dest=\"booster_params\", type=json.loads, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--objective\", dest=\"objective\", type=str, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--booster\", dest=\"booster\", type=str, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--learning-rate\", dest=\"learning_rate\", type=float, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--min-split-loss\", dest=\"min_split_loss\", type=float, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--max-depth\", dest=\"max_depth\", type=int, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--model\", dest=\"model_path\", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--model-config\", dest=\"model_config_path\", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\n_outputs = xgboost_train(**_parsed_args)\n"
            ],
            "image": "python:3.7",
            "args": [
              "--training-data",
              "{{$.inputs.artifacts['training_data'].path}}",
              "--label-column",
              "{{$.inputs.parameters['label_column']}}",
              "--num-iterations",
              "{{$.inputs.parameters['num_iterations']}}",
              "--objective",
              "{{$.inputs.parameters['objective']}}",
              "--model",
              "{{$.outputs.artifacts['model'].path}}",
              "--model-config",
              "{{$.outputs.artifacts['model_config'].path}}"
            ]
          }
        },
        "exec-xgboost-predict": {
          "container": {
            "command": [
              "sh",
              "-c",
              "(PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'xgboost==1.1.1' 'pandas==1.0.5' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'xgboost==1.1.1' 'pandas==1.0.5' --user) && \"$0\" \"$@\"",
              "python3",
              "-u",
              "-c",
              "def _make_parent_dirs_and_return_path(file_path: str):\n    import os\n    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n    return file_path\n\ndef xgboost_predict(\n    data_path,  # Also supports LibSVM\n    model_path,\n    predictions_path,\n    label_column = None,\n):\n    '''Make predictions using a trained XGBoost model.\n\n    Args:\n        data_path: Path for the feature data in CSV format.\n        model_path: Path for the trained model in binary XGBoost format.\n        predictions_path: Output path for the predictions.\n        label_column: Column containing the label data.\n\n    Annotations:\n        author: Alexey Volkov <alexey.volkov@ark-kun.com>\n    '''\n    from pathlib import Path\n\n    import numpy\n    import pandas\n    import xgboost\n\n    df = pandas.read_csv(\n        data_path,\n    )\n\n    if label_column is not None:\n        df = df.drop(columns=[df.columns[label_column]])\n\n    testing_data = xgboost.DMatrix(\n        data=df,\n    )\n\n    model = xgboost.Booster(model_file=model_path)\n\n    predictions = model.predict(testing_data)\n\n    Path(predictions_path).parent.mkdir(parents=True, exist_ok=True)\n    numpy.savetxt(predictions_path, predictions)\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Xgboost predict', description='Make predictions using a trained XGBoost model.\\n\\n    Args:\\n        data_path: Path for the feature data in CSV format.\\n        model_path: Path for the trained model in binary XGBoost format.\\n        predictions_path: Output path for the predictions.\\n        label_column: Column containing the label data.\\n\\n    Annotations:\\n        author: Alexey Volkov <alexey.volkov@ark-kun.com>')\n_parser.add_argument(\"--data\", dest=\"data_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--model\", dest=\"model_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--label-column\", dest=\"label_column\", type=int, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--predictions\", dest=\"predictions_path\", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\n_outputs = xgboost_predict(**_parsed_args)\n"
            ],
            "args": [
              "--data",
              "{{$.inputs.artifacts['data'].path}}",
              "--model",
              "{{$.inputs.artifacts['model'].path}}",
              "--label-column",
              "{{$.inputs.parameters['label_column']}}",
              "--predictions",
              "{{$.outputs.parameters['predictions'].output_file}}"
            ],
            "image": "python:3.7"
          }
        }
      }
    },
    "components": {
      "comp-xgboost-train-2": {
        "executorLabel": "exec-xgboost-train-2",
        "inputDefinitions": {
          "parameters": {
            "objective": {
              "type": "STRING"
            },
            "label_column_name": {
              "type": "STRING"
            },
            "num_iterations": {
              "type": "INT"
            }
          },
          "artifacts": {
            "training_data": {
              "artifactType": {
                "instanceSchema": "title: kfp.Artifact\ntype: object\n"
              }
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "model": {
              "artifactType": {
                "instanceSchema": "title: kfp.Artifact\ntype: object\n"
              }
            },
            "model_config": {
              "artifactType": {
                "instanceSchema": "title: kfp.Artifact\ntype: object\n"
              }
            }
          }
        }
      },
      "comp-xgboost-predict": {
        "inputDefinitions": {
          "parameters": {
            "label_column": {
              "type": "INT"
            }
          },
          "artifacts": {
            "data": {
              "artifactType": {
                "instanceSchema": "title: kfp.Artifact\ntype: object\n"
              }
            },
            "model": {
              "artifactType": {
                "instanceSchema": "title: kfp.Artifact\ntype: object\n"
              }
            }
          }
        },
        "executorLabel": "exec-xgboost-predict",
        "outputDefinitions": {
          "parameters": {
            "predictions": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-xgboost-train": {
        "inputDefinitions": {
          "artifacts": {
            "training_data": {
              "artifactType": {
                "instanceSchema": "title: kfp.Artifact\ntype: object\n"
              }
            }
          },
          "parameters": {
            "objective": {
              "type": "STRING"
            },
            "num_iterations": {
              "type": "INT"
            },
            "label_column": {
              "type": "INT"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "model": {
              "artifactType": {
                "instanceSchema": "title: kfp.Artifact\ntype: object\n"
              }
            },
            "model_config": {
              "artifactType": {
                "instanceSchema": "title: kfp.Artifact\ntype: object\n"
              }
            }
          }
        },
        "executorLabel": "exec-xgboost-train"
      },
      "comp-chicago-taxi-trips-dataset": {
        "executorLabel": "exec-chicago-taxi-trips-dataset",
        "outputDefinitions": {
          "artifacts": {
            "Table": {
              "artifactType": {
                "instanceSchema": "title: kfp.Artifact\ntype: object\n"
              }
            }
          }
        },
        "inputDefinitions": {
          "parameters": {
            "Where": {
              "type": "STRING"
            },
            "Limit": {
              "type": "INT"
            },
            "Format": {
              "type": "STRING"
            },
            "Select": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-xgboost-predict-2": {
        "executorLabel": "exec-xgboost-predict-2",
        "inputDefinitions": {
          "parameters": {
            "label_column_name": {
              "type": "STRING"
            }
          },
          "artifacts": {
            "model": {
              "artifactType": {
                "instanceSchema": "title: kfp.Artifact\ntype: object\n"
              }
            },
            "data": {
              "artifactType": {
                "instanceSchema": "title: kfp.Artifact\ntype: object\n"
              }
            }
          }
        },
        "outputDefinitions": {
          "parameters": {
            "predictions": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-convert-csv-to-apache-parquet": {
        "outputDefinitions": {
          "artifacts": {
            "output_data": {
              "artifactType": {
                "instanceSchema": "title: kfp.Artifact\ntype: object\n"
              }
            }
          }
        },
        "executorLabel": "exec-convert-csv-to-apache-parquet",
        "inputDefinitions": {
          "artifacts": {
            "data": {
              "artifactType": {
                "instanceSchema": "title: kfp.Artifact\ntype: object\n"
              }
            }
          }
        }
      },
      "comp-xgboost-predict-4": {
        "outputDefinitions": {
          "parameters": {
            "predictions": {
              "type": "STRING"
            }
          }
        },
        "inputDefinitions": {
          "parameters": {
            "label_column": {
              "type": "INT"
            }
          },
          "artifacts": {
            "data": {
              "artifactType": {
                "instanceSchema": "title: kfp.Artifact\ntype: object\n"
              }
            },
            "model": {
              "artifactType": {
                "instanceSchema": "title: kfp.Artifact\ntype: object\n"
              }
            }
          }
        },
        "executorLabel": "exec-xgboost-predict-4"
      },
      "comp-xgboost-predict-3": {
        "inputDefinitions": {
          "artifacts": {
            "model": {
              "artifactType": {
                "instanceSchema": "title: kfp.Artifact\ntype: object\n"
              }
            },
            "data": {
              "artifactType": {
                "instanceSchema": "title: kfp.Artifact\ntype: object\n"
              }
            }
          },
          "parameters": {
            "label_column_name": {
              "type": "STRING"
            }
          }
        },
        "executorLabel": "exec-xgboost-predict-3",
        "outputDefinitions": {
          "parameters": {
            "predictions": {
              "type": "STRING"
            }
          }
        }
      }
    },
    "pipelineInfo": {
      "name": "xgboost-sample-pipeline"
    },
    "root": {
      "dag": {
        "tasks": {
          "task-xgboost-predict-3": {
            "componentRef": {
              "name": "comp-xgboost-predict-3"
            },
            "taskInfo": {
              "name": "task-xgboost-predict-3"
            },
            "dependentTasks": [
              "task-convert-csv-to-apache-parquet",
              "task-xgboost-train"
            ],
            "inputs": {
              "artifacts": {
                "data": {
                  "taskOutputArtifact": {
                    "producerTask": "task-convert-csv-to-apache-parquet",
                    "outputArtifactKey": "output_data"
                  }
                },
                "model": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "model",
                    "producerTask": "task-xgboost-train"
                  }
                }
              },
              "parameters": {
                "label_column_name": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "tips"
                    }
                  }
                }
              }
            }
          },
          "task-xgboost-predict-4": {
            "componentRef": {
              "name": "comp-xgboost-predict-4"
            },
            "dependentTasks": [
              "task-chicago-taxi-trips-dataset",
              "task-xgboost-train-2"
            ],
            "taskInfo": {
              "name": "task-xgboost-predict-4"
            },
            "inputs": {
              "parameters": {
                "label_column": {
                  "runtimeValue": {
                    "constantValue": {
                      "intValue": "0"
                    }
                  }
                }
              },
              "artifacts": {
                "data": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "Table",
                    "producerTask": "task-chicago-taxi-trips-dataset"
                  }
                },
                "model": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "model",
                    "producerTask": "task-xgboost-train-2"
                  }
                }
              }
            }
          },
          "task-xgboost-predict-2": {
            "dependentTasks": [
              "task-convert-csv-to-apache-parquet",
              "task-xgboost-train-2"
            ],
            "taskInfo": {
              "name": "task-xgboost-predict-2"
            },
            "componentRef": {
              "name": "comp-xgboost-predict-2"
            },
            "inputs": {
              "parameters": {
                "label_column_name": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "tips"
                    }
                  }
                }
              },
              "artifacts": {
                "model": {
                  "taskOutputArtifact": {
                    "producerTask": "task-xgboost-train-2",
                    "outputArtifactKey": "model"
                  }
                },
                "data": {
                  "taskOutputArtifact": {
                    "producerTask": "task-convert-csv-to-apache-parquet",
                    "outputArtifactKey": "output_data"
                  }
                }
              }
            }
          },
          "task-xgboost-train": {
            "taskInfo": {
              "name": "task-xgboost-train"
            },
            "inputs": {
              "artifacts": {
                "training_data": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "Table",
                    "producerTask": "task-chicago-taxi-trips-dataset"
                  }
                }
              },
              "parameters": {
                "num_iterations": {
                  "runtimeValue": {
                    "constantValue": {
                      "intValue": "200"
                    }
                  }
                },
                "objective": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "reg:squarederror"
                    }
                  }
                },
                "label_column": {
                  "runtimeValue": {
                    "constantValue": {
                      "intValue": "0"
                    }
                  }
                }
              }
            },
            "componentRef": {
              "name": "comp-xgboost-train"
            },
            "dependentTasks": [
              "task-chicago-taxi-trips-dataset"
            ]
          },
          "task-convert-csv-to-apache-parquet": {
            "inputs": {
              "artifacts": {
                "data": {
                  "taskOutputArtifact": {
                    "producerTask": "task-chicago-taxi-trips-dataset",
                    "outputArtifactKey": "Table"
                  }
                }
              }
            },
            "dependentTasks": [
              "task-chicago-taxi-trips-dataset"
            ],
            "componentRef": {
              "name": "comp-convert-csv-to-apache-parquet"
            },
            "taskInfo": {
              "name": "task-convert-csv-to-apache-parquet"
            }
          },
          "task-chicago-taxi-trips-dataset": {
            "componentRef": {
              "name": "comp-chicago-taxi-trips-dataset"
            },
            "inputs": {
              "parameters": {
                "Format": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "csv"
                    }
                  }
                },
                "Limit": {
                  "runtimeValue": {
                    "constantValue": {
                      "intValue": "10000"
                    }
                  }
                },
                "Select": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "tips,trip_seconds,trip_miles,pickup_community_area,dropoff_community_area,fare,tolls,extras,trip_total"
                    }
                  }
                },
                "Where": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "trip_start_timestamp >= \"2019-01-01\" AND trip_start_timestamp < \"2019-02-01\""
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "task-chicago-taxi-trips-dataset"
            }
          },
          "task-xgboost-predict": {
            "componentRef": {
              "name": "comp-xgboost-predict"
            },
            "inputs": {
              "parameters": {
                "label_column": {
                  "runtimeValue": {
                    "constantValue": {
                      "intValue": "0"
                    }
                  }
                }
              },
              "artifacts": {
                "model": {
                  "taskOutputArtifact": {
                    "producerTask": "task-xgboost-train",
                    "outputArtifactKey": "model"
                  }
                },
                "data": {
                  "taskOutputArtifact": {
                    "producerTask": "task-chicago-taxi-trips-dataset",
                    "outputArtifactKey": "Table"
                  }
                }
              }
            },
            "taskInfo": {
              "name": "task-xgboost-predict"
            },
            "dependentTasks": [
              "task-chicago-taxi-trips-dataset",
              "task-xgboost-train"
            ]
          },
          "task-xgboost-train-2": {
            "componentRef": {
              "name": "comp-xgboost-train-2"
            },
            "taskInfo": {
              "name": "task-xgboost-train-2"
            },
            "dependentTasks": [
              "task-convert-csv-to-apache-parquet"
            ],
            "inputs": {
              "artifacts": {
                "training_data": {
                  "taskOutputArtifact": {
                    "producerTask": "task-convert-csv-to-apache-parquet",
                    "outputArtifactKey": "output_data"
                  }
                }
              },
              "parameters": {
                "num_iterations": {
                  "runtimeValue": {
                    "constantValue": {
                      "intValue": "200"
                    }
                  }
                },
                "label_column_name": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "tips"
                    }
                  }
                },
                "objective": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "reg:squarederror"
                    }
                  }
                }
              }
            }
          }
        }
      }
    },
    "sdkVersion": "kfp-1.5.0-rc.0",
    "schemaVersion": "2.0.0"
  },
  "runtimeConfig": {
    "gcsOutputDirectory": "dummy_root"
  }
}