{
  "pipelineSpec": {
    "deploymentSpec": {
      "executors": {
        "exec-train": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "train",
              "--dataset-one",
              "{{$.inputs.artifacts['dataset_one'].path}}",
              "--dataset-two",
              "{{$.inputs.artifacts['dataset_two'].path}}",
              "--message",
              "{{$.inputs.parameters['message']}}",
              "--num-steps",
              "{{$.inputs.parameters['num_steps']}}",
              "--model",
              "{{$.outputs.artifacts['model'].path}}"
            ],
            "image": "python:3.7",
            "command": [
              "sh",
              "-ec",
              "program_path=$(mktemp)\nprintf \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n",
              "\nimport json\nimport inspect\nfrom typing import *\n\n# Copyright 2021 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"Classes for input/output types in KFP SDK.\n\nThese are only compatible with v2 Pipelines.\n\"\"\"\n\nimport os\nfrom typing import Dict, Optional, Type, TypeVar\n\n\nclass Artifact(object):\n  \"\"\"Generic Artifact class.\n\n  This class is meant to represent the metadata around an input or output\n  machine-learning Artifact. Artifacts have URIs, which can either be a location\n  on disk (or Cloud storage) or some other resource identifier such as\n  an API resource name.\n\n  Artifacts carry a `metadata` field, which is a dictionary for storing\n  metadata related to this artifact.\n  \"\"\"\n  TYPE_NAME = \"system.Artifact\"\n\n  def __init__(self,\n               name: Optional[str] = None,\n               uri: Optional[str] = None,\n               metadata: Optional[Dict] = None):\n    \"\"\"Initializes the Artifact with the given name, URI and metadata.\"\"\"\n    self.uri = uri or ''\n    self.name = name or ''\n    self.metadata = metadata or {}\n\n\nclass Model(Artifact):\n  \"\"\"An artifact representing an ML Model.\"\"\"\n  TYPE_NAME = \"kfp.Model\"\n\n  def __init__(self,\n               name: Optional[str] = None,\n               uri: Optional[str] = None,\n               metadata: Optional[Dict] = None):\n    super().__init__(uri=uri, name=name, metadata=metadata)\n\n  @property\n  def framework(self) -> str:\n    return self._get_framework()\n\n  def _get_framework(self) -> str:\n    return self.metadata.get('framework', '')\n\n  @framework.setter\n  def framework(self, framework: str):\n    self._set_framework(framework)\n\n  def _set_framework(self, framework: str):\n    self.metadata['framework'] = framework\n\n\nclass Dataset(Artifact):\n  \"\"\"An artifact representing an ML Dataset.\"\"\"\n  TYPE_NAME = \"kfp.Dataset\"\n\n  def __init__(self,\n               name: Optional[str] = None,\n               uri: Optional[str] = None,\n               metadata: Optional[Dict] = None):\n    super().__init__(uri=uri, name=name, metadata=metadata)\n\n\nclass Metrics(Artifact):\n  \"\"\"Represent a simple base Artifact type to store key-value scalar metrics.\n  \"\"\"\n  TYPE_NAME = \"kfp.Metrics\"\n\n  def __init__(self,\n               name: Optional[str] = None,\n               uri: Optional[str] = None,\n               metadata: Optional[Dict] = None):\n    super().__init__(uri=uri, name=name, metadata=metadata)\n\n  def log_metric(self, metric: str, value: float):\n    \"\"\"Sets a custom scalar metric.\n\n    Args:\n      metric: Metric key\n      value: Value of the metric.\n    \"\"\"\n    self.metadata[metric] = value\n\n\nT = TypeVar('T', bound=Artifact)\n\n_GCS_LOCAL_MOUNT_PREFIX = '/gcs/'\n\n\nclass _IOArtifact():\n  \"\"\"Internal wrapper class for representing Input/Output Artifacts.\"\"\"\n\n  def __init__(self, artifact_type: Type[T], artifact: Optional[T] = None):\n    self.type = artifact_type\n    self._artifact = artifact\n\n  def get(self) -> T:\n    return self._artifact\n\n  @property\n  def uri(self):\n    return self._artifact.uri\n\n  @uri.setter\n  def uri(self, uri):\n    self._artifact.uri = uri\n\n  @property\n  def path(self):\n    return self._get_path()\n\n  @path.setter\n  def path(self, path):\n    self._set_path(path)\n\n  def _get_path(self) -> str:\n    if self._artifact.uri.startswith('gs://'):\n      return _GCS_LOCAL_MOUNT_PREFIX + self._artifact.uri[len('gs://'):]\n\n  def _set_path(self, path):\n    if path.startswith(_GCS_LOCAL_MOUNT_PREFIX):\n      path = 'gs://' + path[len(_GCS_LOCAL_MOUNT_PREFIX):]\n    self._artifact.uri = path\n\n\nclass InputArtifact(_IOArtifact):\n\n  def __init__(self, artifact_type: Type[T], artifact: Optional[T] = None):\n    super().__init__(artifact_type=artifact_type, artifact=artifact)\n\n\nclass OutputArtifact(_IOArtifact):\n\n  def __init__(self, artifact_type: Type[T], artifact: Optional[T] = None):\n    super().__init__(artifact_type=artifact_type, artifact=artifact)\n    if artifact is not None:\n      os.makedirs(self.path, exist_ok=True)\n      self.path = os.path.join(self.path, 'data')\n\n\n_SCHEMA_TITLE_TO_TYPE: Dict[str, Artifact] = {\n    x.TYPE_NAME: x for x in [Artifact, Model, Dataset, Metrics]\n}\n\n\ndef create_runtime_artifact(runtime_artifact: Dict) -> Artifact:\n  \"\"\"Creates an Artifact instance from the specified RuntimeArtifact.\n\n  Args:\n    runtime_artifact: Dictionary representing JSON-encoded RuntimeArtifact.\n  \"\"\"\n  schema_title = runtime_artifact.get('type', {}).get('schemaTitle', '')\n\n  artifact_type = _SCHEMA_TITLE_TO_TYPE.get(schema_title)\n  if not artifact_type:\n    artifact_type = Artifact\n  return artifact_type(\n      uri=runtime_artifact.get('uri', ''),\n      name=runtime_artifact.get('name', ''),\n      metadata=runtime_artifact.get('metadata', {}),\n  )\n\nclass InputPath:\n    '''When creating component from function, :class:`.InputPath` should be used as function parameter annotation to tell the system to pass the *data file path* to the function instead of passing the actual data.'''\n    def __init__(self, type=None):\n        self.type = type\n\nclass OutputPath:\n    '''When creating component from function, :class:`.OutputPath` should be used as function parameter annotation to tell the system that the function wants to output data by writing it into a file with the given path instead of returning the data from the function.'''\n    def __init__(self, type=None):\n        self.type = type\n\nclass Executor():\n  \"\"\"Executor executes v2-based Python function components.\"\"\"\n\n  def __init__(self, executor_input: Dict, function_to_execute: Callable):\n    self._func = function_to_execute\n    self._input = executor_input\n    self._input_artifacts: Dict[str, InputArtifact] = {}\n    self._output_artifacts: Dict[str, OutputArtifact] = {}\n\n    for name, artifacts in self._input.get('inputs', {}).get('artifacts',\n                                                             {}).items():\n      artifacts_list = artifacts.get('artifacts')\n      if artifacts_list:\n        self._input_artifacts[name] = self._make_input_artifact(\n            artifacts_list[0])\n\n    for name, artifacts in self._input.get('outputs', {}).get('artifacts',\n                                                              {}).items():\n      artifacts_list = artifacts.get('artifacts')\n      if artifacts_list:\n        self._output_artifacts[name] = self._make_output_artifact(\n            artifacts_list[0])\n\n  @classmethod\n  def _make_input_artifact(self, runtime_artifact: Dict):\n    artifact = create_runtime_artifact(runtime_artifact)\n    return InputArtifact(artifact_type=type(artifact), artifact=artifact)\n\n  @classmethod\n  def _make_output_artifact(self, runtime_artifact: Dict):\n    artifact = create_runtime_artifact(runtime_artifact)\n    return OutputArtifact(artifact_type=type(artifact), artifact=artifact)\n\n  def _get_input_artifact(self, name: str):\n    return self._input_artifacts.get(name)\n\n  def _get_output_artifact(self, name: str):\n    return self._output_artifacts.get(name)\n\n  def _get_input_parameter_value(self, parameter_name: str):\n    parameter = self._input.get('inputs', {}).get('parameters',\n                                                  {}).get(parameter_name, None)\n    if parameter is None:\n      return None\n\n    if parameter.get('stringValue'):\n      return parameter['stringValue']\n    elif parameter.get('intValue'):\n      return int(parameter['intValue'])\n    elif parameter.get('doubleValue'):\n      return float(parameter['doubleValue'])\n\n  def _get_output_parameter_path(self, parameter_name: str):\n    parameter_name = self._maybe_strip_path_suffix(parameter_name)\n    parameter = self._input.get('outputs',\n                                {}).get('parameters',\n                                        {}).get(parameter_name, None)\n    if parameter is None:\n      return None\n\n    return parameter.get('outputFile', None)\n\n  def _get_output_artifact_path(self, artifact_name: str):\n    artifact_name = self._maybe_strip_path_suffix(artifact_name)\n    output_artifact = self._output_artifacts.get(artifact_name)\n    if not output_artifact:\n      raise ValueError(\n          'Failed to get OutputArtifact path for artifact name {}'.format(\n              artifact_name))\n    return output_artifact.path\n\n  def _get_input_artifact_path(self, artifact_name: str):\n    artifact_name = self._maybe_strip_path_suffix(artifact_name)\n    input_artifact = self._input_artifacts.get(artifact_name)\n    if not input_artifact:\n      raise ValueError(\n          'Failed to get InputArtifact path for artifact name {}'.format(\n              artifact_name))\n    return input_artifact.path\n\n  def _write_executor_output(self):\n    executor_output = {'artifacts': {}}\n\n    for name, artifact in self._output_artifacts.items():\n      runtime_artifact = {\n          \"name\": artifact.get().name,\n          \"uri\": artifact.get().uri,\n          \"metadata\": artifact.get().metadata,\n      }\n      artifacts_list = {'artifacts': [runtime_artifact]}\n\n      executor_output['artifacts'][name] = artifacts_list\n\n    with open(self._input['outputs']['outputFile'], 'w') as f:\n      f.write(json.dumps(executor_output))\n\n  def _maybe_strip_path_suffix(self, name) -> str:\n    if name.endswith('_path'):\n      name = name[0:-len('_path')]\n    if name.endswith('_file'):\n      name = name[0:-len('_file')]\n    return name\n\n  def execute(self):\n    annotations = inspect.getfullargspec(self._func).annotations\n\n    # Function arguments.\n    func_kwargs = {}\n\n    for k, v in annotations.items():\n      if v in [str, float, int]:\n        func_kwargs[k] = self._get_input_parameter_value(k)\n\n      if isinstance(v, OutputPath):\n        if v.type in [str, float, int]:\n          func_kwargs[k] = self._get_output_parameter_path(k)\n        else:\n          func_kwargs[k] = self._get_output_artifact_path(k)\n\n      if isinstance(v, InputPath):\n        func_kwargs[k] = self._get_input_artifact_path(k)\n\n      if isinstance(v, InputArtifact):\n        func_kwargs[k] = self._get_input_artifact(k)\n\n      if isinstance(v, OutputArtifact):\n        func_kwargs[k] = self._get_output_artifact(k)\n\n    # TODO(neuromage): Support returned NamedTuple parameters.\n    self._func(**func_kwargs)\n    self._write_executor_output()\n\n\ndef train(\n    # Use InputPath to get a locally accessible path for the input artifact\n    # of type `Dataset`.\n    dataset_one_path: InputPath('Dataset'),\n    # Use InputArtifact to get a metadata-rich handle to the input artifact\n    # of type `Dataset`.\n    dataset_two: InputArtifact(Dataset),\n    # An input parameter of type string.\n    message: str,\n    # Use OutputArtifact to get a metadata-rich handle to the output artifact\n    # of type `Dataset`.\n    model: OutputArtifact(Model),\n    # An input parameter of type int with a default value.\n    num_steps: int = 100):\n  '''Dummy Training step'''\n  with open(dataset_one_path, 'r') as input_file:\n    dataset_one_contents = input_file.read()\n\n  with open(dataset_two.path, 'r') as input_file:\n    dataset_two_contents = input_file.read()\n\n  line = \"dataset_one_contents: {} || dataset_two_contents: {} || message: {}\\n\".format(\n      dataset_one_contents, dataset_two_contents, message)\n\n  with open(model.path, 'w') as output_file:\n    for i in range(num_steps):\n      output_file.write(\"Step {}\\n{}\\n=====\\n\".format(i, line))\n\n  # Use model.get() to get a Model artifact, which has a .metadata dictionary\n  # to store arbitrary metadata for the output artifact.\n  model.get().metadata['accuracy'] = 0.9\n\n\ndef executor_main():\n  import argparse\n  import json\n\n  parser = argparse.ArgumentParser(description='Process some integers.')\n  parser.add_argument('--executor_input', type=str)\n  parser.add_argument('--function_to_execute', type=str)\n\n  args, _ = parser.parse_known_args()\n  executor_input = json.loads(args.executor_input)\n  function_to_execute = globals()[args.function_to_execute]\n\n  executor = Executor(executor_input=executor_input,\n                      function_to_execute=function_to_execute)\n\n  executor.execute()\n\n\nif __name__ == '__main__':\n  executor_main()\n"
            ]
          }
        },
        "exec-preprocess": {
          "container": {
            "image": "python:3.7",
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "preprocess",
              "--message",
              "{{$.inputs.parameters['message']}}",
              "--output-dataset-one",
              "{{$.outputs.artifacts['output_dataset_one'].path}}",
              "--output-dataset-two",
              "{{$.outputs.artifacts['output_dataset_two'].path}}",
              "--output-parameter",
              "{{$.outputs.parameters['output_parameter'].output_file}}"
            ],
            "command": [
              "sh",
              "-ec",
              "program_path=$(mktemp)\nprintf \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n",
              "\nimport json\nimport inspect\nfrom typing import *\n\n# Copyright 2021 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"Classes for input/output types in KFP SDK.\n\nThese are only compatible with v2 Pipelines.\n\"\"\"\n\nimport os\nfrom typing import Dict, Optional, Type, TypeVar\n\n\nclass Artifact(object):\n  \"\"\"Generic Artifact class.\n\n  This class is meant to represent the metadata around an input or output\n  machine-learning Artifact. Artifacts have URIs, which can either be a location\n  on disk (or Cloud storage) or some other resource identifier such as\n  an API resource name.\n\n  Artifacts carry a `metadata` field, which is a dictionary for storing\n  metadata related to this artifact.\n  \"\"\"\n  TYPE_NAME = \"system.Artifact\"\n\n  def __init__(self,\n               name: Optional[str] = None,\n               uri: Optional[str] = None,\n               metadata: Optional[Dict] = None):\n    \"\"\"Initializes the Artifact with the given name, URI and metadata.\"\"\"\n    self.uri = uri or ''\n    self.name = name or ''\n    self.metadata = metadata or {}\n\n\nclass Model(Artifact):\n  \"\"\"An artifact representing an ML Model.\"\"\"\n  TYPE_NAME = \"kfp.Model\"\n\n  def __init__(self,\n               name: Optional[str] = None,\n               uri: Optional[str] = None,\n               metadata: Optional[Dict] = None):\n    super().__init__(uri=uri, name=name, metadata=metadata)\n\n  @property\n  def framework(self) -> str:\n    return self._get_framework()\n\n  def _get_framework(self) -> str:\n    return self.metadata.get('framework', '')\n\n  @framework.setter\n  def framework(self, framework: str):\n    self._set_framework(framework)\n\n  def _set_framework(self, framework: str):\n    self.metadata['framework'] = framework\n\n\nclass Dataset(Artifact):\n  \"\"\"An artifact representing an ML Dataset.\"\"\"\n  TYPE_NAME = \"kfp.Dataset\"\n\n  def __init__(self,\n               name: Optional[str] = None,\n               uri: Optional[str] = None,\n               metadata: Optional[Dict] = None):\n    super().__init__(uri=uri, name=name, metadata=metadata)\n\n\nclass Metrics(Artifact):\n  \"\"\"Represent a simple base Artifact type to store key-value scalar metrics.\n  \"\"\"\n  TYPE_NAME = \"kfp.Metrics\"\n\n  def __init__(self,\n               name: Optional[str] = None,\n               uri: Optional[str] = None,\n               metadata: Optional[Dict] = None):\n    super().__init__(uri=uri, name=name, metadata=metadata)\n\n  def log_metric(self, metric: str, value: float):\n    \"\"\"Sets a custom scalar metric.\n\n    Args:\n      metric: Metric key\n      value: Value of the metric.\n    \"\"\"\n    self.metadata[metric] = value\n\n\nT = TypeVar('T', bound=Artifact)\n\n_GCS_LOCAL_MOUNT_PREFIX = '/gcs/'\n\n\nclass _IOArtifact():\n  \"\"\"Internal wrapper class for representing Input/Output Artifacts.\"\"\"\n\n  def __init__(self, artifact_type: Type[T], artifact: Optional[T] = None):\n    self.type = artifact_type\n    self._artifact = artifact\n\n  def get(self) -> T:\n    return self._artifact\n\n  @property\n  def uri(self):\n    return self._artifact.uri\n\n  @uri.setter\n  def uri(self, uri):\n    self._artifact.uri = uri\n\n  @property\n  def path(self):\n    return self._get_path()\n\n  @path.setter\n  def path(self, path):\n    self._set_path(path)\n\n  def _get_path(self) -> str:\n    if self._artifact.uri.startswith('gs://'):\n      return _GCS_LOCAL_MOUNT_PREFIX + self._artifact.uri[len('gs://'):]\n\n  def _set_path(self, path):\n    if path.startswith(_GCS_LOCAL_MOUNT_PREFIX):\n      path = 'gs://' + path[len(_GCS_LOCAL_MOUNT_PREFIX):]\n    self._artifact.uri = path\n\n\nclass InputArtifact(_IOArtifact):\n\n  def __init__(self, artifact_type: Type[T], artifact: Optional[T] = None):\n    super().__init__(artifact_type=artifact_type, artifact=artifact)\n\n\nclass OutputArtifact(_IOArtifact):\n\n  def __init__(self, artifact_type: Type[T], artifact: Optional[T] = None):\n    super().__init__(artifact_type=artifact_type, artifact=artifact)\n    if artifact is not None:\n      os.makedirs(self.path, exist_ok=True)\n      self.path = os.path.join(self.path, 'data')\n\n\n_SCHEMA_TITLE_TO_TYPE: Dict[str, Artifact] = {\n    x.TYPE_NAME: x for x in [Artifact, Model, Dataset, Metrics]\n}\n\n\ndef create_runtime_artifact(runtime_artifact: Dict) -> Artifact:\n  \"\"\"Creates an Artifact instance from the specified RuntimeArtifact.\n\n  Args:\n    runtime_artifact: Dictionary representing JSON-encoded RuntimeArtifact.\n  \"\"\"\n  schema_title = runtime_artifact.get('type', {}).get('schemaTitle', '')\n\n  artifact_type = _SCHEMA_TITLE_TO_TYPE.get(schema_title)\n  if not artifact_type:\n    artifact_type = Artifact\n  return artifact_type(\n      uri=runtime_artifact.get('uri', ''),\n      name=runtime_artifact.get('name', ''),\n      metadata=runtime_artifact.get('metadata', {}),\n  )\n\nclass InputPath:\n    '''When creating component from function, :class:`.InputPath` should be used as function parameter annotation to tell the system to pass the *data file path* to the function instead of passing the actual data.'''\n    def __init__(self, type=None):\n        self.type = type\n\nclass OutputPath:\n    '''When creating component from function, :class:`.OutputPath` should be used as function parameter annotation to tell the system that the function wants to output data by writing it into a file with the given path instead of returning the data from the function.'''\n    def __init__(self, type=None):\n        self.type = type\n\nclass Executor():\n  \"\"\"Executor executes v2-based Python function components.\"\"\"\n\n  def __init__(self, executor_input: Dict, function_to_execute: Callable):\n    self._func = function_to_execute\n    self._input = executor_input\n    self._input_artifacts: Dict[str, InputArtifact] = {}\n    self._output_artifacts: Dict[str, OutputArtifact] = {}\n\n    for name, artifacts in self._input.get('inputs', {}).get('artifacts',\n                                                             {}).items():\n      artifacts_list = artifacts.get('artifacts')\n      if artifacts_list:\n        self._input_artifacts[name] = self._make_input_artifact(\n            artifacts_list[0])\n\n    for name, artifacts in self._input.get('outputs', {}).get('artifacts',\n                                                              {}).items():\n      artifacts_list = artifacts.get('artifacts')\n      if artifacts_list:\n        self._output_artifacts[name] = self._make_output_artifact(\n            artifacts_list[0])\n\n  @classmethod\n  def _make_input_artifact(self, runtime_artifact: Dict):\n    artifact = create_runtime_artifact(runtime_artifact)\n    return InputArtifact(artifact_type=type(artifact), artifact=artifact)\n\n  @classmethod\n  def _make_output_artifact(self, runtime_artifact: Dict):\n    artifact = create_runtime_artifact(runtime_artifact)\n    return OutputArtifact(artifact_type=type(artifact), artifact=artifact)\n\n  def _get_input_artifact(self, name: str):\n    return self._input_artifacts.get(name)\n\n  def _get_output_artifact(self, name: str):\n    return self._output_artifacts.get(name)\n\n  def _get_input_parameter_value(self, parameter_name: str):\n    parameter = self._input.get('inputs', {}).get('parameters',\n                                                  {}).get(parameter_name, None)\n    if parameter is None:\n      return None\n\n    if parameter.get('stringValue'):\n      return parameter['stringValue']\n    elif parameter.get('intValue'):\n      return int(parameter['intValue'])\n    elif parameter.get('doubleValue'):\n      return float(parameter['doubleValue'])\n\n  def _get_output_parameter_path(self, parameter_name: str):\n    parameter_name = self._maybe_strip_path_suffix(parameter_name)\n    parameter = self._input.get('outputs',\n                                {}).get('parameters',\n                                        {}).get(parameter_name, None)\n    if parameter is None:\n      return None\n\n    return parameter.get('outputFile', None)\n\n  def _get_output_artifact_path(self, artifact_name: str):\n    artifact_name = self._maybe_strip_path_suffix(artifact_name)\n    output_artifact = self._output_artifacts.get(artifact_name)\n    if not output_artifact:\n      raise ValueError(\n          'Failed to get OutputArtifact path for artifact name {}'.format(\n              artifact_name))\n    return output_artifact.path\n\n  def _get_input_artifact_path(self, artifact_name: str):\n    artifact_name = self._maybe_strip_path_suffix(artifact_name)\n    input_artifact = self._input_artifacts.get(artifact_name)\n    if not input_artifact:\n      raise ValueError(\n          'Failed to get InputArtifact path for artifact name {}'.format(\n              artifact_name))\n    return input_artifact.path\n\n  def _write_executor_output(self):\n    executor_output = {'artifacts': {}}\n\n    for name, artifact in self._output_artifacts.items():\n      runtime_artifact = {\n          \"name\": artifact.get().name,\n          \"uri\": artifact.get().uri,\n          \"metadata\": artifact.get().metadata,\n      }\n      artifacts_list = {'artifacts': [runtime_artifact]}\n\n      executor_output['artifacts'][name] = artifacts_list\n\n    with open(self._input['outputs']['outputFile'], 'w') as f:\n      f.write(json.dumps(executor_output))\n\n  def _maybe_strip_path_suffix(self, name) -> str:\n    if name.endswith('_path'):\n      name = name[0:-len('_path')]\n    if name.endswith('_file'):\n      name = name[0:-len('_file')]\n    return name\n\n  def execute(self):\n    annotations = inspect.getfullargspec(self._func).annotations\n\n    # Function arguments.\n    func_kwargs = {}\n\n    for k, v in annotations.items():\n      if v in [str, float, int]:\n        func_kwargs[k] = self._get_input_parameter_value(k)\n\n      if isinstance(v, OutputPath):\n        if v.type in [str, float, int]:\n          func_kwargs[k] = self._get_output_parameter_path(k)\n        else:\n          func_kwargs[k] = self._get_output_artifact_path(k)\n\n      if isinstance(v, InputPath):\n        func_kwargs[k] = self._get_input_artifact_path(k)\n\n      if isinstance(v, InputArtifact):\n        func_kwargs[k] = self._get_input_artifact(k)\n\n      if isinstance(v, OutputArtifact):\n        func_kwargs[k] = self._get_output_artifact(k)\n\n    # TODO(neuromage): Support returned NamedTuple parameters.\n    self._func(**func_kwargs)\n    self._write_executor_output()\n\n\ndef preprocess(\n    # An input parameter of type string.\n    message: str,\n    # Use OutputArtifact to get a metadata-rich handle to the output artifact\n    # of type `Dataset`.\n    output_dataset_one: OutputArtifact(Dataset),\n    # A locally accessible filepath for another output artifact of type\n    # `Dataset`.\n    output_dataset_two_path: OutputPath('Dataset'),\n    # A locally accessible filepath for an output parameter of type string.\n    output_parameter_path: OutputPath(str)):\n  '''Dummy preprocessing step'''\n\n  # Use OutputArtifact.path to access a local file path for writing.\n  # One can also use OutputArtifact.uri to access the actual URI file path.\n  with open(output_dataset_one.path, 'w') as f:\n    f.write(message)\n\n  # OutputPath is used to just pass the local file path of the output artifact\n  # to the function.\n  with open(output_dataset_two_path, 'w') as f:\n    f.write(message)\n\n  with open(output_parameter_path, 'w') as f:\n    f.write(message)\n\n\ndef executor_main():\n  import argparse\n  import json\n\n  parser = argparse.ArgumentParser(description='Process some integers.')\n  parser.add_argument('--executor_input', type=str)\n  parser.add_argument('--function_to_execute', type=str)\n\n  args, _ = parser.parse_known_args()\n  executor_input = json.loads(args.executor_input)\n  function_to_execute = globals()[args.function_to_execute]\n\n  executor = Executor(executor_input=executor_input,\n                      function_to_execute=function_to_execute)\n\n  executor.execute()\n\n\nif __name__ == '__main__':\n  executor_main()\n"
            ]
          }
        }
      }
    },
    "components": {
      "comp-preprocess": {
        "executorLabel": "exec-preprocess",
        "inputDefinitions": {
          "parameters": {
            "message": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "output_dataset_two": {
              "artifactType": {
                "instanceSchema": "title: kfp.Dataset\ntype: object\nproperties:\n  payload_format:\n    type: string\n  container_format:\n    type: string\n"
              }
            },
            "output_dataset_one": {
              "artifactType": {
                "instanceSchema": "title: kfp.Dataset\ntype: object\nproperties:\n  payload_format:\n    type: string\n  container_format:\n    type: string\n"
              }
            }
          },
          "parameters": {
            "output_parameter": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-train": {
        "outputDefinitions": {
          "artifacts": {
            "model": {
              "artifactType": {
                "instanceSchema": "title: kfp.Model\ntype: object\nproperties:\n  framework:\n    type: string\n  framework_version:\n    type: string\n"
              }
            }
          }
        },
        "executorLabel": "exec-train",
        "inputDefinitions": {
          "parameters": {
            "message": {
              "type": "STRING"
            },
            "num_steps": {
              "type": "INT"
            }
          },
          "artifacts": {
            "dataset_one": {
              "artifactType": {
                "instanceSchema": "title: kfp.Dataset\ntype: object\nproperties:\n  payload_format:\n    type: string\n  container_format:\n    type: string\n"
              }
            },
            "dataset_two": {
              "artifactType": {
                "instanceSchema": "title: kfp.Dataset\ntype: object\nproperties:\n  payload_format:\n    type: string\n  container_format:\n    type: string\n"
              }
            }
          }
        }
      }
    },
    "sdkVersion": "kfp-1.5.0-rc.0",
    "root": {
      "inputDefinitions": {
        "parameters": {
          "message": {
            "type": "STRING"
          }
        }
      },
      "dag": {
        "tasks": {
          "task-train": {
            "componentRef": {
              "name": "comp-train"
            },
            "dependentTasks": [
              "task-preprocess"
            ],
            "taskInfo": {
              "name": "task-train"
            },
            "inputs": {
              "parameters": {
                "num_steps": {
                  "runtimeValue": {
                    "constantValue": {
                      "intValue": "5"
                    }
                  }
                },
                "message": {
                  "taskOutputParameter": {
                    "outputParameterKey": "output_parameter",
                    "producerTask": "task-preprocess"
                  }
                }
              },
              "artifacts": {
                "dataset_two": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "output_dataset_two",
                    "producerTask": "task-preprocess"
                  }
                },
                "dataset_one": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "output_dataset_one",
                    "producerTask": "task-preprocess"
                  }
                }
              }
            }
          },
          "task-preprocess": {
            "inputs": {
              "parameters": {
                "message": {
                  "componentInputParameter": "message"
                }
              }
            },
            "taskInfo": {
              "name": "task-preprocess"
            },
            "componentRef": {
              "name": "comp-preprocess"
            }
          }
        }
      }
    },
    "pipelineInfo": {
      "name": "my-test-pipeline-beta"
    },
    "schemaVersion": "2.0.0"
  },
  "runtimeConfig": {
    "gcsOutputDirectory": "dummy_root"
  }
}