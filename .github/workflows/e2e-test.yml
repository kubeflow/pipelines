name: KFP E2E Pipeline tests
env:
  E2E_TESTS_DIR: "./backend/test/end2end"
  NUMBER_OF_PARALLEL_NODES: 10
  CLUSTER_NAME: "kfp"
  NAMESPACE: "kubeflow"
  PYTHON_VERSION: "3.9"
  USER_NAMESPACE: "kubeflow-user-example-com"
  CA_CERT_PATH: ""

on:
  push:
    branches: [master]

  pull_request:
    paths:
      - '.github/workflows/e2e-test.yml'
      - '.github/actions/create-cluster/**'
      - '.github/resources/**'
      - 'api/**'
      - 'go.mod'
      - 'go.sum'
      - 'backend/**'
      - 'proxy/**'
      - 'manifests/kustomize/**'
      - '!**/*.md'
      - '!**/OWNERS'


  workflow_dispatch:
    inputs:
      test_label:
        description: "Test label that you want to filter on and run"
        default: 'ApiServerTests'
        required: true
        type: string
      number_of_parallel_tests:
        description: "Number of ginkgo nodes that you want run in parallel, it essentially is equivalent to number of parallel tests with some caveats"
        default: 10
        required: true
        type: number
      namespace:
        description: "Namespace where you want to create your pipelines in"
        default: "kubeflow"
        required: true
        type: string

jobs:
  build:
    uses: ./.github/workflows/image-builds-with-cache.yml

  end-to-end-critical-scenario-tests:
    runs-on: ubuntu-latest
    needs: build
    strategy:
      matrix:
        k8s_version: ["v1.31.0"]
        cache_enabled: ["true", "false"]
        argo_version: [ "v3.7.3", "v3.6.7", "v3.5.14"]
        storage: [ "seaweedfs", "minio"]
        proxy: [ "false" ]
        test_label: [ "E2ECritical" ]
        pod_to_pod_tls_enabled: [ "false" ]
        include:
          - k8s_version: "v1.29.2"
            cache_enabled: "false"
            argo_version: "v3.5.14"
            test_label: "E2ECritical"
          - k8s_version: "v1.31.0"
            cache_enabled: "false"
            proxy: "true"
            test_label: "E2EProxy"
          - k8s_version: "v1.31.0"
            cache_enabled: "false"
            test_label: "E2EEssential"
          - k8s_version: "v1.31.0"
            cache_enabled: "false"
            test_label: "E2EFailure"
          - k8s_version: "v1.31.0"
            cache_enabled: "true"
            pod_to_pod_tls_enabled: "true"
            test_label: "E2ECritical"
      fail-fast: false
    name: End to End ${{ matrix.test_label}} Tests - K8s ${{ matrix.k8s_version }} cacheEnabled=${{ matrix.cache_enabled }} argoVersion=${{ matrix.argo_version}} proxy=${{ matrix.proxy}} storage=${{ matrix.storage }} pod_to_pod_tls_enabled=${{ matrix.pod_to_pod_tls_enabled }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v5

      - name: Free up disk space
        run: ./.github/resources/scripts/free-disk-space.sh

      - name: Create cluster
        uses: ./.github/actions/create-cluster
        id: create-cluster
        with:
          k8s_version: ${{ matrix.k8s_version }}
          cluster_name: ${{ env.CLUSTER_NAME }}

      - name: Deploy KFP
        uses: ./.github/actions/deploy
        if: ${{ steps.create-cluster.outcome == 'success' }}
        id: deploy
        with:
          cache_enabled: ${{ matrix.cache_enabled }}
          argo_version: ${{ matrix.argo_version }}
          storage_backend: ${{ matrix.storage }}
          pod_to_pod_tls_enabled: ${{ matrix.pod_to_pod_tls_enabled }}
          image_path: ${{ needs.build.outputs.IMAGE_PATH }}
          image_tag: ${{ needs.build.outputs.IMAGE_TAG }}
          image_registry: ${{ needs.build.outputs.IMAGE_REGISTRY }}

      - name: Configure Cluster CA Cert for TLS-Enabled Tests
        shell: bash
        if: ${{ matrix.pod_to_pod_tls_enabled == 'true'}}
        run: |
          kubectl get secret kfp-api-tls-cert -n kubeflow -o jsonpath='{.data.ca\.crt}' | base64 -d > "${{ github.workspace }}/ca.crt"
          echo "CA_CERT_PATH=${{ github.workspace }}/ca.crt" >> "$GITHUB_ENV"
      - name: Configure Input Variables
        shell: bash
        id: configure
        if: ${{ steps.deploy.outcome == 'success' }}
        run: |
          NUMBER_OF_NODES=${{ env.NUMBER_OF_PARALLEL_NODES }}
          TEST_LABEL=${{ matrix.test_label }}
          NAMESPACE=${{ env.NAMESPACE }}
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            NUMBER_OF_NODES=${{ inputs.number_of_parallel_tests }}
            TEST_LABEL=${{ inputs.test_label }}
            NAMESPACE=${{ inputs.namespace }}
          fi
          
          {
            echo "NUMBER_OF_NODES=$NUMBER_OF_NODES"
            echo "TEST_LABEL=$TEST_LABEL"
            echo "NAMESPACE=$NAMESPACE"
          } >> "$GITHUB_OUTPUT"

      - name: Build and upload the sample Modelcar image to Kind
        id: build-sample-modelcar-image
        if: ${{ steps.deploy.outcome == 'success' }}
        run: |
          docker build -f ./test_data/sdk_compiled_pipelines/valid/critical/modelcar/Dockerfile -t registry.domain.local/modelcar:test .
          kind --name kfp load docker-image registry.domain.local/modelcar:test
        continue-on-error: true

      - name: Run Tests
        uses: ./.github/actions/test-and-report
        id: test-run
        if: ${{ steps.configure.outcome == 'success' }}
        with:
          cache_enabled: ${{ matrix.cache_enabled }}
          test_directory: ${{ env.E2E_TESTS_DIR }}
          test_label: ${{ steps.configure.outputs.TEST_LABEL }}
          num_parallel_nodes: ${{ steps.configure.outputs.NUMBER_OF_NODES }}
          default_namespace: ${{ steps.configure.outputs.NAMESPACE }}
          python_version: ${{ env.PYTHON_VERSION }}
          report_name: "${{ matrix.test_label}}Tests_K8s=${{ matrix.k8s_version }}_cacheEnabled=${{ matrix.cache_enabled }}_argoVersion=${{ matrix.argo_version}}_proxy=${{ matrix.proxy }}_storage=${{ matrix.storage }}"
          tls_enabled: ${{ matrix.pod_to_pod_tls_enabled }}
          ca_cert_path: ${{ env.CA_CERT_PATH }}

      - name: Collect Pod logs on test failure
        id: collect-failure-logs
        shell: bash
        if: ${{ always() && steps.test-run.outcome != 'success' && steps.configure.outcome == 'success' }}
        run: |
          echo "=== Collecting enhanced logs after test failure ==="
          NAMESPACE=${{ steps.configure.outputs.NAMESPACE }}
          TEST_START_TIME=$(date -u -d '30 minutes ago' '+%Y-%m-%dT%H:%M:%SZ')
          TEST_CONTEXT="${{ matrix.test_label}}_K8s-${{ matrix.k8s_version }}_cache-${{ matrix.cache_enabled }}"

          # First, immediately capture any pipeline pods that might still exist
          echo "=== IMMEDIATE PIPELINE POD CAPTURE ===" > /tmp/immediate_pod_logs.txt
          echo "Timestamp: $(date)" >> /tmp/immediate_pod_logs.txt
          echo "Searching for pipeline pods immediately after test failure..." >> /tmp/immediate_pod_logs.txt

          # Capture any pipeline/workflow pods that exist right now
          kubectl get pods -n $NAMESPACE | grep -E "(pipeline|workflow|producer|consumer)" >> /tmp/immediate_pod_logs.txt 2>&1 || echo "No pipeline pods found" >> /tmp/immediate_pod_logs.txt

          # Get logs from any pods matching pipeline patterns (broader search)
          for pod in $(kubectl get pods -n $NAMESPACE -o name 2>/dev/null | grep -E "(pipeline|workflow|producer|consumer|dag-driver|system)" | sed 's|pod/||'); do
            echo "--- Immediate Pod Logs: $pod ---" >> /tmp/immediate_pod_logs.txt
            kubectl describe pod "$pod" -n $NAMESPACE >> /tmp/immediate_pod_logs.txt 2>&1 || echo "Failed to describe $pod" >> /tmp/immediate_pod_logs.txt
            kubectl logs "$pod" -n $NAMESPACE --all-containers=true >> /tmp/immediate_pod_logs.txt 2>&1 || echo "No logs for $pod" >> /tmp/immediate_pod_logs.txt
            echo "" >> /tmp/immediate_pod_logs.txt
          done

          # Also capture any failed/pending pods in main namespace
          echo "--- Main namespace failed/pending pods ---" >> /tmp/immediate_pod_logs.txt
          for pod in $(kubectl get pods -n $NAMESPACE --field-selector=status.phase!=Running,status.phase!=Succeeded -o name 2>/dev/null | sed 's|pod/||'); do
            echo "--- FAILED/PENDING Pod: $pod ---" >> /tmp/immediate_pod_logs.txt
            kubectl describe pod "$pod" -n $NAMESPACE >> /tmp/immediate_pod_logs.txt 2>&1 || echo "Failed to describe $pod" >> /tmp/immediate_pod_logs.txt
            kubectl logs "$pod" -n $NAMESPACE --all-containers=true >> /tmp/immediate_pod_logs.txt 2>&1 || echo "No logs for $pod" >> /tmp/immediate_pod_logs.txt
            echo "" >> /tmp/immediate_pod_logs.txt
          done

          # CRITICAL: Immediately capture workflow controller logs for debugging
          echo "=== IMMEDIATE INFRASTRUCTURE LOGS ===" >> /tmp/immediate_pod_logs.txt

          # Workflow Controller - most critical for pipeline execution
          WF_CONTROLLER=$(kubectl get pods -n $NAMESPACE -l app=workflow-controller -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
          if [ -n "$WF_CONTROLLER" ]; then
            echo "--- Workflow Controller: $WF_CONTROLLER (ALL LOGS) ---" >> /tmp/immediate_pod_logs.txt
            kubectl logs "$WF_CONTROLLER" -n $NAMESPACE >> /tmp/immediate_pod_logs.txt 2>&1 || echo "No logs" >> /tmp/immediate_pod_logs.txt
          else
            echo "--- No Workflow Controller found ---" >> /tmp/immediate_pod_logs.txt
          fi

          # Persistence Agent - handles workflow submission
          PERSISTENCE_AGENT=$(kubectl get pods -n $NAMESPACE -l app=ml-pipeline-persistenceagent -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
          if [ -n "$PERSISTENCE_AGENT" ]; then
            echo "--- Persistence Agent: $PERSISTENCE_AGENT (ALL LOGS) ---" >> /tmp/immediate_pod_logs.txt
            kubectl logs "$PERSISTENCE_AGENT" -n $NAMESPACE >> /tmp/immediate_pod_logs.txt 2>&1 || echo "No logs" >> /tmp/immediate_pod_logs.txt
          else
            echo "--- No Persistence Agent found ---" >> /tmp/immediate_pod_logs.txt
          fi

          # Create enhanced log collection
          chmod +x ./.github/resources/scripts/collect-enhanced-logs.sh
          ./.github/resources/scripts/collect-enhanced-logs.sh \
            --ns $NAMESPACE \
            --output /tmp/enhanced_failure_logs.txt \
            --test-context "$TEST_CONTEXT" \
            --start-time "$TEST_START_TIME"

          # Combine immediate logs with enhanced logs
          cat /tmp/immediate_pod_logs.txt >> /tmp/enhanced_failure_logs.txt

          # Also collect Ginkgo test output if available
          if [ -f "${{ env.E2E_TESTS_DIR }}/reports/junit.xml" ]; then
            echo "=== GINKGO TEST RESULTS ===" >> /tmp/enhanced_failure_logs.txt
            cat "${{ env.E2E_TESTS_DIR }}/reports/junit.xml" >> /tmp/enhanced_failure_logs.txt 2>/dev/null || true
          fi
        continue-on-error: true

      - name: Upload Pod logs on test failure
        uses: actions/upload-artifact@v4
        if: ${{ always() && steps.test-run.outcome != 'success' && steps.collect-failure-logs.outcome == 'success' }}
        with:
          name: failure-logs-${{ matrix.test_label}}-K8s-${{ matrix.k8s_version }}-cache-${{ matrix.cache_enabled }}-argo-${{ matrix.argo_version}}-proxy-${{ matrix.proxy }}-storage-${{ matrix.storage }}
          path: /tmp/enhanced_failure_logs.txt
          retention-days: 30
        continue-on-error: true

      - name: Notify test reports
        shell: bash
        if: ${{ steps.test-run.outcome == 'success' }}
        run: |
          echo "::notice title=Test Summary and HTML Report is now available in the Summary Tab"

  end-to-end-critical-scenario-multi-user-tests:
    runs-on: ubuntu-latest
    needs: build
    strategy:
      matrix:
        k8s_version: ["v1.31.0"]
        cache_enabled: ["true", "false"]
        storage: [ "seaweedfs", "minio"]
        multi_user: [ "true" ]
        test_label: [ "E2ECritical" ]
        include:
        - multi_user: "true"
          artifact_proxy: "true"
          storage: "seaweedfs"
          k8s_version: "v1.31.0"
          cache_enabled: "true"
          test_label: "E2ECritical" 
      fail-fast: false
    name: End to End Critical Scenario Multi User Tests - K8s ${{ matrix.k8s_version }} cacheEnabled=${{ matrix.cache_enabled }} multiUser=${{ matrix.multi_user }} storage=${{ matrix.storage }} artifactProxy=${{ matrix.artifact_proxy }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v5

      - name: Free up disk space
        run: ./.github/resources/scripts/free-disk-space.sh

      - name: Create cluster
        uses: ./.github/actions/create-cluster
        id: create-cluster
        with:
          k8s_version: ${{ matrix.k8s_version }}
          cluster_name: ${{ env.CLUSTER_NAME }}

      - name: Deploy KFP
        uses: ./.github/actions/deploy
        if: ${{ steps.create-cluster.outcome == 'success' }}
        id: deploy
        with:
          cache_enabled: ${{ matrix.cache_enabled }}
          multi_user: "true"
          storage_backend: ${{ matrix.storage }}
          artifact_proxy: ${{ matrix.artifact_proxy }}
          image_path: ${{ needs.build.outputs.IMAGE_PATH }}
          image_tag: ${{ needs.build.outputs.IMAGE_TAG }}
          image_registry: ${{ needs.build.outputs.IMAGE_REGISTRY }}

      - name: Configure Input Variables
        shell: bash
        id: configure
        if: ${{ steps.deploy.outcome == 'success' }}
        run: |
          NUMBER_OF_NODES=${{ env.NUMBER_OF_PARALLEL_NODES }}
          TEST_LABEL=${{ matrix.test_label }}
          NAMESPACE=${{ env.NAMESPACE }}
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            NUMBER_OF_NODES=${{ inputs.number_of_parallel_tests }}
            TEST_LABEL=${{ inputs.test_label }}
            NAMESPACE=${{ inputs.namespace }}
          fi
          {
            echo "NUMBER_OF_NODES=$NUMBER_OF_NODES"
            echo "TEST_LABEL=$TEST_LABEL"
            echo "NAMESPACE=$NAMESPACE"
          } >> "$GITHUB_OUTPUT"

      - name: Build and upload the sample Modelcar image to Kind
        id: build-sample-modelcar-image
        if: ${{ steps.deploy.outcome == 'success' }}
        run: |
          docker build -f ./test_data/sdk_compiled_pipelines/valid/critical/modelcar/Dockerfile -t registry.domain.local/modelcar:test .
          kind --name kfp load docker-image registry.domain.local/modelcar:test
        continue-on-error: true

      - name: Test Artifact Proxy
        id: test-artifact-proxy
        if: ${{ steps.deploy.outcome == 'success' && matrix.artifact_proxy == 'true' }}
        shell: bash
        env:
          USER_NAMESPACE: ${{ env.USER_NAMESPACE }}
        run: |
          ./test/artifact-proxy/test-artifact-proxy.sh "$USER_NAMESPACE"

      - name: Run Tests
        uses: ./.github/actions/test-and-report
        if: ${{ steps.configure.outcome == 'success' }}
        id: test-run
        env:
          LOCAL_API_SERVER: "true"
          MULTI_USER: ${{ matrix.multi_user }}
        with:
          multi_user: ${{ matrix.multi_user }}
          cache_enabled: ${{ matrix.cache_enabled }}
          test_directory: ${{ env.E2E_TESTS_DIR }}
          test_label: ${{ steps.configure.outputs.TEST_LABEL }}
          num_parallel_nodes: ${{ steps.configure.outputs.NUMBER_OF_NODES }}
          default_namespace: ${{ steps.configure.outputs.NAMESPACE }}
          python_version: ${{ env.PYTHON_VERSION }}
          user_namespace: ${{ env.USER_NAMESPACE }}
          report_name: "E2EMultiUserTests_K8s=${{ matrix.k8s_version }}_cacheEnabled=${{ matrix.cache_enabled }}_multiUser=${{ matrix.multi_user }}_storage=${{ matrix.storage }}"

      - name: Collect Pod logs on test failure
        id: collect-failure-logs
        shell: bash
        if: ${{ always() && steps.test-run.outcome != 'success' && steps.configure.outcome == 'success' }}
        run: |
          echo "=== Collecting enhanced logs after test failure ==="
          NAMESPACE=${{ steps.configure.outputs.NAMESPACE }}
          USER_NS="${{ env.USER_NAMESPACE }}"
          TEST_START_TIME=$(date -u -d '30 minutes ago' '+%Y-%m-%dT%H:%M:%SZ')
          TEST_CONTEXT="MultiUser_K8s-${{ matrix.k8s_version }}_cache-${{ matrix.cache_enabled }}_storage-${{ matrix.storage }}"

          # First, immediately capture any pipeline pods that might still exist in both namespaces
          echo "=== IMMEDIATE PIPELINE POD CAPTURE ===" > /tmp/immediate_pod_logs.txt
          echo "Timestamp: $(date)" >> /tmp/immediate_pod_logs.txt
          echo "Searching for pipeline pods immediately after test failure..." >> /tmp/immediate_pod_logs.txt

          # Check main namespace
          echo "--- Main namespace ($NAMESPACE) ---" >> /tmp/immediate_pod_logs.txt
          kubectl get pods -n $NAMESPACE | grep -E "(pipeline|workflow|producer|consumer)" >> /tmp/immediate_pod_logs.txt 2>&1 || echo "No pipeline pods found in $NAMESPACE" >> /tmp/immediate_pod_logs.txt

          for pod in $(kubectl get pods -n $NAMESPACE -o name 2>/dev/null | grep -E "(pipeline|workflow|producer|consumer)" | sed 's|pod/||'); do
            echo "--- Immediate Pod Logs ($NAMESPACE): $pod ---" >> /tmp/immediate_pod_logs.txt
            kubectl logs "$pod" -n $NAMESPACE >> /tmp/immediate_pod_logs.txt 2>&1 || echo "No logs for $pod" >> /tmp/immediate_pod_logs.txt
            echo "" >> /tmp/immediate_pod_logs.txt
          done

          # Check user namespace if different
          if [ "$USER_NS" != "$NAMESPACE" ]; then
            echo "--- User namespace ($USER_NS) ALL PODS ---" >> /tmp/immediate_pod_logs.txt
            kubectl get pods -n "$USER_NS" -o wide >> /tmp/immediate_pod_logs.txt 2>&1 || echo "No pods found in $USER_NS" >> /tmp/immediate_pod_logs.txt

            # Look for ALL workflow-related pods with broader patterns
            echo "--- User namespace workflow/execution pods ---" >> /tmp/immediate_pod_logs.txt
            for pod in $(kubectl get pods -n "$USER_NS" -o name 2>/dev/null | grep -E "(pipeline|workflow|producer|consumer|dag-driver|system)" | sed 's|pod/||'); do
              echo "--- Immediate Pod Logs ($USER_NS): $pod ---" >> /tmp/immediate_pod_logs.txt
              kubectl describe pod "$pod" -n "$USER_NS" >> /tmp/immediate_pod_logs.txt 2>&1 || echo "Failed to describe $pod" >> /tmp/immediate_pod_logs.txt
              kubectl logs "$pod" -n "$USER_NS" --all-containers=true >> /tmp/immediate_pod_logs.txt 2>&1 || echo "No logs for $pod" >> /tmp/immediate_pod_logs.txt
              echo "" >> /tmp/immediate_pod_logs.txt
            done

            # Specifically capture failed/pending pods
            echo "--- User namespace failed/pending pods ---" >> /tmp/immediate_pod_logs.txt
            for pod in $(kubectl get pods -n "$USER_NS" --field-selector=status.phase!=Running,status.phase!=Succeeded -o name 2>/dev/null | sed 's|pod/||'); do
              echo "--- FAILED/PENDING Pod ($USER_NS): $pod ---" >> /tmp/immediate_pod_logs.txt
              kubectl describe pod "$pod" -n "$USER_NS" >> /tmp/immediate_pod_logs.txt 2>&1 || echo "Failed to describe $pod" >> /tmp/immediate_pod_logs.txt
              kubectl logs "$pod" -n "$USER_NS" --all-containers=true >> /tmp/immediate_pod_logs.txt 2>&1 || echo "No logs for $pod" >> /tmp/immediate_pod_logs.txt
              echo "" >> /tmp/immediate_pod_logs.txt
            done

            # Capture recent events in user namespace
            echo "--- User namespace recent events ---" >> /tmp/immediate_pod_logs.txt
            kubectl get events -n "$USER_NS" --sort-by='.lastTimestamp' | tail -20 >> /tmp/immediate_pod_logs.txt 2>&1 || echo "No events in $USER_NS" >> /tmp/immediate_pod_logs.txt
          fi

          # CRITICAL: Immediately capture workflow controller logs for debugging
          echo "=== IMMEDIATE INFRASTRUCTURE LOGS ===" >> /tmp/immediate_pod_logs.txt

          # Workflow Controller - most critical for pipeline execution
          WF_CONTROLLER=$(kubectl get pods -n $NAMESPACE -l app=workflow-controller -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
          if [ -n "$WF_CONTROLLER" ]; then
            echo "--- Workflow Controller: $WF_CONTROLLER (ALL LOGS) ---" >> /tmp/immediate_pod_logs.txt
            kubectl logs "$WF_CONTROLLER" -n $NAMESPACE >> /tmp/immediate_pod_logs.txt 2>&1 || echo "No logs" >> /tmp/immediate_pod_logs.txt
          else
            echo "--- No Workflow Controller found ---" >> /tmp/immediate_pod_logs.txt
          fi

          # Persistence Agent - handles workflow submission
          PERSISTENCE_AGENT=$(kubectl get pods -n $NAMESPACE -l app=ml-pipeline-persistenceagent -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
          if [ -n "$PERSISTENCE_AGENT" ]; then
            echo "--- Persistence Agent: $PERSISTENCE_AGENT (ALL LOGS) ---" >> /tmp/immediate_pod_logs.txt
            kubectl logs "$PERSISTENCE_AGENT" -n $NAMESPACE >> /tmp/immediate_pod_logs.txt 2>&1 || echo "No logs" >> /tmp/immediate_pod_logs.txt
          else
            echo "--- No Persistence Agent found ---" >> /tmp/immediate_pod_logs.txt
          fi

          # Create enhanced log collection
          chmod +x ./.github/resources/scripts/collect-enhanced-logs.sh
          ./.github/resources/scripts/collect-enhanced-logs.sh \
            --ns $NAMESPACE \
            --output /tmp/enhanced_failure_logs.txt \
            --test-context "$TEST_CONTEXT" \
            --start-time "$TEST_START_TIME"

          # Also collect user namespace logs for multi-user tests
          if [ "$USER_NS" != "$NAMESPACE" ]; then
            echo "=== USER NAMESPACE LOGS ===" >> /tmp/enhanced_failure_logs.txt
            ./.github/resources/scripts/collect-enhanced-logs.sh \
              --ns "$USER_NS" \
              --output /tmp/user_ns_logs.txt \
              --test-context "$TEST_CONTEXT" \
              --start-time "$TEST_START_TIME"
            cat /tmp/user_ns_logs.txt >> /tmp/enhanced_failure_logs.txt 2>/dev/null || true
          fi

          # Combine immediate logs with enhanced logs
          cat /tmp/immediate_pod_logs.txt >> /tmp/enhanced_failure_logs.txt

          # Also collect Ginkgo test output if available
          if [ -f "${{ env.E2E_TESTS_DIR }}/reports/junit.xml" ]; then
            echo "=== GINKGO TEST RESULTS ===" >> /tmp/enhanced_failure_logs.txt
            cat "${{ env.E2E_TESTS_DIR }}/reports/junit.xml" >> /tmp/enhanced_failure_logs.txt 2>/dev/null || true
          fi
        continue-on-error: true

      - name: Upload Pod logs on test failure
        uses: actions/upload-artifact@v4
        if: ${{ always() && steps.test-run.outcome != 'success' && steps.collect-failure-logs.outcome == 'success' }}
        with:
          name: failure-logs-multiuser-K8s-${{ matrix.k8s_version }}-cache-${{ matrix.cache_enabled }}-storage-${{ matrix.storage }}
          path: /tmp/enhanced_failure_logs.txt
          retention-days: 30
        continue-on-error: true

      - name: Notify test reports
        shell: bash
        if: ${{ steps.test-run.outcome == 'success' }}
        run: |
          echo "::notice title=Test Summary and HTML Report is now available in the Summary Tab"
