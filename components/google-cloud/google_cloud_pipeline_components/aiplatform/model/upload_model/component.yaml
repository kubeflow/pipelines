name: model_upload
description: |
    Uploads a model and returns a Model representing the uploaded Model resource.
    For more details, see https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.models/upload.

    Args:
        project (str):
            Required. Project to upload this model to.
        location (Optional[str]):
            Optional location to upload this model to. If not set,
            default to us-central1.
        display_name (str):
            Required. The display name of the Model. The name can be up to 128
            characters long and can be consist of any UTF-8 characters.
        description (Optional[str]):
            The description of the model.
        serving_container_image_uri (str):
            Required. The URI of the Model serving container.

            For more details, see https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.models#Model.ModelContainerSpec.
        serving_container_command (Optional[Sequence[str]]=None):
            The command with which the container is run. Not executed within a
            shell. The Docker image's ENTRYPOINT is used if this is not provided.
            Variable references $(VAR_NAME) are expanded using the container's
            environment. If a variable cannot be resolved, the reference in the
            input string will be unchanged. The $(VAR_NAME) syntax can be escaped
            with a double $$, ie: $$(VAR_NAME). Escaped references will never be
            expanded, regardless of whether the variable exists or not.

            For more details, see https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.models#Model.ModelContainerSpec.
        serving_container_args (Optional[Sequence[str]]=None):
            The arguments to the command. The Docker image's CMD is used if this is
            not provided. Variable references $(VAR_NAME) are expanded using the
            container's environment. If a variable cannot be resolved, the reference
            in the input string will be unchanged. The $(VAR_NAME) syntax can be
            escaped with a double $$, ie: $$(VAR_NAME). Escaped references will
            never be expanded, regardless of whether the variable exists or not.

            For more details, see https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.models#Model.ModelContainerSpec.
        serving_container_environment_variables (Optional[dict[str, str]]=None):
            The environment variables that are to be present in the container.
            Should be a dictionary where keys are environment variable names
            and values are environment variable values for those names.

            For more details, see https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.models#Model.ModelContainerSpec.
        serving_container_ports (Optional[Sequence[int]]=None):
            Declaration of ports that are exposed by the container. This field is
            primarily informational, it gives Vertex AI information about the
            network connections the container uses. Listing or not a port here has
            no impact on whether the port is actually exposed, any port listening on
            the default "0.0.0.0" address inside a container will be accessible from
            the network.

            For more details, see https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.models#Model.ModelContainerSpec.
        serving_container_predict_route (Optional[str]):
            An HTTP path to send prediction requests to the container, and
            which must be supported by it. If not specified a default HTTP path will
            be used by Vertex AI.

            For more details, see https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.models#Model.ModelContainerSpec.
        serving_container_health_route (Optional[str]):
            An HTTP path to send health check requests to the container, and which
            must be supported by it. If not specified a standard HTTP path will be
            used by Vertex AI.

            For more details, see https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.models#Model.ModelContainerSpec.
        instance_schema_uri (Optional[str]):
            Points to a YAML file stored on Google Cloud
            Storage describing the format of a single instance, which
            are used in
            ``PredictRequest.instances``,
            ``ExplainRequest.instances``
            and
            ``BatchPredictionJob.input_config``.
            The schema is defined as an OpenAPI 3.0.2 `Schema
            Object <https://tinyurl.com/y538mdwt#schema-object>`__.
            AutoML Models always have this field populated by AI
            Platform. Note: The URI given on output will be immutable
            and probably different, including the URI scheme, than the
            one given on input. The output URI will point to a location
            where the user only has a read access.

            For more details on PredictionSchema, see https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.models#predictschemata.
        parameters_schema_uri (Optional[str]):
            Points to a YAML file stored on Google Cloud
            Storage describing the parameters of prediction and
            explanation via
            ``PredictRequest.parameters``,
            ``ExplainRequest.parameters``
            and
            ``BatchPredictionJob.model_parameters``.
            The schema is defined as an OpenAPI 3.0.2 `Schema
            Object <https://tinyurl.com/y538mdwt#schema-object>`__.
            AutoML Models always have this field populated by AI
            Platform, if no parameters are supported it is set to an
            empty string. Note: The URI given on output will be
            immutable and probably different, including the URI scheme,
            than the one given on input. The output URI will point to a
            location where the user only has a read access.

            For more details on PredictionSchema, see https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.models#predictschemata.
        prediction_schema_uri (Optional[str]):
            Points to a YAML file stored on Google Cloud
            Storage describing the format of a single prediction
            produced by this Model, which are returned via
            ``PredictResponse.predictions``,
            ``ExplainResponse.explanations``,
            and
            ``BatchPredictionJob.output_config``.
            The schema is defined as an OpenAPI 3.0.2 `Schema
            Object <https://tinyurl.com/y538mdwt#schema-object>`__.
            AutoML Models always have this field populated by AI
            Platform. Note: The URI given on output will be immutable
            and probably different, including the URI scheme, than the
            one given on input. The output URI will point to a location
            where the user only has a read access.

            For more details on PredictionSchema, see https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.models#predictschemata
        artifact_uri (Optional[str]):
            The path to the directory containing the Model artifact and
            any of its supporting files. Leave blank for custom container prediction.
            Not present for AutoML Models.
        explanation_metadata (Optional[dict]):
            Metadata describing the Model's input and output for explanation.
            Both `explanation_metadata` and `explanation_parameters` must be
            passed together when used.

            For more details, see https://cloud.google.com/vertex-ai/docs/reference/rest/v1/ExplanationSpec#explanationmetadata.
        explanation_parameters (Optional[dict]):
            Parameters to configure explaining for Model's predictions.

            For more details, see https://cloud.google.com/vertex-ai/docs/reference/rest/v1/ExplanationSpec#explanationmetadata.
        encryption_spec_key_name (Optional[str]):
            Customer-managed encryption key spec for a Model.
            If set, this Model and all sub-resources of this Model will
            be secured by this key.

            Has the form:
            ``projects/my-project/locations/my-location/keyRings/my-kr/cryptoKeys/my-key``.
            The key needs to be in the same region as where the compute
            resource is created.
        labels (Optional[dict]):
            The labels with user-defined metadata to organize your model.

            Label keys and values can be no longer than
            64 characters (Unicode codepoints), can only contain lowercase
            letters, numeric characters, underscores and dashes.
            International characters are allowed.

            See https://goo.gl/xmQnxf for more information and examples of labels.
    Returns:
        model (google.VertexModel):
            Artifact tracking the created model.
        gcp_resources (str):
            Serialized gcp_resources proto tracking the upload model's long running operation.

            For more details, see https://github.com/kubeflow/pipelines/blob/master/components/google-cloud/google_cloud_pipeline_components/proto/README.md.
inputs:
- {name: project, type: String}
- {name: location, type: String, default: "us-central1"}
- {name: display_name, type: String}
- {name: description, type: String, optional: true, default: ''}
- {name: serving_container_image_uri, type: String}
- {name: serving_container_command, type: JsonArray, optional: true, default: '[]'}
- {name: serving_container_args, type: JsonArray, optional: true, default: '[]'}
- {name: serving_container_environment_variables, type: JsonArray, optional: true, default: '[]'}
- {name: serving_container_ports, type: JsonArray, optional: true, default: '[]'}
- {name: serving_container_predict_route, type: String, optional: true, default: ''}
- {name: serving_container_health_route, type: String, optional: true, default: ''}
- {name: instance_schema_uri, type: String, optional: true, default: ''}
- {name: parameters_schema_uri, type: String, optional: true, default: ''}
- {name: prediction_schema_uri, type: String, optional: true, default: ''}
- {name: artifact_uri, type: String, optional: true, default: ''}
- {name: explanation_metadata, type: JsonObject, optional: true, default: '{}'}
- {name: explanation_parameters, type: JsonObject, optional: true, default: '{}'}
- {name: encryption_spec_key_name, type: String, optional: true, default: ''}
- {name: labels, type: JsonObject, optional: true, default: '{}'}
outputs:
- {name: model, type: google.VertexModel}
- {name: gcp_resources, type: String}
implementation:
  container:
    image: gcr.io/ml-pipeline/google-cloud-pipeline-components:latest
    command: [python3, -u, -m, google_cloud_pipeline_components.container.experimental.gcp_launcher.launcher]
    args: [
      --type, UploadModel,
      --payload,
      concat: [
          '{',
          '"display_name": "', {inputValue: display_name}, '"',
          ', "description": "', {inputValue: description}, '"',
          ', "predict_schemata": {',
          '"instance_schema_uri": "',{inputValue: instance_schema_uri}, '"',
          ', "parameters_schema_uri": "', {inputValue: parameters_schema_uri}, '"',
          ', "prediction_schema_uri": "', {inputValue: prediction_schema_uri}, '"',
          '}',
          ', "container_spec": {',
          '"image_uri": "', {inputValue: serving_container_image_uri}, '"',
          ', "command": ', {inputValue: serving_container_command},
          ', "args": ', {inputValue: serving_container_args},
          ', "env": ', {inputValue: serving_container_environment_variables},
          ', "ports": ', {inputValue: serving_container_ports},
          ', "predict_route": "', {inputValue: serving_container_predict_route}, '"',
          ', "health_route": "', {inputValue: serving_container_health_route}, '"',
          '}',
          ', "artifact_uri": "', {inputValue: artifact_uri}, '"',
          ', "explanation_spec": {',
          '"parameters": ', {inputValue: explanation_parameters},
          ', "metadata": ', {inputValue: explanation_metadata},
          '}',
          ', "encryption_spec": {"kms_key_name":"', {inputValue: encryption_spec_key_name}, '"}',
          ', "labels": ', {inputValue: labels},
          '}'
      ],
      --project, {inputValue: project},
      --location, {inputValue: location},
      --gcp_resources, {outputPath: gcp_resources},
      --executor_input, "{{$}}",
    ]
