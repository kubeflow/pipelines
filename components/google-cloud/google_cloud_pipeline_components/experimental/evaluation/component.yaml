name: model_evaluation
description: |
    Compute evaluation metrics on a trained model's batch prediction results.
    Creates a dataflow job to compute the metrics.

    Args:
        project (str):
            Project to run evaluation container.
        location (Optional[str]):
            Location for running the evaluation. If not set, defaulted to `us-central1`.
        root_dir (str):
            The GCS directory for keeping staging files.
            A random subdirectory will be created under the directory to keep job info for resuming
            the job in case of failure.
        problem_type (str):
            The problem type being addressed by this evaluation run.
            `classification` and `regression` are the currently supported problem types.
        predictions_format (Optional[str]):
            The file format for the batch prediction results. `jsonl` is currently the only allowed
            format currently.
            If not set, default to `jsonl`.
        batch_prediction_job (google.VertexBatchPredictionJob):
            The VertexBatchPredictionJob with prediction or explanation results for this evaluation
            run.
            For prediction results, the files should be in format "prediction.results-*".
            For explanation results, the files should be in format "explanation.results-*".
        classification_type (str):
            Required for a `classification` problem_type. The type of classification problem.
            Defined as `multiclass` or `multilabel`.
        class_names (Sequence[str]):
            The list of class names, in the same order they appear in the batch predictions column.
        ground_truth_column (str):
            The column name of the feature containing ground truth.
            Formatted to be able to find nested columns, delimeted by `.`.
            Prefixed with 'instance.' for Vertex Batch Prediction.
        prediction_score_column (str):
            The column name of the field containing batch prediction scores.
            Formatted to be able to find nested columns, delimeted by `.`.
        prediction_label_column (Optional[str]):
            Optional. The column name of the field containing classes the model is scoring.
            Formatted to be able to find nested columns, delimeted by `.`.
        prediction_id_column (Optional[str]):
            Optional. The column name of the field containing ids for classes the model is scoring.
            Formatted to be able to find nested columns, delimeted by `.`.
        example_weight_column (Optional[str]):
            Optional. The column name of the field containing example weights.
            Formatted to be able to find nested columns, delimeted by `.`.
        positive_classes (Optional[Sequence[str]]):
            Optional for `classification` problem_type.
            The list of class names to create binary classification metrics based on one-vs-rest for
            Each value of positive_classes provided.
        generate_feature_attribution (Optional[bool]):
            Optional. Set to False by default.
            If set to True, then the explanations generated by the VertexBatchPredictionJob will be
            used to generate feature attributions. This will only pass if the input
            VertexBatchPredictionJob generated explanations.
        dataflow_service_account (Optional[str]):
            Service account to run the dataflow job.
        dataflow_disk_size (Optional[int]):
            The disk size (in GB) of the machine executing the evaluation run.
            If not set, defaulted to `200`.
        dataflow_machine_type (Optional[str]):
            The machine type executing the evaluation run.
            If not set, defaulted to `n1-standard-4`.
        dataflow_workers_num (Optional[int]):
            The number of workers executing the evaluation run.
            If not set, defaulted to `10`.
        dataflow_max_workers_num (Optional[int]):
            The max number of workers executing the evaluation run.
            If not set, defaulted to `100`.

    Returns:
        evaluation_metrics (system.Metrics):
            System metrics artifact representing the evaluation metrics in GCS.
            WIP to update to a google.VertexMetrics type with additional functionality.
inputs:
- {name: project, type: String}
- {name: location, type: String, default: "us-central1"}
- {name: root_dir, type: String}
- {name: problem_type, type: String}
- {name: predictions_format, type: String, default: 'jsonl'}
- {name: batch_prediction_job, type: google.VertexBatchPredictionJob}
- {name: classification_type, type: String, optional: true}
- {name: class_names, type: JsonArray}
- {name: ground_truth_column, type: String}
- {name: prediction_score_column, type: String, default: 'prediction.scores'}
- {name: prediction_label_column, type: String, optional: true, default: 'prediction.classes'}
- {name: prediction_id_column, type: String, optional: true, default: ''}
- {name: example_weight_column, type: String, optional: true, default: ''}
- {name: positive_classes, type: JsonArray, optional: true, default: '{}'}
- {name: generate_feature_attribution, type: Boolean, optional: true, default: False}
- {name: dataflow_service_account, type: String, optional: true}
- {name: dataflow_disk_size, type: Integer, default: 200}
- {name: dataflow_machine_type, type: String, default: 'n1-standard-4'}
- {name: dataflow_workers_num, type: Integer, default: '10'}
- {name: dataflow_max_workers_num, type: Integer, default: '100'}
outputs:
- {name: evaluation_metrics, type: Metrics}
implementation:
  container:
    image: gcr.io/ml-pipeline/model-evaluation:v0.1
    command:
    - python
    - /main.py
    args:
    - --setup_file
    - /setup.py
    - --json_mode
    - 'true'
    - --project_id
    - {inputValue: project}
    - --location
    - {inputValue: location}
    - --problem_type
    - {inputValue: problem_type}
    - --batch_prediction_format
    - {inputValue: predictions_format}
    - --batch_prediction_gcs_source
    - "{{$.inputs.artifacts['batch_prediction_job'].metadata['gcsOutputDirectory']}}"
    - --root_dir
    - "{{$.inputs.parameters['root_dir']}}/{{$.pipeline_job_uuid}}-{{$.pipeline_task_uuid}}"
    - --classification_type
    - {inputValue: classification_type}
    - --class_names
    - {inputValue: class_names}
    - --ground_truth_column
    - "instance.{{$.inputs.parameters['ground_truth_column']}}"
    - --prediction_score_column
    - {inputValue: prediction_score_column}
    - --prediction_label_column
    - {inputValue: prediction_label_column}
    - --prediction_id_column
    - {inputValue: prediction_id_column}
    - --example_weight_column
    - {inputValue: example_weight_column}
    - --positive_classes
    - {inputValue: positive_classes}
    - --generate_feature_attribution
    - {inputValue: generate_feature_attribution}
    - --dataflow_job_prefix
    - 'evaluation-{{$.pipeline_job_uuid}}-{{$.pipeline_task_uuid}}'
    - if:
        cond: {isPresent: dataflow_service_account}
        then:
        - --dataflow_service_account
        - {inputValue: dataflow_service_account}
    - --dataflow_disk_size
    - {inputValue: dataflow_disk_size}
    - --dataflow_machine_type
    - {inputValue: dataflow_machine_type}
    - --dataflow_workers_num
    - {inputValue: dataflow_workers_num}
    - --dataflow_max_workers_num
    - {inputValue: dataflow_max_workers_num}
    - --output_metrics_gcs_path
    - {outputUri: evaluation_metrics}
    - --executor_input
    - "{{$}}"
