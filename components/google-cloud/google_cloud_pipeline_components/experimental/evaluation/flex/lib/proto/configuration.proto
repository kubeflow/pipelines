syntax = "proto3";

// Configuration necessary to compute model predictions from an evaluation
// dataset. Evaluation dataset must contain ground truth and model's
// predictions, and can also contain weights for each evaluated example.
// Example configuration for a multilabel classification problem:
//
// name: "eval_run1"
// data_source {
//   gcs_source {
//     format: JSONL
//     files: "gs://my_bucket/input/file1.jsonl"
//     files: "gs://my_bucket/input/file2.jsonl"
//   }
// }
// problem {
//   classification {
//     ground_truth = "labels"
//     predictions = "scores"
//     class_names = "class0"
//     class_names = "class1"
//     class_names = "class2"
//     type = MULTILABEL
//     evaluation_options {
//       decision_threshold: 0.65
//     }
//   }
// }
// output {
//   gcs_sink {
//     path = "gs://my_bucket/eval_output"
//   }
// }
// execution {
//   local_beam {
//     num_workers: 2
//   }
// }

message EvaluationRunConfig {
  // Name of this evaluation run.
  string name = 1;

  // Specification for the source of the evaluation dataset.
  DataSource data_source = 2;

  // Specification for the evaluation task being addressed by this run.
  ProblemSpec problem = 3;

  // Specification for the location of the computed evaluation metrics.
  OutputSpec output = 4;

  // Specification for running evaluation Pipeline.
  ExecutionSpec execution = 6;

  reserved 5;
}

message DataSource {
  // Parameters necessary to read dataset from GCS.
  GcsSource gcs_source = 1;
}

message GcsSource {
  enum Format {
    UNKNOWN = 0;
    JSONL = 1;
  }
  // Format of the files containing evaluation dataset.
  Format format = 1;

  // Full names of files containing evaluation dataset.
  // Example: gs://my/input/folder/file1.jsonl or
  // gs://my_bucket/sub_folder/prediction.results-*-of-*
  repeated string files = 2;
}

message ProblemSpec {
  oneof problems {
    // Specifications necessary for evaluating a classification problem.
    ClassificationProblemSpec classification = 1;

    // Specifications necessary for evaluating a regression problem.
    RegressionProblemSpec regression = 2;

    // Specifications necessary for evaluating a time series forecasting
    // problem.
    ForecastingProblemSpec forecasting = 3;
  }
}

// Example of the dataset for a multilabel classification problem in JSONL
// format:
// {"label": ["class0", "class1"], "scores": [0.6, 0.5, 0.1]}
// {"label": ["class2"], "scores": [0.2, 0.7, 0.5]}
// NEXT ID: 12
message ClassificationProblemSpec {
  // The list of class names, in the same order they appear in predictions
  // column.
  // In the example above, class_names would be set to the list
  // ["class0", "class1", "class2"]. For the first line in the dataset, the
  // score of "class0" is 0.6, "class1" is 0.5 and "class2" is 0.1.
  repeated string class_names = 3;

  // Column spec of the feature containing ground truth.
  // In the example above, ground_truth_key_spec is a
  // ColumnSpec 'name: "label".'
  ColumnSpec ground_truth_column_spec = 7;

  // Next three fields describe classification model predictions
  // An example of prediction dictionary:
  // {
  //   "classes": ["class1", "class2"],
  //   "scores": [0.3, 0.7],
  //   "class_ids": [0, 1]
  // }

  // Column spec for the field containing model scores. In the example above it
  // is ColumnSpec 'name: "scores"'.
  ColumnSpec prediction_score_column_spec = 8;

  // Optional. Column spec for the field containing classes the model is
  // scoring. In the example above it is ColumnSpec 'name: "classes"'.
  ColumnSpec prediction_label_column_spec = 9;

  // Optional. Column spec for the field containing ids for classes the model is
  // scoring. In the example above it is ColumnSpec 'name: "class_ids"'.
  ColumnSpec prediction_id_column_spec = 10;

  // Optional. Column spec of the column containing example weights.
  ColumnSpec example_weight_column_spec = 11;

  enum ClassificationType {
    UNKNOWN = 0;
    MULTICLASS = 1;
    MULTILABEL = 2;
  }
  // Type of the classification problem: multiclass or multilabel.
  ClassificationType type = 5;

  message EvaluationOptions {
    // An example is considered to be classified as a member of a certain class
    // if that class has score greater than this value.
    float decision_threshold = 1;

    // Creates binary classification metrics based on the top k predicted values
    // for each value of top_k provided. For example, if top_k_list = [3] we
    // will compute metrics based on whether the correct label is present
    // within the predictions with 3 largest scores.
    repeated int32 top_k_list = 2;

    // Creates binary classification metrics based on one-vs-rest for each
    // value of positive_class provided.
    repeated string positive_classes = 3;
  }

  // Customization options for classification metrics.
  EvaluationOptions evaluation_options = 6;

  reserved 1, 2, 4;
}

// Example of the dataset for a regression problem in JSONL format:
// {"age": [32.0], "estimate": [39.4], "importance": 0.3}
// {"age": [59.0], "estimate": [43.1], "importance": 0.8}
message RegressionProblemSpec {
  // Column spec of the feature containing ground truth.
  // In the example above, ground_truth_key_spec is a
  // ColumnSpec 'name: "age"'.
  ColumnSpec ground_truth_column_spec = 4;

  // Column spec for the field containing model scores. In this example, it
  // is ColumnSpec 'name: "estimate"'.
  ColumnSpec prediction_score_column_spec = 5;

  // Column spec of the column containing example weights.
  // In the example above, example_weight is a ColumnSpec
  // 'name: "importance"'.
  ColumnSpec example_weight_column_spec = 6;

  reserved 1, 2, 3;
}

// Example of the dataset for a quantile forecasting problem in JSONL format:
// {"price": [32.0], "estimate": [39.0, 41.0, 54.0], "weight": 0.3}
// {"price": [59.0], "estimate": [43.0, 45.0, 66.0], "weight": 0.8}
//
// Example of the dataset for a point forecasting problem in JSONL format:
// {"price": [32.0], "estimate": [41.0], "weight": 0.3}
// {"price": [59.0], "estimate": [45.0], "weight": 0.8}
message ForecastingProblemSpec {
  reserved 6;
  // Column spec of the feature containing ground truth.
  // In the example above, ground_truth_column_spec is a
  // ColumnSpec 'name: "price"'.
  ColumnSpec ground_truth_column_spec = 1;

  // Column spec for the field containing point or quantile predictions.
  // In this example, it is ColumnSpec 'name: "estimate"'.
  ColumnSpec prediction_score_column_spec = 2;

  // Column spec of the column containing example weights.
  // In the example above, example_weight is a ColumnSpec
  // 'name: "weight"'.
  ColumnSpec example_weight_column_spec = 3;

  enum ForecastingType {
    UNKNOWN = 0;
    POINT = 1;
    QUANTILE = 2;
  }
  // Type of the forecasting problem: point or quantile forecasting.
  ForecastingType type = 4;

  // The list of quantiles in the same order they appear in quantile
  // prediction score column. Required if type is QUANTILE.
  // For example, when quantiles is [0.25, 0.5, 0.75], the first line in the
  // dataset means 39.0 is the forecast of 25% quantile, 41.0 is 50% quantile,
  // and 54.0 is 75% quantile.
  repeated float quantiles = 5;

  message ForecastingEvaluationOptions {
    // Create point accuracy metrics based on the prediction value for the
    // quantile that is equal to quantiles[point_evaluation_quantile_index].
    // Only applicable if type is QUANTILE.
    bool enable_point_evaluation = 1;

    // Only applicable if enable_point_evaluation is true.
    // point_evaluation_quantile_index must be a valid index in quantiles.
    // For example, if quantiles = [0.25, 0.5, 0.75] and
    // point_evaluation_quantile_index = 1, in addition to the quantile
    // accurary metrics, we will also create traditional point accuracy
    // metrics using the 50%-ile prediction score.
    int32 point_evaluation_quantile_index = 2;
  }

  // Customization options for forecasting metrics.
  ForecastingEvaluationOptions options = 7;
}

message ColumnSpec {
  // Spec identifying a column value in a JSON
  // dictionary. For example, given JSON dictionary
  // {"car": {"make": "Ariel"}}, the ColumnSpec identifying name
  // of a car will be
  // '
  //   name: "car"
  //   sub_column_spec {
  //     name: "make"
  //   }
  // '

  // Name of the column.
  string name = 1;

  // Spec for a subcolumn, if any.
  ColumnSpec sub_column_spec = 2;
}

message OutputSpec {
  // Specification for the GCS location where to store computed evaluation
  // metrics.
  GcsSink gcs_sink = 1;
}

message GcsSink {
  // GCS folder where to store computed evaluation metrics.
  // Example: gs://my/output/folder
  string path = 1;
}

message EnvironmentSpec {
  // Project ID to use for the run of the Dataflow job computing the metrics.
  string project_id = 1;

  // Service account to use for the run of the Dataflow job computing the
  // metrics.
  string service_account = 2;
}

message ExecutionSpec {
  // Specification for execution on Dataflow.
  oneof spec {
    DataflowBeam dataflow_beam = 1;
    LocalBeam local_beam = 2;
  }
}

// Specification for remote execution.
message DataflowBeam {
  // Prefix for the Dataflow job name. The full name is formed by
  // concatenating this prefix with the name specified in the
  // EvaluationConfig.
  string dataflow_job_prefix = 1;

  // Which project to use to run Dataflow Job. For example,
  // "some-project".
  string project_id = 2;

  // Which service account to use for running a Dataflow job. For example,
  // "someone@some-project.iam.gserviceaccount.com".
  string service_account = 3;

  // Staging directory for the Dataflow job. For example,
  // "gs://my_bucket/some_folder/staging".
  string dataflow_staging_dir = 4;

  // Temporary directory for the Dataflow job. For example,
  // "gs://my_bucket/some_folder/temp".
  string dataflow_temp_dir = 5;

  // Path to the setup.py file to use when launching the Dataflow job. For
  // example, "gs://my_bucket/some_folder/setup.py".
  string setup_file = 6;

  // Initial number of workers. For example, 2.
  int32 num_workers = 7;

  // Maximum number of workers. For example, 5.
  int32 max_num_workers = 8;

  // Region where the Dataflow job should be executed, for example,
  // "us-central1". Leave unset to use default region.
  string region = 9;

  // Machine type of workers.
  string machine_type = 10;
}

// Specification for local execution.
message LocalBeam {
  // Number of workers. For example, 2.
  int32 num_workers = 1;
}
