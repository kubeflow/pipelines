# Copyright 2021 The Kubeflow Authors
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

name: dataflow_python
description: |
  Launch a self-executing beam python file on Google Cloud using the DataflowRunner.

    Args:
        project (str):
            Required. Project to create the Dataflow job in.
        location (Optional[str]):
            Location for creating the Dataflow job. If not set,
            default to us-central1.
        python_module_path (str):
            The GCS path to the python file to run.
        temp_location (str):
            A GCS path for Dataflow to stage temporary job files created
            during the execution of the pipeline.
        requirements_file_path (Optional[str]):
            The GCS path to the pip requirements file.
        args(Optional[List[str]]):
            The list of args to pass to the python file. Can include additional parameters
            for the beam runner.
    Returns:
        gcp_resources (str):
            Serialized gcp_resources proto tracking the Dataflow job.
            For more details, see https://github.com/kubeflow/pipelines/blob/master/components/google-cloud/google_cloud_pipeline_components/proto/README.md.
inputs:
- {name: project, type: String}
- {name: location, type: String, default: "us-central1"}
- {name: python_module_path, type: String}
- {name: temp_location, type: String}
- {name: requirements_file_path, type: String, optional: true, default: ""}
- {name: args, type: JsonArray, optional: true, default: "[]"}
outputs:
- {name: gcp_resources, type: String}
implementation:
  container:
    image: gcr.io/ml-pipeline/google-cloud-pipeline-components:latest
    command: [python3, -u, -m, google_cloud_pipeline_components.container.experimental.dataflow.dataflow_launcher]
    args: [
      --project, {inputValue: project},
      --location, {inputValue: location},
      --python_module_path, {inputValue: python_module_path},
      --temp_location, {inputValue: temp_location},
      --requirements_file_path, {inputValue: requirements_file_path},
      --args, {inputValue: args},
      --gcp_resources, {outputPath: gcp_resources},
    ]
