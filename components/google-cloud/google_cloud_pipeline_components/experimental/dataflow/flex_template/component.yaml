name: dataflow_flex_template
description: |
 Launch a Dataflow Flex Template job.
   Args:
       project (str):
           Required. The ID of the Cloud Platform project that the job
           belongs to.
       location (Optional[str]):
           The regional endpoint to which to direct the request.
           E.g., us-central1, us-west1. Defaults to `us-central1` if not set.
       job_name (Optional[str]):
           The job name to use for the created job. For update job
           requests, the job name should be the same as the existing running
           job. If none is specified, a default name will be generated by the
           component.
       container_spec_gcs_path (str]):
           Cloud Storage path to a file with json serialized ContainerSpec as
           content.
       parameters (Optional[Dict[str, str]]):
           The parameters for the flex template. Ex. {"my_template_param":"5"}
       launch_options (Optional[Dict[str, str]]):
           Launch options for this flex template job. This is a common set of
           options across languages and templates. This should not be used to
           pass job parameters.
       num_workers (Optional[int]):
           The initial number of Google Compute Engine instances for the job.
           If empty or unspecified, the Dataflow service determines an appropriate
           number of workers.
       max_workers (Optional[int]):
           The maximum number of Google Compute Engine instances to be made
           available to your pipeline during execution, from 1 to 1000. If
           empty or unspecified, the Dataflow service determines a default maximum
           number of instances. For more details, see https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#horizontal-autoscaling.
       service_account_email (Optional[str]):
           The email address of the service account to run the job as. If
           unspecified, the Dataflow service uses the project's Compute Engine
           default service account.
       temp_location (Optional[str]):
           The Cloud Storage path to use for temporary files. Must be a valid
           Cloud Storage URL, beginning with gs://.
           For more details, see https://cloud.google.com/dataflow/docs/guides/setting-pipeline-options.
       machine_type (Optional[str]):
           The machine type to use for the flex template job. Defaults to the value from
           the template if not specified.
       additional_experiments (Optional[Sequence]):
           Additional experiment flags for the job.
       network (Optional[str]):
           Network to which VMs will be assigned. If empty or unspecified,
           the service will use the network "default".
       subnetwork (Optional[str]):
           Subnetwork to which VMs will be assigned, if desired. You can
           specify a subnetwork using either a complete URL or an abbreviated
           path.

           Expected to be of the form "https://www.googleapis.com/compute/v1/projects/HOST_PROJECT_ID/regions/REGION/subnetworks/SUBNETWORK"
           or "regions/REGION/subnetworks/SUBNETWORK". If the subnetwork is
           located in a Shared VPC network, you must use the complete URL.
       additional_user_labels (Optional[Dict[str, str]]):
           Additional user labels to be specified for the job. Keys and values must follow the restrictions specified in the labeling restrictions page.
           An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1kg", "count": "3" }.
       kms_key_name (Optional[str]):
           Name for the Cloud KMS key for the job. Key format is:
           projects//locations//keyRings//cryptoKeys/
       ip_configuration (Optional[str]):
           Configuration for VM IPs.
       worker_region (Optional[str]):
           The Compute Engine region (https://cloud.google.com/compute/docs/regions-zones/regions-zones)
           in which worker processing should occur, e.g. "us-west1". Mutually
           exclusive with workerZone. If neither workerRegion nor workerZone
           is specified, default to the control plane's region.
       worker_zone (Optional[str]):
           The Compute Engine zone (https://cloud.google.com/compute/docs/regions-zones/regions-zones)
           in which worker processing should occur, e.g. "us-west1-a".
           Mutually exclusive with workerRegion. If neither workerRegion nor
           workerZone is specified, a zone in the control plane's region is
           chosen based on available capacity. If both workerZone and zone
           are set, workerZone takes precedence.
       enable_streaming_engine (Optional[bool]):
           Whether to enable Streaming Engine for the job.
       flexrs_goal (Optional[str]):
           Set FlexRS goal for the job. https://cloud.google.com/dataflow/docs/guides/flexrs
       staging_location (Optional[str]):
           The Cloud Storage path for staging local files. Must be a valid
           Cloud Storage URL, beginning with gs://.
           For more details, see https://cloud.google.com/dataflow/docs/guides/setting-pipeline-options.
       sdk_container_image (Optional[str]):
           Docker registry location (e.g. Artifact Registry) of the container image
           to use for the 'worker
           harness. Default is the container for the version of the SDK. Note
           this field is only valid for portable Dataflow pipeline jobss.
       disk_size_gb (Optional[int]):
           Worker disk size, in gigabytes. If empty or unspecified, the Dataflow
           service determines an appropriate disk size.
       autoscaling_algorithm (Optional[str]):
           The algorithm to use for autoscaling. If empty or unspecified, the
           Dataflow service sets a default value. For more details, see       https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#horizontal-autoscaling.
       dump_heap_on_oom (Optional[bool]):
           If true, when processing time is spent almost entirely on garbage
           collection (GC), saves a heap dump before ending the thread or
           process. If false, ends the thread or process without saving a
           heap dump. Does not save a heap dump when the Java Virtual Machine
           (JVM) has an out of memory error during processing. The location
           of the heap file is either echoed back to the user, or the user is
           given the opportunity to download the heap file.
       save_heap_dumps_to_gcs_path (Optional[str]):
           Cloud Storage bucket (directory) to upload heap dumps to. Enabling
           this field implies that dumpHeapOnOom is set to true.
       launcher_machine_type (Optional[str]):
           The machine type to use for launching the job. The default is
           n1-standard-1.
       enable_launcher_vm_serial_port_logging (Optional[bool]):
           If true serial port logging will be enabled for the launcher VM.
       update (Optional[bool]):
           Set this to true if you are sending a request to update a running
           streaming job. When set, the job name should be the same as the
           running job.
       transform_name_mappings (Optional[Dict[str, str]]):
           Use this to pass transformNameMappings for streaming update jobs.
           Ex:{"oldTransformName":"newTransformName",...}'
       validate_only (Optional[bool]):
           If true, the request is validated but not actually executed. Defaults to false.

   Returns:
       gcp_resources (str):
           Serialized gcp_resources proto tracking the Dataflow job.
           For more details, see https://github.com/kubeflow/pipelines/blob/master/components/google-cloud/google_cloud_pipeline_components/proto/README.md.

inputs:
- {name: project, type: String}
- {name: location, type: String, default: 'us-central1'}
- {name: job_name, type: String, optional: true, default: ''}
- {name: container_spec_gcs_path, type: String}
- {name: parameters, type: JsonObject, optional: true, default: '{}'}
- {name: launch_options, type: JsonObject, optional: true, default: '{}'}
- {name: num_workers, type: Integer, optional: true, default: 1}
- {name: max_workers, type: Integer, optional: true, default: 1000}
- {name: service_account_email, type: String, optional: true, default: ''}
- {name: temp_location, type: String, optional: true, default: ''}
- {name: machine_type, type: String, optional: true, default: ''}
- {name: additional_experiments, type: JsonArray, optional: true, default: '[]'}
- {name: network, type: String, optional: true, default: ''}
- {name: subnetwork, type: String, optional: true, default: ''}
- {name: additional_user_labels, type: JsonObject, optional: true, default: '{}'}
- {name: kms_key_name, type: String, optional: true, default: ''}
- {name: ip_configuration, type: String, optional: true, default: ''}
- {name: worker_region, type: String, optional: true, default: ''}
- {name: worker_zone, type: String, optional: true, default: ''}
- {name: enable_streaming_engine, type: Boolean, optional: true, default: False}
- {name: flexrs_goal, type: String, optional: true, default: ''}
- {name: staging_location, type: String, optional: true, default: ''}
- {name: sdk_container_image, type: String, optional: true, default: ''}
- {name: disk_size_gb, type: Integer, optional: true, default: 0}
- {name: autoscaling_algorithm, type: String, optional: true, default: ''}
- {name: dump_heap_on_oom, type: Boolean, optional: true, default: False}
- {name: save_heap_dumps_to_gcs_path, type: String, optional: true, default: ''}
- {name: launcher_machine_type, type: String, optional: true, default: ''}
- {name: enable_launcher_vm_serial_port_logging, type: Boolean, optional: true, default: False}
- {name: update, type: Boolean, optional: true, default: False}
- {name: transform_name_mappings, type: JsonObject, optional: true, default: '{}'}
- {name: validate_only, type: Boolean, optional: true, default: False}
outputs:
- {name: gcp_resources, type: String}
implementation:
  container:
    image: gcr.io/ml-pipeline/google-cloud-pipeline-components:latest
    command: [python3, -u, -m, google_cloud_pipeline_components.container.experimental.dataflow.flex_template.launcher]
    args: [
      --type, DataflowJob,
      --project, {inputValue: project},
      --location, {inputValue: location},
      --payload,
      concat: [
          '{',
            '"launch_parameter": {',
              '"job_name": "', {inputValue: job_name}, '"',
              ', "container_spec_gcs_path": "', {inputValue: container_spec_gcs_path}, '"',
              ', "parameters": ', {inputValue: parameters},
              ', "launch_options": ', {inputValue: launch_options},
              ', "environment": {',
                '"num_workers": ', {inputValue: num_workers},
                ', "max_workers": ', {inputValue: max_workers},
                ', "service_account_email": "', {inputValue: service_account_email}, '"',
                ', "temp_location": "', {inputValue: temp_location}, '"',
                ', "machine_type": "', {inputValue: machine_type}, '"',
                ', "additional_experiments": ', {inputValue: additional_experiments},
                ', "network": "', {inputValue: network}, '"',
                ', "subnetwork": "', {inputValue: subnetwork}, '"',
                ', "additional_user_labels": ', {inputValue: additional_user_labels},
                ', "kms_key_name": "', {inputValue: kms_key_name}, '"',
                ', "ip_configuration": "', {inputValue: ip_configuration}, '"',
                ', "worker_region": "', {inputValue: worker_region}, '"',
                ', "worker_zone": "', {inputValue: worker_zone}, '"',
                ', "enable_streaming_engine": ', {inputValue: enable_streaming_engine},
                ', "flexrs_goal": "', {inputValue: flexrs_goal}, '"',
                ', "staging_location": "', {inputValue: staging_location}, '"',
                ', "sdk_container_image": "', {inputValue: sdk_container_image}, '"',
                ', "disk_size_gb": ', {inputValue: disk_size_gb},
                ', "autoscaling_algorithm": "', {inputValue: autoscaling_algorithm}, '"',
                ', "dump_heap_on_oom": ', {inputValue: dump_heap_on_oom},
                ', "save_heap_dumps_to_gcs_path": "', {inputValue: save_heap_dumps_to_gcs_path}, '"',
                ', "launcher_machine_type": "', {inputValue: launcher_machine_type}, '"',
                ', "enable_launcher_vm_serial_port_logging": ', {inputValue: enable_launcher_vm_serial_port_logging},
              '}',
              ', "update": ', {inputValue: update},
              ', "transform_name_mappings": ', {inputValue: transform_name_mappings},
            '}',
            ', "validate_only": ', {inputValue: validate_only},
          '}'
        ],
      --gcp_resources, {outputPath: gcp_resources},
    ]
