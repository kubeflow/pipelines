# PIPELINE DEFINITION
# Name: automl-tabular-xgboost-trainer
# Description: The XGBoost training pipeline.
# Inputs:
#    base_score: float [Default: 0.5]
#    bigquery_staging_full_dataset_id: str [Default: '']
#    booster: str [Default: 'gbtree']
#    colsample_bylevel: float [Default: 1.0]
#    colsample_bynode: float [Default: 1.0]
#    colsample_bytree: float [Default: 1.0]
#    data_source_bigquery_table_path: str [Default: '']
#    data_source_csv_filenames: str [Default: '']
#    dataflow_service_account: str [Default: '']
#    dataflow_subnetwork: str [Default: '']
#    dataflow_use_public_ips: bool [Default: True]
#    dataset_level_custom_transformation_definitions: list
#    dataset_level_transformations: list
#    disable_default_eval_metric: int [Default: 0.0]
#    early_stopping_rounds: int [Default: -1.0]
#    encryption_spec_key_name: str [Default: '']
#    eta: float [Default: 0.3]
#    eval_metric: str [Default: '']
#    evaluation_batch_predict_machine_type: str [Default: 'n1-highmem-8']
#    evaluation_batch_predict_max_replica_count: int [Default: 20.0]
#    evaluation_batch_predict_starting_replica_count: int [Default: 20.0]
#    evaluation_dataflow_disk_size_gb: int [Default: 50.0]
#    evaluation_dataflow_machine_type: str [Default: 'n1-standard-4']
#    evaluation_dataflow_max_num_workers: int [Default: 100.0]
#    evaluation_dataflow_starting_num_workers: int [Default: 10.0]
#    feature_selection_algorithm: str [Default: 'AMI']
#    feature_selector: str [Default: 'cyclic']
#    gamma: float [Default: 0.0]
#    grow_policy: str [Default: 'depthwise']
#    huber_slope: float [Default: 1.0]
#    interaction_constraints: str [Default: '']
#    location: str
#    max_bin: int [Default: 256.0]
#    max_cat_to_onehot: int [Default: -1.0]
#    max_delta_step: float [Default: 0.0]
#    max_depth: int [Default: 6.0]
#    max_leaves: int [Default: 0.0]
#    max_selected_features: int [Default: -1.0]
#    min_child_weight: float [Default: 1.0]
#    monotone_constraints: str [Default: '']
#    normalize_type: str [Default: 'tree']
#    num_boost_round: int [Default: 10.0]
#    num_parallel_tree: int [Default: 1.0]
#    objective: str
#    one_drop: int [Default: 0.0]
#    predefined_split_key: str [Default: '']
#    process_type: str [Default: 'default']
#    project: str
#    rate_drop: float [Default: 0.0]
#    refresh_leaf: int [Default: 1.0]
#    reg_alpha: float [Default: 0.0]
#    reg_lambda: float [Default: 1.0]
#    root_dir: str
#    run_evaluation: bool [Default: True]
#    run_feature_selection: bool [Default: False]
#    sample_type: str [Default: 'uniform']
#    sampling_method: str [Default: 'uniform']
#    scale_pos_weight: float [Default: 1.0]
#    seed: int [Default: 0.0]
#    seed_per_iteration: bool [Default: False]
#    skip_drop: float [Default: 0.0]
#    stratified_split_key: str [Default: '']
#    subsample: float [Default: 1.0]
#    target_column: str
#    test_fraction: float [Default: -1.0]
#    tf_auto_transform_features: dict
#    tf_custom_transformation_definitions: list
#    tf_transformations_path: str [Default: '']
#    top_k: int [Default: 0.0]
#    training_accelerator_count: int [Default: 0.0]
#    training_accelerator_type: str [Default: '']
#    training_fraction: float [Default: -1.0]
#    training_machine_type: str [Default: 'c2-standard-16']
#    training_total_replica_count: int [Default: 1.0]
#    transform_dataflow_disk_size_gb: int [Default: 40.0]
#    transform_dataflow_machine_type: str [Default: 'n1-standard-16']
#    transform_dataflow_max_num_workers: int [Default: 25.0]
#    tree_method: str [Default: 'auto']
#    tweedie_variance_power: float [Default: 1.5]
#    updater: str [Default: '']
#    validation_fraction: float [Default: -1.0]
#    weight_column: str [Default: '']
# Outputs:
#    model-evaluation-evaluation_metrics: system.Metrics
components:
  comp-automl-tabular-finalizer:
    executorLabel: exec-automl-tabular-finalizer
    inputDefinitions:
      parameters:
        encryption_spec_key_name:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        location:
          parameterType: STRING
        project:
          parameterType: STRING
        root_dir:
          parameterType: STRING
    outputDefinitions:
      parameters:
        gcp_resources:
          parameterType: STRING
  comp-bool-identity:
    executorLabel: exec-bool-identity
    inputDefinitions:
      parameters:
        value:
          parameterType: BOOLEAN
    outputDefinitions:
      parameters:
        Output:
          parameterType: STRING
  comp-condition-2:
    dag:
      outputs:
        artifacts:
          model-evaluation-evaluation_metrics:
            artifactSelectors:
            - outputArtifactKey: evaluation_metrics
              producerSubtask: model-evaluation
      tasks:
        model-batch-predict:
          cachingOptions:
            enableCache: true
          componentRef:
            name: comp-model-batch-predict
          inputs:
            artifacts:
              unmanaged_container_model:
                componentInputArtifact: pipelinechannel--generate-xgboost-trainer-worker-pool-specs-unmanaged_container_model
            parameters:
              bigquery_source_input_uri:
                componentInputParameter: pipelinechannel--feature-transform-engine-bigquery_test_split_uri
              encryption_spec_key_name:
                componentInputParameter: pipelinechannel--encryption_spec_key_name
              gcs_destination_output_uri_prefix:
                componentInputParameter: pipelinechannel--root_dir
              instances_format:
                runtimeValue:
                  constant: bigquery
              job_display_name:
                runtimeValue:
                  constant: batch-predict-evaluation-{{$.pipeline_job_uuid}}-{{$.pipeline_task_uuid}}
              location:
                componentInputParameter: pipelinechannel--location
              machine_type:
                componentInputParameter: pipelinechannel--evaluation_batch_predict_machine_type
              max_replica_count:
                componentInputParameter: pipelinechannel--evaluation_batch_predict_max_replica_count
              predictions_format:
                runtimeValue:
                  constant: jsonl
              project:
                componentInputParameter: pipelinechannel--project
              starting_replica_count:
                componentInputParameter: pipelinechannel--evaluation_batch_predict_starting_replica_count
          taskInfo:
            name: model-batch-predict
        model-evaluation:
          cachingOptions:
            enableCache: true
          componentRef:
            name: comp-model-evaluation
          dependentTasks:
          - model-batch-predict
          inputs:
            artifacts:
              batch_prediction_job:
                taskOutputArtifact:
                  outputArtifactKey: batchpredictionjob
                  producerTask: model-batch-predict
            parameters:
              dataflow_disk_size:
                componentInputParameter: pipelinechannel--evaluation_dataflow_disk_size_gb
              dataflow_machine_type:
                componentInputParameter: pipelinechannel--evaluation_dataflow_machine_type
              dataflow_max_workers_num:
                componentInputParameter: pipelinechannel--evaluation_dataflow_max_num_workers
              dataflow_service_account:
                componentInputParameter: pipelinechannel--dataflow_service_account
              dataflow_subnetwork:
                componentInputParameter: pipelinechannel--dataflow_subnetwork
              dataflow_use_public_ips:
                componentInputParameter: pipelinechannel--dataflow_use_public_ips
              dataflow_workers_num:
                componentInputParameter: pipelinechannel--evaluation_dataflow_starting_num_workers
              encryption_spec_key_name:
                componentInputParameter: pipelinechannel--encryption_spec_key_name
              ground_truth_column:
                componentInputParameter: pipelinechannel--target_column
              ground_truth_format:
                runtimeValue:
                  constant: jsonl
              location:
                componentInputParameter: pipelinechannel--location
              prediction_label_column:
                runtimeValue:
                  constant: ''
              prediction_score_column:
                runtimeValue:
                  constant: ''
              predictions_format:
                runtimeValue:
                  constant: jsonl
              problem_type:
                componentInputParameter: pipelinechannel--get-prediction-type-for-xgboost-Output
              project:
                componentInputParameter: pipelinechannel--project
              root_dir:
                componentInputParameter: pipelinechannel--root_dir
          taskInfo:
            name: model-evaluation
    inputDefinitions:
      artifacts:
        pipelinechannel--generate-xgboost-trainer-worker-pool-specs-unmanaged_container_model:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
      parameters:
        pipelinechannel--bool-identity-Output:
          parameterType: STRING
        pipelinechannel--dataflow_service_account:
          parameterType: STRING
        pipelinechannel--dataflow_subnetwork:
          parameterType: STRING
        pipelinechannel--dataflow_use_public_ips:
          parameterType: BOOLEAN
        pipelinechannel--encryption_spec_key_name:
          parameterType: STRING
        pipelinechannel--evaluation_batch_predict_machine_type:
          parameterType: STRING
        pipelinechannel--evaluation_batch_predict_max_replica_count:
          parameterType: NUMBER_INTEGER
        pipelinechannel--evaluation_batch_predict_starting_replica_count:
          parameterType: NUMBER_INTEGER
        pipelinechannel--evaluation_dataflow_disk_size_gb:
          parameterType: NUMBER_INTEGER
        pipelinechannel--evaluation_dataflow_machine_type:
          parameterType: STRING
        pipelinechannel--evaluation_dataflow_max_num_workers:
          parameterType: NUMBER_INTEGER
        pipelinechannel--evaluation_dataflow_starting_num_workers:
          parameterType: NUMBER_INTEGER
        pipelinechannel--feature-transform-engine-bigquery_test_split_uri:
          parameterType: STRING
        pipelinechannel--get-prediction-type-for-xgboost-Output:
          parameterType: STRING
        pipelinechannel--location:
          parameterType: STRING
        pipelinechannel--project:
          parameterType: STRING
        pipelinechannel--root_dir:
          parameterType: STRING
        pipelinechannel--target_column:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        model-evaluation-evaluation_metrics:
          artifactType:
            schemaTitle: system.Metrics
            schemaVersion: 0.0.1
  comp-exit-handler-1:
    dag:
      outputs:
        artifacts:
          model-evaluation-evaluation_metrics:
            artifactSelectors:
            - outputArtifactKey: model-evaluation-evaluation_metrics
              producerSubtask: condition-2
      tasks:
        bool-identity:
          cachingOptions:
            enableCache: true
          componentRef:
            name: comp-bool-identity
          dependentTasks:
          - xgboost-trainer
          inputs:
            parameters:
              value:
                componentInputParameter: pipelinechannel--run_evaluation
          taskInfo:
            name: bool-identity
        condition-2:
          componentRef:
            name: comp-condition-2
          dependentTasks:
          - bool-identity
          - feature-transform-engine
          - generate-xgboost-trainer-worker-pool-specs
          - get-prediction-type-for-xgboost
          inputs:
            artifacts:
              pipelinechannel--generate-xgboost-trainer-worker-pool-specs-unmanaged_container_model:
                taskOutputArtifact:
                  outputArtifactKey: unmanaged_container_model
                  producerTask: generate-xgboost-trainer-worker-pool-specs
            parameters:
              pipelinechannel--bool-identity-Output:
                taskOutputParameter:
                  outputParameterKey: Output
                  producerTask: bool-identity
              pipelinechannel--dataflow_service_account:
                componentInputParameter: pipelinechannel--dataflow_service_account
              pipelinechannel--dataflow_subnetwork:
                componentInputParameter: pipelinechannel--dataflow_subnetwork
              pipelinechannel--dataflow_use_public_ips:
                componentInputParameter: pipelinechannel--dataflow_use_public_ips
              pipelinechannel--encryption_spec_key_name:
                componentInputParameter: pipelinechannel--encryption_spec_key_name
              pipelinechannel--evaluation_batch_predict_machine_type:
                componentInputParameter: pipelinechannel--evaluation_batch_predict_machine_type
              pipelinechannel--evaluation_batch_predict_max_replica_count:
                componentInputParameter: pipelinechannel--evaluation_batch_predict_max_replica_count
              pipelinechannel--evaluation_batch_predict_starting_replica_count:
                componentInputParameter: pipelinechannel--evaluation_batch_predict_starting_replica_count
              pipelinechannel--evaluation_dataflow_disk_size_gb:
                componentInputParameter: pipelinechannel--evaluation_dataflow_disk_size_gb
              pipelinechannel--evaluation_dataflow_machine_type:
                componentInputParameter: pipelinechannel--evaluation_dataflow_machine_type
              pipelinechannel--evaluation_dataflow_max_num_workers:
                componentInputParameter: pipelinechannel--evaluation_dataflow_max_num_workers
              pipelinechannel--evaluation_dataflow_starting_num_workers:
                componentInputParameter: pipelinechannel--evaluation_dataflow_starting_num_workers
              pipelinechannel--feature-transform-engine-bigquery_test_split_uri:
                taskOutputParameter:
                  outputParameterKey: bigquery_test_split_uri
                  producerTask: feature-transform-engine
              pipelinechannel--get-prediction-type-for-xgboost-Output:
                taskOutputParameter:
                  outputParameterKey: Output
                  producerTask: get-prediction-type-for-xgboost
              pipelinechannel--location:
                componentInputParameter: pipelinechannel--location
              pipelinechannel--project:
                componentInputParameter: pipelinechannel--project
              pipelinechannel--root_dir:
                componentInputParameter: pipelinechannel--root_dir
              pipelinechannel--target_column:
                componentInputParameter: pipelinechannel--target_column
          taskInfo:
            name: run-evaluation
          triggerPolicy:
            condition: inputs.parameter_values['pipelinechannel--bool-identity-Output']
              == 'true'
        feature-transform-engine:
          cachingOptions:
            enableCache: true
          componentRef:
            name: comp-feature-transform-engine
          dependentTasks:
          - get-prediction-type-for-xgboost
          inputs:
            parameters:
              bigquery_staging_full_dataset_id:
                componentInputParameter: pipelinechannel--bigquery_staging_full_dataset_id
              data_source_bigquery_table_path:
                componentInputParameter: pipelinechannel--data_source_bigquery_table_path
              data_source_csv_filenames:
                componentInputParameter: pipelinechannel--data_source_csv_filenames
              dataflow_disk_size_gb:
                componentInputParameter: pipelinechannel--transform_dataflow_disk_size_gb
              dataflow_machine_type:
                componentInputParameter: pipelinechannel--transform_dataflow_machine_type
              dataflow_max_num_workers:
                componentInputParameter: pipelinechannel--transform_dataflow_max_num_workers
              dataflow_service_account:
                componentInputParameter: pipelinechannel--dataflow_service_account
              dataflow_subnetwork:
                componentInputParameter: pipelinechannel--dataflow_subnetwork
              dataflow_use_public_ips:
                componentInputParameter: pipelinechannel--dataflow_use_public_ips
              dataset_level_custom_transformation_definitions:
                componentInputParameter: pipelinechannel--dataset_level_custom_transformation_definitions
              dataset_level_transformations:
                componentInputParameter: pipelinechannel--dataset_level_transformations
              encryption_spec_key_name:
                componentInputParameter: pipelinechannel--encryption_spec_key_name
              feature_selection_algorithm:
                componentInputParameter: pipelinechannel--feature_selection_algorithm
              location:
                componentInputParameter: pipelinechannel--location
              max_selected_features:
                componentInputParameter: pipelinechannel--max_selected_features
              model_type:
                runtimeValue:
                  constant: boosted_trees
              predefined_split_key:
                componentInputParameter: pipelinechannel--predefined_split_key
              prediction_type:
                taskOutputParameter:
                  outputParameterKey: Output
                  producerTask: get-prediction-type-for-xgboost
              project:
                componentInputParameter: pipelinechannel--project
              root_dir:
                componentInputParameter: pipelinechannel--root_dir
              run_feature_selection:
                componentInputParameter: pipelinechannel--run_feature_selection
              stratified_split_key:
                componentInputParameter: pipelinechannel--stratified_split_key
              target_column:
                componentInputParameter: pipelinechannel--target_column
              test_fraction:
                componentInputParameter: pipelinechannel--test_fraction
              tf_auto_transform_features:
                componentInputParameter: pipelinechannel--tf_auto_transform_features
              tf_custom_transformation_definitions:
                componentInputParameter: pipelinechannel--tf_custom_transformation_definitions
              tf_transformations_path:
                componentInputParameter: pipelinechannel--tf_transformations_path
              training_fraction:
                componentInputParameter: pipelinechannel--training_fraction
              validation_fraction:
                componentInputParameter: pipelinechannel--validation_fraction
              weight_column:
                componentInputParameter: pipelinechannel--weight_column
          taskInfo:
            name: feature-transform-engine
        generate-xgboost-trainer-worker-pool-specs:
          cachingOptions:
            enableCache: true
          componentRef:
            name: comp-generate-xgboost-trainer-worker-pool-specs
          dependentTasks:
          - feature-transform-engine
          - split-materialized-data
          - training-configurator-and-validator
          inputs:
            artifacts:
              instance_baseline:
                taskOutputArtifact:
                  outputArtifactKey: instance_baseline
                  producerTask: training-configurator-and-validator
              materialized_eval_split:
                taskOutputArtifact:
                  outputArtifactKey: materialized_eval_split
                  producerTask: split-materialized-data
              materialized_train_split:
                taskOutputArtifact:
                  outputArtifactKey: materialized_train_split
                  producerTask: split-materialized-data
              training_schema_uri:
                taskOutputArtifact:
                  outputArtifactKey: training_schema
                  producerTask: feature-transform-engine
              transform_output:
                taskOutputArtifact:
                  outputArtifactKey: transform_output
                  producerTask: feature-transform-engine
            parameters:
              accelerator_count:
                componentInputParameter: pipelinechannel--training_accelerator_count
              accelerator_type:
                componentInputParameter: pipelinechannel--training_accelerator_type
              base_score:
                componentInputParameter: pipelinechannel--base_score
              booster:
                componentInputParameter: pipelinechannel--booster
              colsample_bylevel:
                componentInputParameter: pipelinechannel--colsample_bylevel
              colsample_bynode:
                componentInputParameter: pipelinechannel--colsample_bynode
              colsample_bytree:
                componentInputParameter: pipelinechannel--colsample_bytree
              disable_default_eval_metric:
                componentInputParameter: pipelinechannel--disable_default_eval_metric
              early_stopping_rounds:
                componentInputParameter: pipelinechannel--early_stopping_rounds
              eta:
                componentInputParameter: pipelinechannel--eta
              eval_metric:
                componentInputParameter: pipelinechannel--eval_metric
              feature_selector:
                componentInputParameter: pipelinechannel--feature_selector
              gamma:
                componentInputParameter: pipelinechannel--gamma
              grow_policy:
                componentInputParameter: pipelinechannel--grow_policy
              huber_slope:
                componentInputParameter: pipelinechannel--huber_slope
              interaction_constraints:
                componentInputParameter: pipelinechannel--interaction_constraints
              machine_type:
                componentInputParameter: pipelinechannel--training_machine_type
              max_bin:
                componentInputParameter: pipelinechannel--max_bin
              max_cat_to_onehot:
                componentInputParameter: pipelinechannel--max_cat_to_onehot
              max_delta_step:
                componentInputParameter: pipelinechannel--max_delta_step
              max_depth:
                componentInputParameter: pipelinechannel--max_depth
              max_leaves:
                componentInputParameter: pipelinechannel--max_leaves
              min_child_weight:
                componentInputParameter: pipelinechannel--min_child_weight
              monotone_constraints:
                componentInputParameter: pipelinechannel--monotone_constraints
              normalize_type:
                componentInputParameter: pipelinechannel--normalize_type
              num_boost_round:
                componentInputParameter: pipelinechannel--num_boost_round
              num_parallel_tree:
                componentInputParameter: pipelinechannel--num_parallel_tree
              objective:
                componentInputParameter: pipelinechannel--objective
              one_drop:
                componentInputParameter: pipelinechannel--one_drop
              process_type:
                componentInputParameter: pipelinechannel--process_type
              rate_drop:
                componentInputParameter: pipelinechannel--rate_drop
              refresh_leaf:
                componentInputParameter: pipelinechannel--refresh_leaf
              reg_alpha:
                componentInputParameter: pipelinechannel--reg_alpha
              reg_lambda:
                componentInputParameter: pipelinechannel--reg_lambda
              sample_type:
                componentInputParameter: pipelinechannel--sample_type
              sampling_method:
                componentInputParameter: pipelinechannel--sampling_method
              scale_pos_weight:
                componentInputParameter: pipelinechannel--scale_pos_weight
              seed:
                componentInputParameter: pipelinechannel--seed
              seed_per_iteration:
                componentInputParameter: pipelinechannel--seed_per_iteration
              skip_drop:
                componentInputParameter: pipelinechannel--skip_drop
              subsample:
                componentInputParameter: pipelinechannel--subsample
              target_column:
                componentInputParameter: pipelinechannel--target_column
              top_k:
                componentInputParameter: pipelinechannel--top_k
              total_replica_count:
                componentInputParameter: pipelinechannel--training_total_replica_count
              tree_method:
                componentInputParameter: pipelinechannel--tree_method
              tweedie_variance_power:
                componentInputParameter: pipelinechannel--tweedie_variance_power
              updater:
                componentInputParameter: pipelinechannel--updater
              weight_column:
                componentInputParameter: pipelinechannel--weight_column
          taskInfo:
            name: generate-xgboost-trainer-worker-pool-specs
        get-prediction-type-for-xgboost:
          cachingOptions:
            enableCache: true
          componentRef:
            name: comp-get-prediction-type-for-xgboost
          inputs:
            parameters:
              objective:
                componentInputParameter: pipelinechannel--objective
          taskInfo:
            name: get-prediction-type-for-xgboost
        model-upload:
          cachingOptions:
            enableCache: true
          componentRef:
            name: comp-model-upload
          dependentTasks:
          - generate-xgboost-trainer-worker-pool-specs
          - xgboost-trainer
          inputs:
            artifacts:
              unmanaged_container_model:
                taskOutputArtifact:
                  outputArtifactKey: unmanaged_container_model
                  producerTask: generate-xgboost-trainer-worker-pool-specs
            parameters:
              display_name:
                runtimeValue:
                  constant: automl-tabular-model-upload-{{$.pipeline_job_uuid}}-{{$.pipeline_task_uuid}}
              encryption_spec_key_name:
                componentInputParameter: pipelinechannel--encryption_spec_key_name
              location:
                componentInputParameter: pipelinechannel--location
              project:
                componentInputParameter: pipelinechannel--project
          taskInfo:
            name: model-upload
        split-materialized-data:
          cachingOptions:
            enableCache: true
          componentRef:
            name: comp-split-materialized-data
          dependentTasks:
          - feature-transform-engine
          inputs:
            artifacts:
              materialized_data:
                taskOutputArtifact:
                  outputArtifactKey: materialized_data
                  producerTask: feature-transform-engine
          taskInfo:
            name: split-materialized-data
        training-configurator-and-validator:
          cachingOptions:
            enableCache: true
          componentRef:
            name: comp-training-configurator-and-validator
          dependentTasks:
          - feature-transform-engine
          - get-prediction-type-for-xgboost
          inputs:
            artifacts:
              dataset_stats:
                taskOutputArtifact:
                  outputArtifactKey: dataset_stats
                  producerTask: feature-transform-engine
              instance_schema:
                taskOutputArtifact:
                  outputArtifactKey: instance_schema
                  producerTask: feature-transform-engine
              training_schema:
                taskOutputArtifact:
                  outputArtifactKey: training_schema
                  producerTask: feature-transform-engine
            parameters:
              prediction_type:
                taskOutputParameter:
                  outputParameterKey: Output
                  producerTask: get-prediction-type-for-xgboost
              run_evaluation:
                componentInputParameter: pipelinechannel--run_evaluation
              split_example_counts:
                taskOutputParameter:
                  outputParameterKey: split_example_counts
                  producerTask: feature-transform-engine
              target_column:
                componentInputParameter: pipelinechannel--target_column
              weight_column:
                componentInputParameter: pipelinechannel--weight_column
          taskInfo:
            name: training-configurator-and-validator
        xgboost-trainer:
          cachingOptions:
            enableCache: true
          componentRef:
            name: comp-xgboost-trainer
          dependentTasks:
          - generate-xgboost-trainer-worker-pool-specs
          inputs:
            parameters:
              encryption_spec_key_name:
                componentInputParameter: pipelinechannel--encryption_spec_key_name
              location:
                componentInputParameter: pipelinechannel--location
              project:
                componentInputParameter: pipelinechannel--project
              worker_pool_specs:
                taskOutputParameter:
                  outputParameterKey: worker_pool_specs
                  producerTask: generate-xgboost-trainer-worker-pool-specs
          taskInfo:
            name: xgboost-trainer
    inputDefinitions:
      parameters:
        pipelinechannel--base_score:
          parameterType: NUMBER_DOUBLE
        pipelinechannel--bigquery_staging_full_dataset_id:
          parameterType: STRING
        pipelinechannel--booster:
          parameterType: STRING
        pipelinechannel--colsample_bylevel:
          parameterType: NUMBER_DOUBLE
        pipelinechannel--colsample_bynode:
          parameterType: NUMBER_DOUBLE
        pipelinechannel--colsample_bytree:
          parameterType: NUMBER_DOUBLE
        pipelinechannel--data_source_bigquery_table_path:
          parameterType: STRING
        pipelinechannel--data_source_csv_filenames:
          parameterType: STRING
        pipelinechannel--dataflow_service_account:
          parameterType: STRING
        pipelinechannel--dataflow_subnetwork:
          parameterType: STRING
        pipelinechannel--dataflow_use_public_ips:
          parameterType: BOOLEAN
        pipelinechannel--dataset_level_custom_transformation_definitions:
          parameterType: LIST
        pipelinechannel--dataset_level_transformations:
          parameterType: LIST
        pipelinechannel--disable_default_eval_metric:
          parameterType: NUMBER_INTEGER
        pipelinechannel--early_stopping_rounds:
          parameterType: NUMBER_INTEGER
        pipelinechannel--encryption_spec_key_name:
          parameterType: STRING
        pipelinechannel--eta:
          parameterType: NUMBER_DOUBLE
        pipelinechannel--eval_metric:
          parameterType: STRING
        pipelinechannel--evaluation_batch_predict_machine_type:
          parameterType: STRING
        pipelinechannel--evaluation_batch_predict_max_replica_count:
          parameterType: NUMBER_INTEGER
        pipelinechannel--evaluation_batch_predict_starting_replica_count:
          parameterType: NUMBER_INTEGER
        pipelinechannel--evaluation_dataflow_disk_size_gb:
          parameterType: NUMBER_INTEGER
        pipelinechannel--evaluation_dataflow_machine_type:
          parameterType: STRING
        pipelinechannel--evaluation_dataflow_max_num_workers:
          parameterType: NUMBER_INTEGER
        pipelinechannel--evaluation_dataflow_starting_num_workers:
          parameterType: NUMBER_INTEGER
        pipelinechannel--feature_selection_algorithm:
          parameterType: STRING
        pipelinechannel--feature_selector:
          parameterType: STRING
        pipelinechannel--gamma:
          parameterType: NUMBER_DOUBLE
        pipelinechannel--grow_policy:
          parameterType: STRING
        pipelinechannel--huber_slope:
          parameterType: NUMBER_DOUBLE
        pipelinechannel--interaction_constraints:
          parameterType: STRING
        pipelinechannel--location:
          parameterType: STRING
        pipelinechannel--max_bin:
          parameterType: NUMBER_INTEGER
        pipelinechannel--max_cat_to_onehot:
          parameterType: NUMBER_INTEGER
        pipelinechannel--max_delta_step:
          parameterType: NUMBER_DOUBLE
        pipelinechannel--max_depth:
          parameterType: NUMBER_INTEGER
        pipelinechannel--max_leaves:
          parameterType: NUMBER_INTEGER
        pipelinechannel--max_selected_features:
          parameterType: NUMBER_INTEGER
        pipelinechannel--min_child_weight:
          parameterType: NUMBER_DOUBLE
        pipelinechannel--monotone_constraints:
          parameterType: STRING
        pipelinechannel--normalize_type:
          parameterType: STRING
        pipelinechannel--num_boost_round:
          parameterType: NUMBER_INTEGER
        pipelinechannel--num_parallel_tree:
          parameterType: NUMBER_INTEGER
        pipelinechannel--objective:
          parameterType: STRING
        pipelinechannel--one_drop:
          parameterType: NUMBER_INTEGER
        pipelinechannel--predefined_split_key:
          parameterType: STRING
        pipelinechannel--process_type:
          parameterType: STRING
        pipelinechannel--project:
          parameterType: STRING
        pipelinechannel--rate_drop:
          parameterType: NUMBER_DOUBLE
        pipelinechannel--refresh_leaf:
          parameterType: NUMBER_INTEGER
        pipelinechannel--reg_alpha:
          parameterType: NUMBER_DOUBLE
        pipelinechannel--reg_lambda:
          parameterType: NUMBER_DOUBLE
        pipelinechannel--root_dir:
          parameterType: STRING
        pipelinechannel--run_evaluation:
          parameterType: BOOLEAN
        pipelinechannel--run_feature_selection:
          parameterType: BOOLEAN
        pipelinechannel--sample_type:
          parameterType: STRING
        pipelinechannel--sampling_method:
          parameterType: STRING
        pipelinechannel--scale_pos_weight:
          parameterType: NUMBER_DOUBLE
        pipelinechannel--seed:
          parameterType: NUMBER_INTEGER
        pipelinechannel--seed_per_iteration:
          parameterType: BOOLEAN
        pipelinechannel--skip_drop:
          parameterType: NUMBER_DOUBLE
        pipelinechannel--stratified_split_key:
          parameterType: STRING
        pipelinechannel--subsample:
          parameterType: NUMBER_DOUBLE
        pipelinechannel--target_column:
          parameterType: STRING
        pipelinechannel--test_fraction:
          parameterType: NUMBER_DOUBLE
        pipelinechannel--tf_auto_transform_features:
          parameterType: STRUCT
        pipelinechannel--tf_custom_transformation_definitions:
          parameterType: LIST
        pipelinechannel--tf_transformations_path:
          parameterType: STRING
        pipelinechannel--top_k:
          parameterType: NUMBER_INTEGER
        pipelinechannel--training_accelerator_count:
          parameterType: NUMBER_INTEGER
        pipelinechannel--training_accelerator_type:
          parameterType: STRING
        pipelinechannel--training_fraction:
          parameterType: NUMBER_DOUBLE
        pipelinechannel--training_machine_type:
          parameterType: STRING
        pipelinechannel--training_total_replica_count:
          parameterType: NUMBER_INTEGER
        pipelinechannel--transform_dataflow_disk_size_gb:
          parameterType: NUMBER_INTEGER
        pipelinechannel--transform_dataflow_machine_type:
          parameterType: STRING
        pipelinechannel--transform_dataflow_max_num_workers:
          parameterType: NUMBER_INTEGER
        pipelinechannel--tree_method:
          parameterType: STRING
        pipelinechannel--tweedie_variance_power:
          parameterType: NUMBER_DOUBLE
        pipelinechannel--updater:
          parameterType: STRING
        pipelinechannel--validation_fraction:
          parameterType: NUMBER_DOUBLE
        pipelinechannel--weight_column:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        model-evaluation-evaluation_metrics:
          artifactType:
            schemaTitle: system.Metrics
            schemaVersion: 0.0.1
  comp-feature-transform-engine:
    executorLabel: exec-feature-transform-engine
    inputDefinitions:
      parameters:
        autodetect_csv_schema:
          defaultValue: false
          isOptional: true
          parameterType: BOOLEAN
        bigquery_staging_full_dataset_id:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        data_source_bigquery_table_path:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        data_source_csv_filenames:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        dataflow_disk_size_gb:
          defaultValue: 40.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        dataflow_machine_type:
          defaultValue: n1-standard-16
          isOptional: true
          parameterType: STRING
        dataflow_max_num_workers:
          defaultValue: 25.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        dataflow_service_account:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        dataflow_subnetwork:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        dataflow_use_public_ips:
          defaultValue: true
          isOptional: true
          parameterType: BOOLEAN
        dataset_level_custom_transformation_definitions:
          defaultValue: []
          isOptional: true
          parameterType: LIST
        dataset_level_transformations:
          defaultValue: []
          isOptional: true
          parameterType: LIST
        encryption_spec_key_name:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        feature_selection_algorithm:
          defaultValue: AMI
          isOptional: true
          parameterType: STRING
        forecasting_apply_windowing:
          defaultValue: true
          isOptional: true
          parameterType: BOOLEAN
        forecasting_available_at_forecast_columns:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        forecasting_context_window:
          defaultValue: -1.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        forecasting_forecast_horizon:
          defaultValue: -1.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        forecasting_predefined_window_column:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        forecasting_time_column:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        forecasting_time_series_attribute_columns:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        forecasting_time_series_identifier_column:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        forecasting_unavailable_at_forecast_columns:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        forecasting_window_max_count:
          defaultValue: -1.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        forecasting_window_stride_length:
          defaultValue: -1.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        legacy_transformations_path:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        location:
          parameterType: STRING
        materialized_examples_format:
          defaultValue: tfrecords_gzip
          isOptional: true
          parameterType: STRING
        max_selected_features:
          defaultValue: 1000.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        model_type:
          isOptional: true
          parameterType: STRING
        predefined_split_key:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        prediction_type:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        project:
          parameterType: STRING
        root_dir:
          parameterType: STRING
        run_distill:
          defaultValue: false
          isOptional: true
          parameterType: BOOLEAN
        run_feature_selection:
          defaultValue: false
          isOptional: true
          parameterType: BOOLEAN
        stratified_split_key:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        target_column:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        test_fraction:
          defaultValue: -1.0
          isOptional: true
          parameterType: NUMBER_DOUBLE
        tf_auto_transform_features:
          defaultValue: {}
          isOptional: true
          parameterType: STRUCT
        tf_custom_transformation_definitions:
          defaultValue: []
          isOptional: true
          parameterType: LIST
        tf_transform_execution_engine:
          defaultValue: dataflow
          isOptional: true
          parameterType: STRING
        tf_transformations_path:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        timestamp_split_key:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        training_fraction:
          defaultValue: -1.0
          isOptional: true
          parameterType: NUMBER_DOUBLE
        validation_fraction:
          defaultValue: -1.0
          isOptional: true
          parameterType: NUMBER_DOUBLE
        weight_column:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
    outputDefinitions:
      artifacts:
        dataset_stats:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        feature_ranking:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        instance_schema:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        materialized_data:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        training_schema:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        transform_output:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
      parameters:
        bigquery_downsampled_test_split_uri:
          parameterType: STRING
        bigquery_test_split_uri:
          parameterType: STRING
        gcp_resources:
          parameterType: STRING
        split_example_counts:
          parameterType: STRING
  comp-generate-xgboost-trainer-worker-pool-specs:
    executorLabel: exec-generate-xgboost-trainer-worker-pool-specs
    inputDefinitions:
      artifacts:
        instance_baseline:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        materialized_eval_split:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        materialized_train_split:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        training_schema_uri:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        transform_output:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
      parameters:
        accelerator_count:
          defaultValue: 0.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        accelerator_type:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        base_score:
          defaultValue: 0.5
          isOptional: true
          parameterType: NUMBER_DOUBLE
        booster:
          defaultValue: gbtree
          isOptional: true
          parameterType: STRING
        colsample_bylevel:
          defaultValue: 1.0
          isOptional: true
          parameterType: NUMBER_DOUBLE
        colsample_bynode:
          defaultValue: 1.0
          isOptional: true
          parameterType: NUMBER_DOUBLE
        colsample_bytree:
          defaultValue: 1.0
          isOptional: true
          parameterType: NUMBER_DOUBLE
        disable_default_eval_metric:
          defaultValue: 0.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        early_stopping_rounds:
          defaultValue: -1.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        eta:
          defaultValue: 0.3
          isOptional: true
          parameterType: NUMBER_DOUBLE
        eval_metric:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        feature_selector:
          defaultValue: cyclic
          isOptional: true
          parameterType: STRING
        gamma:
          defaultValue: 0.0
          isOptional: true
          parameterType: NUMBER_DOUBLE
        grow_policy:
          defaultValue: depthwise
          isOptional: true
          parameterType: STRING
        huber_slope:
          defaultValue: 1.0
          isOptional: true
          parameterType: NUMBER_DOUBLE
        interaction_constraints:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        machine_type:
          defaultValue: c2-standard-16
          isOptional: true
          parameterType: STRING
        max_bin:
          defaultValue: 256.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        max_cat_to_onehot:
          defaultValue: -1.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        max_delta_step:
          defaultValue: 0.0
          isOptional: true
          parameterType: NUMBER_DOUBLE
        max_depth:
          defaultValue: 6.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        max_leaves:
          defaultValue: 0.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        min_child_weight:
          defaultValue: 1.0
          isOptional: true
          parameterType: NUMBER_DOUBLE
        monotone_constraints:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        normalize_type:
          defaultValue: tree
          isOptional: true
          parameterType: STRING
        num_boost_round:
          defaultValue: 10.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        num_parallel_tree:
          defaultValue: 1.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        objective:
          parameterType: STRING
        one_drop:
          defaultValue: 0.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        process_type:
          defaultValue: default
          isOptional: true
          parameterType: STRING
        rate_drop:
          defaultValue: 0.0
          isOptional: true
          parameterType: NUMBER_DOUBLE
        refresh_leaf:
          defaultValue: 1.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        reg_alpha:
          defaultValue: 0.0
          isOptional: true
          parameterType: NUMBER_DOUBLE
        reg_lambda:
          defaultValue: 1.0
          isOptional: true
          parameterType: NUMBER_DOUBLE
        sample_type:
          defaultValue: uniform
          isOptional: true
          parameterType: STRING
        sampling_method:
          defaultValue: uniform
          isOptional: true
          parameterType: STRING
        scale_pos_weight:
          defaultValue: 1.0
          isOptional: true
          parameterType: NUMBER_DOUBLE
        seed:
          defaultValue: 0.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        seed_per_iteration:
          defaultValue: false
          isOptional: true
          parameterType: BOOLEAN
        skip_drop:
          defaultValue: 0.0
          isOptional: true
          parameterType: NUMBER_DOUBLE
        subsample:
          defaultValue: 1.0
          isOptional: true
          parameterType: NUMBER_DOUBLE
        target_column:
          parameterType: STRING
        top_k:
          defaultValue: 0.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        total_replica_count:
          parameterType: NUMBER_INTEGER
        tree_method:
          defaultValue: auto
          isOptional: true
          parameterType: STRING
        tweedie_variance_power:
          defaultValue: 1.5
          isOptional: true
          parameterType: NUMBER_DOUBLE
        updater:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        weight_column:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
    outputDefinitions:
      artifacts:
        job_dir:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        unmanaged_container_model:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
      parameters:
        worker_pool_specs:
          parameterType: LIST
  comp-get-prediction-type-for-xgboost:
    executorLabel: exec-get-prediction-type-for-xgboost
    inputDefinitions:
      parameters:
        objective:
          parameterType: STRING
    outputDefinitions:
      parameters:
        Output:
          parameterType: STRING
  comp-model-batch-predict:
    executorLabel: exec-model-batch-predict
    inputDefinitions:
      artifacts:
        unmanaged_container_model:
          artifactType:
            schemaTitle: google.UnmanagedContainerModel
            schemaVersion: 0.0.1
          isOptional: true
      parameters:
        accelerator_count:
          defaultValue: 0.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        accelerator_type:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        bigquery_destination_output_uri:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        bigquery_source_input_uri:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        encryption_spec_key_name:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        explanation_metadata:
          defaultValue: {}
          isOptional: true
          parameterType: STRUCT
        explanation_parameters:
          defaultValue: {}
          isOptional: true
          parameterType: STRUCT
        gcs_destination_output_uri_prefix:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        gcs_source_uris:
          defaultValue: []
          isOptional: true
          parameterType: LIST
        generate_explanation:
          defaultValue: false
          isOptional: true
          parameterType: BOOLEAN
        instances_format:
          defaultValue: jsonl
          isOptional: true
          parameterType: STRING
        job_display_name:
          parameterType: STRING
        labels:
          defaultValue: {}
          isOptional: true
          parameterType: STRUCT
        location:
          defaultValue: us-central1
          isOptional: true
          parameterType: STRING
        machine_type:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        manual_batch_tuning_parameters_batch_size:
          defaultValue: 0.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        max_replica_count:
          defaultValue: 0.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        model_parameters:
          defaultValue: {}
          isOptional: true
          parameterType: STRUCT
        predictions_format:
          defaultValue: jsonl
          isOptional: true
          parameterType: STRING
        project:
          parameterType: STRING
        starting_replica_count:
          defaultValue: 0.0
          isOptional: true
          parameterType: NUMBER_INTEGER
    outputDefinitions:
      artifacts:
        batchpredictionjob:
          artifactType:
            schemaTitle: google.VertexBatchPredictionJob
            schemaVersion: 0.0.1
        bigquery_output_table:
          artifactType:
            schemaTitle: google.BQTable
            schemaVersion: 0.0.1
        gcs_output_directory:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
      parameters:
        gcp_resources:
          parameterType: STRING
  comp-model-evaluation:
    executorLabel: exec-model-evaluation
    inputDefinitions:
      artifacts:
        batch_prediction_job:
          artifactType:
            schemaTitle: google.VertexBatchPredictionJob
            schemaVersion: 0.0.1
      parameters:
        dataflow_disk_size:
          defaultValue: 50.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        dataflow_machine_type:
          defaultValue: n1-standard-4
          isOptional: true
          parameterType: STRING
        dataflow_max_workers_num:
          defaultValue: 100.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        dataflow_service_account:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        dataflow_subnetwork:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        dataflow_use_public_ips:
          defaultValue: true
          isOptional: true
          parameterType: BOOLEAN
        dataflow_workers_num:
          defaultValue: 10.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        encryption_spec_key_name:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        example_weight_column:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        ground_truth_column:
          parameterType: STRING
        ground_truth_format:
          defaultValue: jsonl
          isOptional: true
          parameterType: STRING
        location:
          defaultValue: us-central1
          isOptional: true
          parameterType: STRING
        prediction_id_column:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        prediction_label_column:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        prediction_score_column:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        predictions_format:
          defaultValue: jsonl
          isOptional: true
          parameterType: STRING
        problem_type:
          parameterType: STRING
        project:
          parameterType: STRING
        root_dir:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        evaluation_metrics:
          artifactType:
            schemaTitle: system.Metrics
            schemaVersion: 0.0.1
      parameters:
        gcp_resources:
          parameterType: STRING
  comp-model-upload:
    executorLabel: exec-model-upload
    inputDefinitions:
      artifacts:
        unmanaged_container_model:
          artifactType:
            schemaTitle: google.UnmanagedContainerModel
            schemaVersion: 0.0.1
          isOptional: true
      parameters:
        description:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        display_name:
          parameterType: STRING
        encryption_spec_key_name:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        explanation_metadata:
          defaultValue: {}
          isOptional: true
          parameterType: STRUCT
        explanation_parameters:
          defaultValue: {}
          isOptional: true
          parameterType: STRUCT
        labels:
          defaultValue: {}
          isOptional: true
          parameterType: STRUCT
        location:
          defaultValue: us-central1
          isOptional: true
          parameterType: STRING
        project:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        model:
          artifactType:
            schemaTitle: google.VertexModel
            schemaVersion: 0.0.1
      parameters:
        gcp_resources:
          parameterType: STRING
  comp-split-materialized-data:
    executorLabel: exec-split-materialized-data
    inputDefinitions:
      artifacts:
        materialized_data:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
    outputDefinitions:
      artifacts:
        materialized_eval_split:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        materialized_test_split:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        materialized_train_split:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
  comp-training-configurator-and-validator:
    executorLabel: exec-training-configurator-and-validator
    inputDefinitions:
      artifacts:
        dataset_stats:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        instance_schema:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        training_schema:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
      parameters:
        available_at_forecast_columns:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        context_window:
          defaultValue: -1.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        enable_probabilistic_inference:
          defaultValue: false
          isOptional: true
          parameterType: BOOLEAN
        forecast_horizon:
          defaultValue: -1.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        forecasting_model_type:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        forecasting_transformations_path:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        optimization_objective:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        optimization_objective_precision_value:
          defaultValue: -1.0
          isOptional: true
          parameterType: NUMBER_DOUBLE
        optimization_objective_recall_value:
          defaultValue: -1.0
          isOptional: true
          parameterType: NUMBER_DOUBLE
        prediction_type:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        quantiles:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        run_distill:
          defaultValue: false
          isOptional: true
          parameterType: BOOLEAN
        run_evaluation:
          defaultValue: false
          isOptional: true
          parameterType: BOOLEAN
        split_example_counts:
          parameterType: STRING
        stage_1_deadline_hours:
          isOptional: true
          parameterType: NUMBER_DOUBLE
        stage_2_deadline_hours:
          isOptional: true
          parameterType: NUMBER_DOUBLE
        target_column:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        time_column:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        time_series_attribute_columns:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        time_series_identifier_column:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        unavailable_at_forecast_columns:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        weight_column:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
    outputDefinitions:
      artifacts:
        instance_baseline:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        metadata:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
  comp-xgboost-trainer:
    executorLabel: exec-xgboost-trainer
    inputDefinitions:
      parameters:
        encryption_spec_key_name:
          defaultValue: ''
          isOptional: true
          parameterType: STRING
        location:
          parameterType: STRING
        project:
          parameterType: STRING
        worker_pool_specs:
          parameterType: LIST
    outputDefinitions:
      parameters:
        gcp_resources:
          parameterType: STRING
deploymentSpec:
  executors:
    exec-automl-tabular-finalizer:
      container:
        args:
        - --type
        - CustomJob
        - --project
        - '{{$.inputs.parameters[''project'']}}'
        - --location
        - '{{$.inputs.parameters[''location'']}}'
        - --gcp_resources
        - '{{$.outputs.parameters[''gcp_resources''].output_file}}'
        - --payload
        - '{"Concat": ["{\"display_name\": \"automl-tabular-finalizer-{{$.pipeline_job_uuid}}-{{$.pipeline_task_uuid}}\",
          \"encryption_spec\": {\"kms_key_name\":\"", "{{$.inputs.parameters[''encryption_spec_key_name'']}}",
          "\"}, \"job_spec\": {\"worker_pool_specs\": [{\"replica_count\": 1, \"machine_spec\":
          {\"machine_type\": \"n1-standard-8\"}, \"container_spec\": {\"image_uri\":\"",
          "us-docker.pkg.dev/vertex-ai-restricted/automl-tabular/training:20230424_1325", "\",
          \"args\": [\"cancel_l2l_tuner\", \"--error_file_path=", "{{$.inputs.parameters[''root_dir'']}}",
          "/{{$.pipeline_job_uuid}}/{{$.pipeline_task_uuid}}/error.pb\", \"--cleanup_lro_job_infos=",
          "{{$.inputs.parameters[''root_dir'']}}", "/{{$.pipeline_job_uuid}}/lro\"]}}]}}"]}'
        command:
        - python3
        - -u
        - -m
        - google_cloud_pipeline_components.container.v1.custom_job.launcher
        image: gcr.io/ml-pipeline/google-cloud-pipeline-components:1.0.32
    exec-bool-identity:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - _bool_identity
        command:
        - sh
        - -ec
        - 'program_path=$(mktemp -d)

          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          python3 -m kfp.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef _bool_identity(value: bool) -> str:\n  \"\"\"Returns boolean\
          \ value.\n\n  Args:\n    value: Boolean value to return\n\n  Returns:\n\
          \    Boolean value.\n  \"\"\"\n  return 'true' if value else 'false'\n\n"
        image: us-docker.pkg.dev/vertex-ai/automl-tabular/kfp-v2-base:20230424_1325
    exec-feature-transform-engine:
      container:
        args:
        - feature_transform_engine
        - '{"Concat": ["--project=", "{{$.inputs.parameters[''project'']}}"]}'
        - '{"Concat": ["--location=", "{{$.inputs.parameters[''location'']}}"]}'
        - '{"Concat": ["--dataset_level_custom_transformation_definitions=", "{{$.inputs.parameters[''dataset_level_custom_transformation_definitions'']}}"]}'
        - '{"Concat": ["--dataset_level_transformations=", "{{$.inputs.parameters[''dataset_level_transformations'']}}"]}'
        - '{"Concat": ["--forecasting_time_column=", "{{$.inputs.parameters[''forecasting_time_column'']}}"]}'
        - '{"Concat": ["--forecasting_time_series_identifier_column=", "{{$.inputs.parameters[''forecasting_time_series_identifier_column'']}}"]}'
        - '{"Concat": ["--forecasting_time_series_attribute_columns=", "{{$.inputs.parameters[''forecasting_time_series_attribute_columns'']}}"]}'
        - '{"Concat": ["--forecasting_unavailable_at_forecast_columns=", "{{$.inputs.parameters[''forecasting_unavailable_at_forecast_columns'']}}"]}'
        - '{"Concat": ["--forecasting_available_at_forecast_columns=", "{{$.inputs.parameters[''forecasting_available_at_forecast_columns'']}}"]}'
        - '{"Concat": ["--forecasting_forecast_horizon=", "{{$.inputs.parameters[''forecasting_forecast_horizon'']}}"]}'
        - '{"Concat": ["--forecasting_context_window=", "{{$.inputs.parameters[''forecasting_context_window'']}}"]}'
        - '{"Concat": ["--forecasting_predefined_window_column=", "{{$.inputs.parameters[''forecasting_predefined_window_column'']}}"]}'
        - '{"Concat": ["--forecasting_window_stride_length=", "{{$.inputs.parameters[''forecasting_window_stride_length'']}}"]}'
        - '{"Concat": ["--forecasting_window_max_count=", "{{$.inputs.parameters[''forecasting_window_max_count'']}}"]}'
        - '{"Concat": ["--forecasting_apply_windowing=", "{{$.inputs.parameters[''forecasting_apply_windowing'']}}"]}'
        - '{"Concat": ["--predefined_split_key=", "{{$.inputs.parameters[''predefined_split_key'']}}"]}'
        - '{"Concat": ["--stratified_split_key=", "{{$.inputs.parameters[''stratified_split_key'']}}"]}'
        - '{"Concat": ["--timestamp_split_key=", "{{$.inputs.parameters[''timestamp_split_key'']}}"]}'
        - '{"Concat": ["--training_fraction=", "{{$.inputs.parameters[''training_fraction'']}}"]}'
        - '{"Concat": ["--validation_fraction=", "{{$.inputs.parameters[''validation_fraction'']}}"]}'
        - '{"Concat": ["--test_fraction=", "{{$.inputs.parameters[''test_fraction'']}}"]}'
        - '{"Concat": ["--tf_transform_execution_engine=", "{{$.inputs.parameters[''tf_transform_execution_engine'']}}"]}'
        - '{"Concat": ["--tf_auto_transform_features=", "{{$.inputs.parameters[''tf_auto_transform_features'']}}"]}'
        - '{"Concat": ["--tf_custom_transformation_definitions=", "{{$.inputs.parameters[''tf_custom_transformation_definitions'']}}"]}'
        - '{"Concat": ["--tf_transformations_path=", "{{$.inputs.parameters[''tf_transformations_path'']}}"]}'
        - '{"Concat": ["--legacy_transformations_path=", "{{$.inputs.parameters[''legacy_transformations_path'']}}"]}'
        - '{"Concat": ["--data_source_csv_filenames=", "{{$.inputs.parameters[''data_source_csv_filenames'']}}"]}'
        - '{"Concat": ["--data_source_bigquery_table_path=", "{{$.inputs.parameters[''data_source_bigquery_table_path'']}}"]}'
        - '{"Concat": ["--bigquery_staging_full_dataset_id=", "{{$.inputs.parameters[''bigquery_staging_full_dataset_id'']}}"]}'
        - '{"Concat": ["--target_column=", "{{$.inputs.parameters[''target_column'']}}"]}'
        - '{"Concat": ["--weight_column=", "{{$.inputs.parameters[''weight_column'']}}"]}'
        - '{"Concat": ["--prediction_type=", "{{$.inputs.parameters[''prediction_type'']}}"]}'
        - '{"IfPresent": {"InputName": "model_type", "Then": {"Concat": ["--model_type=",
          "{{$.inputs.parameters[''model_type'']}}"]}}}'
        - '{"Concat": ["--run_distill=", "{{$.inputs.parameters[''run_distill'']}}"]}'
        - '{"Concat": ["--run_feature_selection=", "{{$.inputs.parameters[''run_feature_selection'']}}"]}'
        - '{"Concat": ["--materialized_examples_format=", "{{$.inputs.parameters[''materialized_examples_format'']}}"]}'
        - '{"Concat": ["--max_selected_features=", "{{$.inputs.parameters[''max_selected_features'']}}"]}'
        - '{"Concat": ["--feature_selection_staging_dir=", "{{$.inputs.parameters[''root_dir'']}}",
          "/{{$.pipeline_job_uuid}}/{{$.pipeline_task_uuid}}/feature_selection_staging_dir"]}'
        - '{"Concat": ["--feature_selection_algorithm=", "{{$.inputs.parameters[''feature_selection_algorithm'']}}"]}'
        - '{"Concat": ["--feature_ranking_path=", "{{$.outputs.artifacts[''feature_ranking''].uri}}"]}'
        - '{"Concat": ["--error_file_path=", "{{$.inputs.parameters[''root_dir'']}}",
          "/{{$.pipeline_job_uuid}}/{{$.pipeline_task_uuid}}/error.txt"]}'
        - '{"Concat": ["--stats_result_path=", "{{$.outputs.artifacts[''dataset_stats''].uri}}"]}'
        - '{"Concat": ["--transform_output_artifact_path=", "{{$.outputs.artifacts[''transform_output''].uri}}"]}'
        - '{"Concat": ["--transform_output_path=", "{{$.inputs.parameters[''root_dir'']}}",
          "/{{$.pipeline_job_uuid}}/{{$.pipeline_task_uuid}}/transform"]}'
        - '{"Concat": ["--materialized_examples_path=", "{{$.inputs.parameters[''root_dir'']}}",
          "/{{$.pipeline_job_uuid}}/{{$.pipeline_task_uuid}}/materialized"]}'
        - '{"Concat": ["--export_data_path=", "{{$.inputs.parameters[''root_dir'']}}",
          "/{{$.pipeline_job_uuid}}/{{$.pipeline_task_uuid}}/export"]}'
        - '{"Concat": ["--materialized_data_path=", "{{$.inputs.parameters[''root_dir'']}}",
          "/{{$.pipeline_job_uuid}}/{{$.pipeline_task_uuid}}/materialized_data"]}'
        - '{"Concat": ["--materialized_data_artifact_path=", "{{$.outputs.artifacts[''materialized_data''].uri}}"]}'
        - '{"Concat": ["--bigquery_test_split_uri_path=", "{{$.outputs.parameters[''bigquery_test_split_uri''].output_file}}"]}'
        - '{"Concat": ["--bigquery_downsampled_test_split_uri_path=", "{{$.outputs.parameters[''bigquery_downsampled_test_split_uri''].output_file}}"]}'
        - '{"Concat": ["--split_example_counts_path=", "{{$.outputs.parameters[''split_example_counts''].output_file}}"]}'
        - '{"Concat": ["--instance_schema_path=", "{{$.outputs.artifacts[''instance_schema''].path}}"]}'
        - '{"Concat": ["--training_schema_path=", "{{$.outputs.artifacts[''training_schema''].path}}"]}'
        - --job_name=feature-transform-engine-{{$.pipeline_job_uuid}}-{{$.pipeline_task_uuid}}
        - '{"Concat": ["--dataflow_project=", "{{$.inputs.parameters[''project'']}}"]}'
        - '{"Concat": ["--dataflow_staging_dir=", "{{$.inputs.parameters[''root_dir'']}}",
          "/{{$.pipeline_job_uuid}}/{{$.pipeline_task_uuid}}/dataflow_staging"]}'
        - '{"Concat": ["--dataflow_tmp_dir=", "{{$.inputs.parameters[''root_dir'']}}",
          "/{{$.pipeline_job_uuid}}/{{$.pipeline_task_uuid}}/dataflow_tmp"]}'
        - '{"Concat": ["--dataflow_max_num_workers=", "{{$.inputs.parameters[''dataflow_max_num_workers'']}}"]}'
        - '{"Concat": ["--dataflow_machine_type=", "{{$.inputs.parameters[''dataflow_machine_type'']}}"]}'
        - --dataflow_worker_container_image=us-docker.pkg.dev/vertex-ai/automl-tabular/dataflow-worker:20230424_1325
        - --feature_transform_engine_docker_uri=us-docker.pkg.dev/vertex-ai/automl-tabular/feature-transform-engine:20230424_1325
        - '{"Concat": ["--dataflow_disk_size_gb=", "{{$.inputs.parameters[''dataflow_disk_size_gb'']}}"]}'
        - '{"Concat": ["--dataflow_subnetwork_fully_qualified=", "{{$.inputs.parameters[''dataflow_subnetwork'']}}"]}'
        - '{"Concat": ["--dataflow_use_public_ips=", "{{$.inputs.parameters[''dataflow_use_public_ips'']}}"]}'
        - '{"Concat": ["--dataflow_service_account=", "{{$.inputs.parameters[''dataflow_service_account'']}}"]}'
        - '{"Concat": ["--dataflow_kms_key=", "{{$.inputs.parameters[''encryption_spec_key_name'']}}"]}'
        - '{"Concat": ["--autodetect_csv_schema=", "{{$.inputs.parameters[''autodetect_csv_schema'']}}"]}'
        - '{"Concat": ["--gcp_resources_path=", "{{$.outputs.parameters[''gcp_resources''].output_file}}"]}'
        image: us-docker.pkg.dev/vertex-ai/automl-tabular/feature-transform-engine:20230424_1325
        resources:
          cpuLimit: 8.0
          memoryLimit: 30.0
    exec-generate-xgboost-trainer-worker-pool-specs:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - _generate_xgboost_trainer_worker_pool_specs
        command:
        - sh
        - -ec
        - 'program_path=$(mktemp -d)

          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          python3 -m kfp.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef _generate_xgboost_trainer_worker_pool_specs(\n    total_replica_count:\
          \ int,\n    target_column: str,\n    objective: str,\n    materialized_train_split:\
          \ dsl.InputPath('MaterializedSplit'),\n    materialized_eval_split: dsl.InputPath('MaterializedSplit'),\n\
          \    transform_output: dsl.InputPath('TransformOutput'),\n    training_schema_uri:\
          \ dsl.InputPath('DatasetSchema'),\n    instance_baseline: dsl.InputPath('AutoMLTabularInstanceBaseline'),\n\
          \    job_dir: OutputPath('JobDir'),\n    unmanaged_container_model: dsl.Output[dsl.Artifact],\n\
          \    machine_type: str = 'c2-standard-16',\n    accelerator_type: str =\
          \ '',\n    accelerator_count: int = 0,\n    weight_column: str = '',\n \
          \   eval_metric: str = '',\n    num_boost_round: int = 10,\n    early_stopping_rounds:\
          \ int = -1,\n    base_score: float = 0.5,\n    disable_default_eval_metric:\
          \ int = 0,\n    seed: int = 0,\n    seed_per_iteration: bool = False,\n\
          \    booster: str = 'gbtree',\n    eta: float = 0.3,\n    gamma: float =\
          \ 0.0,\n    max_depth: int = 6,\n    min_child_weight: float = 1.0,\n  \
          \  max_delta_step: float = 0.0,\n    subsample: float = 1.0,\n    colsample_bytree:\
          \ float = 1.0,\n    colsample_bylevel: float = 1.0,\n    colsample_bynode:\
          \ float = 1.0,\n    reg_lambda: float = 1.0,\n    reg_alpha: float = 0.0,\n\
          \    tree_method: str = 'auto',\n    scale_pos_weight: float = 1.0,\n  \
          \  updater: str = '',\n    refresh_leaf: int = 1,\n    process_type: str\
          \ = 'default',\n    grow_policy: str = 'depthwise',\n    sampling_method:\
          \ str = 'uniform',\n    monotone_constraints: str = '',\n    interaction_constraints:\
          \ str = '',\n    sample_type: str = 'uniform',\n    normalize_type: str\
          \ = 'tree',\n    rate_drop: float = 0.0,\n    one_drop: int = 0,\n    skip_drop:\
          \ float = 0.0,\n    num_parallel_tree: int = 1,\n    feature_selector: str\
          \ = 'cyclic',\n    top_k: int = 0,\n    max_cat_to_onehot: int = -1,\n \
          \   max_leaves: int = 0,\n    max_bin: int = 256,\n    tweedie_variance_power:\
          \ float = 1.5,\n    huber_slope: float = 1.0,\n) -> NamedTuple(\n    'Outputs',\n\
          \    [\n        ('worker_pool_specs', list),  # pylint:disable=g-bare-generic\n\
          \    ],\n):\n  \"\"\"Generates worker pool specs for XGBoost training.\n\
          \n  For single machine XGBoost training, returns one worker pool spec for\
          \ master.\n  For distributed XGBoost training, returns two worker pool specs,\
          \ the first one\n  for master and the second one for the remaining workers.\n\
          \n  Args:\n    total_replica_count: Number of workers.\n    target_column:\
          \ Required. Target column name.\n    objective: Required. Specifies the\
          \ learning task and the learning objective.\n    materialized_train_split:\
          \ Required. The path to the materialized train\n      split.\n    materialized_eval_split:\
          \ Required. The path to the materialized validation\n      split.\n    transform_output:\
          \ Required. The path to transform output.\n    training_schema_uri: Required.\
          \ The path to the training schema.\n    instance_baseline: Path to JSON\
          \ file for baseline values.\n    job_dir: Job dir path.\n    unmanaged_container_model:\
          \ The unmanaged model.\n    machine_type: Machine type.\n    accelerator_type:\
          \ Accelerator type.\n    accelerator_count: Accelerator count.\n    weight_column:\
          \ Weight column name.\n    eval_metric: Evaluation metrics for validation\
          \ data represented as a\n      comma-separated string.\n    num_boost_round:\
          \ Number of boosting iterations.\n    early_stopping_rounds: Activates early\
          \ stopping. Validation error needs to\n      decrease at least every early_stopping_rounds\
          \ round(s) to continue\n      training.\n    base_score: The initial prediction\
          \ score of all instances, global bias.\n    disable_default_eval_metric:\
          \ Flag to disable default metric. Set to >0 to\n      disable. Default to\
          \ 0.\n    seed: Random seed.\n    seed_per_iteration: Seed PRNG determnisticly\
          \ via iterator number.\n    booster: Which booster to use, can be gbtree,\
          \ gblinear or dart. gbtree and\n      dart use tree based model while gblinear\
          \ uses linear function.\n    eta: Learning rate.\n    gamma: Minimum loss\
          \ reduction required to make a further partition on a leaf\n      node of\
          \ the tree.\n    max_depth: Maximum depth of a tree.\n    min_child_weight:\
          \ Minimum sum of instance weight(hessian) needed in a child.\n    max_delta_step:\
          \ Maximum delta step we allow each tree's weight estimation to\n      be.\n\
          \    subsample: Subsample ratio of the training instance.\n    colsample_bytree:\
          \ Subsample ratio of columns when constructing each tree.\n    colsample_bylevel:\
          \ Subsample ratio of columns for each split, in each level.\n    colsample_bynode:\
          \ Subsample ratio of columns for each node (split).\n    reg_lambda: L2\
          \ regularization term on weights.\n    reg_alpha: L1 regularization term\
          \ on weights.\n    tree_method: The tree construction algorithm used in\
          \ XGBoost. Choices:\n      [\"auto\", \"exact\", \"approx\", \"hist\", \"\
          gpu_exact\", \"gpu_hist\"].\n    scale_pos_weight: Control the balance of\
          \ positive and negative weights.\n    updater: A comma separated string\
          \ defining the sequence of tree updaters to\n      run.\n    refresh_leaf:\
          \ Refresh updater plugin. Update tree leaf and nodes's stats if\n      True.\
          \ When it is False, only node stats are updated.\n    process_type: A type\
          \ of boosting process to run. Choices:[\"default\",\n      \"update\"]\n\
          \    grow_policy: Controls a way new nodes are added to the tree. Only supported\n\
          \      if tree_method is hist. Choices:[\"depthwise\", \"lossguide\"]\n\
          \    sampling_method: The method to use to sample the training instances.\n\
          \    monotone_constraints: Constraint of variable monotonicity.\n    interaction_constraints:\
          \ Constraints for interaction representing permitted\n      interactions.\n\
          \    sample_type: [dart booster only] Type of sampling algorithm.\n    \
          \  Choices:[\"uniform\", \"weighted\"]\n    normalize_type: [dart booster\
          \ only] Type of normalization algorithm,\n      Choices:[\"tree\", \"forest\"\
          ]\n    rate_drop: [dart booster only] Dropout rate.'\n    one_drop: [dart\
          \ booster only] When this flag is enabled, at least one tree\n      is always\
          \ dropped during the dropout (allows Binomial-plus-one or\n      epsilon-dropout\
          \ from the original DART paper).\n    skip_drop: [dart booster only] Probability\
          \ of skipping the dropout procedure\n      during a boosting iteration.\n\
          \    num_parallel_tree: Number of parallel trees constructed during each\n\
          \      iteration. This option is used to support boosted random forest.\n\
          \    feature_selector: [linear booster only] Feature selection and ordering\n\
          \      method.\n    top_k: The number of top features to select in greedy\
          \ and thrifty feature\n      selector. The value of 0 means using all the\
          \ features.\n    max_cat_to_onehot: A threshold for deciding whether XGBoost\
          \ should use\n      one-hot encoding based split for categorical data.\n\
          \    max_leaves: Maximum number of nodes to be added.\n    max_bin: Maximum\
          \ number of discrete bins to bucket continuous features.\n    tweedie_variance_power:\
          \ Parameter that controls the variance of the Tweedie\n      distribution.\n\
          \    huber_slope: A parameter used for Pseudo-Huber loss to define the delta\n\
          \      term.\n\n  Raises:\n    ValueError: If accelerator_count <= 0 and\
          \ accelerator_type is specified.\n\n  Returns:\n    Outputs containing the\
          \ worker pool specs.\n  \"\"\"\n  import copy\n  import collections\n  import\
          \ os\n  import re\n\n  def get_gcs_path(path):\n    return re.sub(r'/gcs/',\
          \ 'gs://', path)\n\n  formatted_job_dir = get_gcs_path(job_dir)\n  prediction_docker_uri\
          \ = (\n      'us-docker.pkg.dev/vertex-ai/automl-tabular/xgboost-prediction-server:20230424_1325'\n\
          \  )\n  master_worker_pool_spec = {\n      'replica_count': 1,\n      'machine_spec':\
          \ {\n          'machine_type': machine_type,\n      },\n      'container_spec':\
          \ {\n          'image_uri': 'us-docker.pkg.dev/vertex-ai-restricted/automl-tabular/xgboost-training:20230424_1325',\n\
          \          'args': [\n              f'--job_dir={formatted_job_dir}',\n\
          \              f'--target_column={target_column}',\n              f'--objective={objective}',\n\
          \              f'--training_data_path={get_gcs_path(materialized_train_split)}',\n\
          \              f'--validation_data_path={get_gcs_path(materialized_eval_split)}',\n\
          \              f'--transform_output_path={get_gcs_path(transform_output)}',\n\
          \              f'--training_schema_path={get_gcs_path(training_schema_uri)}',\n\
          \              f'--baseline_path={get_gcs_path(instance_baseline)}',\n \
          \             f'--eval_metric={eval_metric}',\n              f'--num_boost_round={num_boost_round}',\n\
          \              f'--base_score={base_score}',\n              f'--disable_default_eval_metric={disable_default_eval_metric}',\n\
          \              f'--seed={seed}',\n              f'--seed_per_iteration={seed_per_iteration}',\n\
          \              f'--booster={booster}',\n              f'--eta={eta}',\n\
          \              f'--gamma={gamma}',\n              f'--max_depth={max_depth}',\n\
          \              f'--min_child_weight={min_child_weight}',\n             \
          \ f'--max_delta_step={max_delta_step}',\n              f'--subsample={subsample}',\n\
          \              f'--colsample_bytree={colsample_bytree}',\n             \
          \ f'--colsample_bylevel={colsample_bylevel}',\n              f'--colsample_bynode={colsample_bynode}',\n\
          \              f'--lambda={reg_lambda}',\n              f'--alpha={reg_alpha}',\n\
          \              f'--tree_method={tree_method}',\n              f'--scale_pos_weight={scale_pos_weight}',\n\
          \              f'--refresh_leaf={refresh_leaf}',\n              f'--process_type={process_type}',\n\
          \              f'--grow_policy={grow_policy}',\n              f'--sampling_method={sampling_method}',\n\
          \              f'--sample_type={sample_type}',\n              f'--normalize_type={normalize_type}',\n\
          \              f'--rate_drop={rate_drop}',\n              f'--one_drop={one_drop}',\n\
          \              f'--skip_drop={skip_drop}',\n              f'--num_parallel_tree={num_parallel_tree}',\n\
          \              f'--feature_selector={feature_selector}',\n             \
          \ f'--top_k={top_k}',\n              f'--max_leaves={max_leaves}',\n   \
          \           f'--max_bin={max_bin}',\n              f'--tweedie_variance_power={tweedie_variance_power}',\n\
          \              f'--huber_slope={huber_slope}',\n              f'--prediction_docker_uri={prediction_docker_uri}',\n\
          \              '--executor_input={{$.json_escape[1]}}',\n          ],\n\
          \      },\n  }\n\n  # Add optional arguments if set\n  if weight_column:\n\
          \    master_worker_pool_spec['container_spec']['args'].append(\n       \
          \ f'--weight_column={weight_column}'\n    )\n  if early_stopping_rounds\
          \ >= 0:\n    master_worker_pool_spec['container_spec']['args'].append(\n\
          \        f'--early_stopping_rounds={early_stopping_rounds}'\n    )\n  if\
          \ updater:\n    master_worker_pool_spec['container_spec']['args'].append(\n\
          \        f'--updater={updater}'\n    )\n  if monotone_constraints:\n   \
          \ master_worker_pool_spec['container_spec']['args'].append(\n        f'--monotone_constraints={monotone_constraints}'\n\
          \    )\n  if interaction_constraints:\n    master_worker_pool_spec['container_spec']['args'].append(\n\
          \        f'--interaction_constraints={interaction_constraints}'\n    )\n\
          \  if max_cat_to_onehot >= 0:\n    master_worker_pool_spec['container_spec']['args'].append(\n\
          \        f'--max_cat_to_onehot={max_cat_to_onehot}'\n    )\n\n  # Add accelerator_type\
          \ and accelerator_count if set.\n  if accelerator_type:\n    if accelerator_count\
          \ <= 0:\n      raise ValueError(\n          'Accelerator count must be greator\
          \ than 0 when type is specified.'\n      )\n    master_worker_pool_spec['machine_spec'][\n\
          \        'accelerator_type'\n    ] = accelerator_type\n    master_worker_pool_spec['machine_spec'][\n\
          \        'accelerator_count'\n    ] = accelerator_count\n\n  worker_pool_specs_lst\
          \ = [master_worker_pool_spec]\n\n  # Add an additional worker pool spec\
          \ for distributed training.\n  if total_replica_count > 1:\n    additional_replica\
          \ = total_replica_count - 1\n    additional_worker_spec = copy.deepcopy(master_worker_pool_spec)\n\
          \    additional_worker_spec['replica_count'] = additional_replica\n    worker_pool_specs_lst.append(additional_worker_spec)\n\
          \n  # Build unmanaged_container_model\n  model_dir = os.path.join(formatted_job_dir,\
          \ 'model')\n  unmanaged_container_model.metadata['containerSpec'] = {\n\
          \      'imageUri': prediction_docker_uri,\n      'healthRoute': '/health',\n\
          \      'predictRoute': '/predict',\n  }\n  unmanaged_container_model.metadata['predictSchemata']\
          \ = {\n      'instanceSchemaUri': os.path.join(model_dir, 'instance.yaml'),\n\
          \      'predictionSchemaUri': os.path.join(model_dir, 'prediction_schema.yaml'),\n\
          \  }\n  unmanaged_container_model.uri = model_dir\n\n  return collections.namedtuple('Outputs',\
          \ ['worker_pool_specs'])(\n      worker_pool_specs_lst\n  )\n\n"
        image: us-docker.pkg.dev/vertex-ai/automl-tabular/kfp-v2-base:20230424_1325
    exec-get-prediction-type-for-xgboost:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - _get_prediction_type_for_xgboost
        command:
        - sh
        - -ec
        - 'program_path=$(mktemp -d)

          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          python3 -m kfp.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef _get_prediction_type_for_xgboost(objective: str) -> str:\n  \"\
          \"\"Returns prediction_type given XGBoost training objective..\n\n  Args:\n\
          \    objective: The XGBoost training objective\n\n  Returns:\n    A string.\
          \ One of 'regression' or 'classification'\n  \"\"\"\n  if objective.startswith('binary')\
          \ or objective.startswith('multi'):\n    return 'classification'\n  elif\
          \ objective.startswith('reg'):\n    return 'regression'\n  else:\n    raise\
          \ ValueError(\n        f'Unsupported XGBoost training objective: {objective}.\
          \ Must be one of'\n        ' [reg:squarederror, reg:squaredlogerror, reg:logistic,\
          \ reg:gamma,'\n        ' reg:tweedie, reg:pseudohubererror, binary:logistic,'\n\
          \        ' multi:softprob].'\n    )\n\n"
        image: us-docker.pkg.dev/vertex-ai/automl-tabular/kfp-v2-base:20230424_1325
    exec-model-batch-predict:
      container:
        args:
        - --type
        - BatchPredictionJob
        - --payload
        - '{"Concat": ["{", "\"display_name\": \"", "{{$.inputs.parameters[''job_display_name'']}}",
          "\", ", " \"input_config\": {", "\"instances_format\": \"", "{{$.inputs.parameters[''instances_format'']}}",
          "\"", ", \"gcs_source\": {", "\"uris\":", "{{$.inputs.parameters[''gcs_source_uris'']}}",
          "}", ", \"bigquery_source\": {", "\"input_uri\": \"", "{{$.inputs.parameters[''bigquery_source_input_uri'']}}",
          "\"", "}", "}", ", \"model_parameters\": ", "{{$.inputs.parameters[''model_parameters'']}}",
          ", \"output_config\": {", "\"predictions_format\": \"", "{{$.inputs.parameters[''predictions_format'']}}",
          "\"", ", \"gcs_destination\": {", "\"output_uri_prefix\": \"", "{{$.inputs.parameters[''gcs_destination_output_uri_prefix'']}}",
          "\"", "}", ", \"bigquery_destination\": {", "\"output_uri\": \"", "{{$.inputs.parameters[''bigquery_destination_output_uri'']}}",
          "\"", "}", "}", ", \"dedicated_resources\": {", "\"machine_spec\": {", "\"machine_type\":
          \"", "{{$.inputs.parameters[''machine_type'']}}", "\"", ", \"accelerator_type\":
          \"", "{{$.inputs.parameters[''accelerator_type'']}}", "\"", ", \"accelerator_count\":
          ", "{{$.inputs.parameters[''accelerator_count'']}}", "}", ", \"starting_replica_count\":
          ", "{{$.inputs.parameters[''starting_replica_count'']}}", ", \"max_replica_count\":
          ", "{{$.inputs.parameters[''max_replica_count'']}}", "}", ", \"manual_batch_tuning_parameters\":
          {", "\"batch_size\": ", "{{$.inputs.parameters[''manual_batch_tuning_parameters_batch_size'']}}",
          "}", ", \"generate_explanation\": ", "{{$.inputs.parameters[''generate_explanation'']}}",
          ", \"explanation_spec\": {", "\"parameters\": ", "{{$.inputs.parameters[''explanation_parameters'']}}",
          ", \"metadata\": ", "{{$.inputs.parameters[''explanation_metadata'']}}",
          "}", ", \"labels\": ", "{{$.inputs.parameters[''labels'']}}", ", \"encryption_spec\":
          {\"kms_key_name\":\"", "{{$.inputs.parameters[''encryption_spec_key_name'']}}",
          "\"}", "}"]}'
        - --project
        - '{{$.inputs.parameters[''project'']}}'
        - --location
        - '{{$.inputs.parameters[''location'']}}'
        - --gcp_resources
        - '{{$.outputs.parameters[''gcp_resources''].output_file}}'
        - --executor_input
        - '{{$}}'
        command:
        - python3
        - -u
        - -m
        - google_cloud_pipeline_components.container.v1.batch_prediction_job.launcher
        image: gcr.io/ml-pipeline/google-cloud-pipeline-components:1.0.32
    exec-model-evaluation:
      container:
        args:
        - --setup_file
        - /setup.py
        - --json_mode
        - 'true'
        - --project_id
        - '{{$.inputs.parameters[''project'']}}'
        - --location
        - '{{$.inputs.parameters[''location'']}}'
        - --problem_type
        - '{{$.inputs.parameters[''problem_type'']}}'
        - --batch_prediction_format
        - '{{$.inputs.parameters[''predictions_format'']}}'
        - --batch_prediction_gcs_source
        - '{{$.inputs.artifacts[''batch_prediction_job''].metadata[''gcsOutputDirectory'']}}'
        - --ground_truth_format
        - '{{$.inputs.parameters[''ground_truth_format'']}}'
        - --key_prefix_in_prediction_dataset
        - instance
        - --root_dir
        - '{{$.inputs.parameters[''root_dir'']}}/{{$.pipeline_job_uuid}}-{{$.pipeline_task_uuid}}'
        - --classification_type
        - multiclass
        - --ground_truth_column
        - instance.{{$.inputs.parameters['ground_truth_column']}}
        - --prediction_score_column
        - '{{$.inputs.parameters[''prediction_score_column'']}}'
        - --prediction_label_column
        - '{{$.inputs.parameters[''prediction_label_column'']}}'
        - --prediction_id_column
        - ''
        - --example_weight_column
        - ''
        - --generate_feature_attribution
        - 'false'
        - --dataflow_job_prefix
        - evaluation-{{$.pipeline_job_uuid}}-{{$.pipeline_task_uuid}}
        - --dataflow_service_account
        - '{{$.inputs.parameters[''dataflow_service_account'']}}'
        - --dataflow_disk_size
        - '{{$.inputs.parameters[''dataflow_disk_size'']}}'
        - --dataflow_machine_type
        - '{{$.inputs.parameters[''dataflow_machine_type'']}}'
        - --dataflow_workers_num
        - '{{$.inputs.parameters[''dataflow_workers_num'']}}'
        - --dataflow_max_workers_num
        - '{{$.inputs.parameters[''dataflow_max_workers_num'']}}'
        - --dataflow_subnetwork
        - '{{$.inputs.parameters[''dataflow_subnetwork'']}}'
        - --dataflow_use_public_ips
        - '{{$.inputs.parameters[''dataflow_use_public_ips'']}}'
        - --kms_key_name
        - '{{$.inputs.parameters[''encryption_spec_key_name'']}}'
        - --output_metrics_gcs_path
        - '{{$.outputs.artifacts[''evaluation_metrics''].uri}}'
        - --gcp_resources
        - '{{$.outputs.parameters[''gcp_resources''].output_file}}'
        - --executor_input
        - '{{$}}'
        command:
        - python
        - /main.py
        image: gcr.io/ml-pipeline/model-evaluation:v0.4
    exec-model-upload:
      container:
        args:
        - --type
        - UploadModel
        - --payload
        - '{"Concat": ["{", "\"display_name\": \"", "{{$.inputs.parameters[''display_name'']}}",
          "\"", ", \"description\": \"", "{{$.inputs.parameters[''description'']}}",
          "\"", ", \"explanation_spec\": {", "\"parameters\": ", "{{$.inputs.parameters[''explanation_parameters'']}}",
          ", \"metadata\": ", "{{$.inputs.parameters[''explanation_metadata'']}}",
          "}", ", \"encryption_spec\": {\"kms_key_name\":\"", "{{$.inputs.parameters[''encryption_spec_key_name'']}}",
          "\"}", ", \"labels\": ", "{{$.inputs.parameters[''labels'']}}", "}"]}'
        - --project
        - '{{$.inputs.parameters[''project'']}}'
        - --location
        - '{{$.inputs.parameters[''location'']}}'
        - --gcp_resources
        - '{{$.outputs.parameters[''gcp_resources''].output_file}}'
        - --executor_input
        - '{{$}}'
        command:
        - python3
        - -u
        - -m
        - launcher
        image: gcr.io/ml-pipeline/automl-tables-private:1.0.13
    exec-split-materialized-data:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - _split_materialized_data
        command:
        - sh
        - -ec
        - 'program_path=$(mktemp -d)

          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing\
          \ import *\n\ndef _split_materialized_data(\n    materialized_data: Input[Dataset],\n\
          \    materialized_train_split: OutputPath('MaterializedSplit'),\n    materialized_eval_split:\
          \ OutputPath('MaterializedSplit'),\n    materialized_test_split: OutputPath('MaterializedSplit')):\n\
          \  \"\"\"Splits materialized_data into materialized_data test, train, and\
          \ eval splits.\n\n  Necessary adapter between FTE pipeline and trainer.\n\
          \n  Args:\n    materialized_data: materialized_data dataset output by FTE.\n\
          \    materialized_train_split: Path patern to materialized_train_split.\n\
          \    materialized_eval_split: Path patern to materialized_eval_split.\n\
          \    materialized_test_split: Path patern to materialized_test_split.\n\
          \  \"\"\"\n  # pylint: disable=g-import-not-at-top,import-outside-toplevel,redefined-outer-name,reimported\n\
          \  import json\n  import tensorflow as tf\n  # pylint: enable=g-import-not-at-top,import-outside-toplevel,redefined-outer-name,reimported\n\
          \n  with tf.io.gfile.GFile(materialized_data.path, 'r') as f:\n    artifact_path\
          \ = f.read()\n\n  # needed to import tf because this is a path in gs://\n\
          \  with tf.io.gfile.GFile(artifact_path, 'r') as f:\n    materialized_data_json\
          \ = json.load(f)\n\n  if 'tf_record_data_source' in materialized_data_json:\n\
          \    file_patterns = materialized_data_json['tf_record_data_source'][\n\
          \        'file_patterns']\n  elif 'avro_data_source' in materialized_data_json:\n\
          \    file_patterns = materialized_data_json['avro_data_source'][\n     \
          \   'file_patterns']\n  elif 'parquet_data_source' in materialized_data_json:\n\
          \    file_patterns = materialized_data_json['parquet_data_source'][\n  \
          \      'file_patterns']\n  else:\n    raise ValueError(f'Unsupported training\
          \ data source: {materialized_data_json}')\n\n  # we map indices to file\
          \ patterns based on the ordering of insertion order\n  # in our transform_data\
          \ (see above in _generate_analyze_and_transform_data)\n  with tf.io.gfile.GFile(materialized_train_split,\
          \ 'w') as f:\n    f.write(file_patterns[0])\n\n  with tf.io.gfile.GFile(materialized_eval_split,\
          \ 'w') as f:\n    f.write(file_patterns[1])\n\n  with tf.io.gfile.GFile(materialized_test_split,\
          \ 'w') as f:\n    f.write(file_patterns[2])\n\n"
        image: us-docker.pkg.dev/vertex-ai/automl-tabular/dataflow-worker:20230424_1325
    exec-training-configurator-and-validator:
      container:
        args:
        - training_configurator_and_validator
        - '{"Concat": ["--instance_schema_path=", "{{$.inputs.artifacts[''instance_schema''].uri}}"]}'
        - '{"Concat": ["--training_schema_path=", "{{$.inputs.artifacts[''training_schema''].uri}}"]}'
        - '{"Concat": ["--dataset_stats_path=", "{{$.inputs.artifacts[''dataset_stats''].uri}}"]}'
        - '{"Concat": ["--split_example_counts=", "{{$.inputs.parameters[''split_example_counts'']}}"]}'
        - '{"Concat": ["--target_column=", "{{$.inputs.parameters[''target_column'']}}"]}'
        - '{"Concat": ["--weight_column=", "{{$.inputs.parameters[''weight_column'']}}"]}'
        - '{"Concat": ["--prediction_type=", "{{$.inputs.parameters[''prediction_type'']}}"]}'
        - '{"Concat": ["--optimization_objective=", "{{$.inputs.parameters[''optimization_objective'']}}"]}'
        - '{"Concat": ["--optimization_objective_recall_value=", "{{$.inputs.parameters[''optimization_objective_recall_value'']}}"]}'
        - '{"Concat": ["--optimization_objective_precision_value=", "{{$.inputs.parameters[''optimization_objective_precision_value'']}}"]}'
        - '{"Concat": ["--metadata_path=", "{{$.outputs.artifacts[''metadata''].uri}}"]}'
        - '{"Concat": ["--instance_baseline_path=", "{{$.outputs.artifacts[''instance_baseline''].uri}}"]}'
        - '{"Concat": ["--run_evaluation=", "{{$.inputs.parameters[''run_evaluation'']}}"]}'
        - '{"Concat": ["--run_distill=", "{{$.inputs.parameters[''run_distill'']}}"]}'
        - '{"Concat": ["--enable_probabilistic_inference=", "{{$.inputs.parameters[''enable_probabilistic_inference'']}}"]}'
        - '{"Concat": ["--time_series_identifier_column=", "{{$.inputs.parameters[''time_series_identifier_column'']}}"]}'
        - '{"Concat": ["--time_column=", "{{$.inputs.parameters[''time_column'']}}"]}'
        - '{"Concat": ["--time_series_attribute_columns=", "{{$.inputs.parameters[''time_series_attribute_columns'']}}"]}'
        - '{"Concat": ["--available_at_forecast_columns=", "{{$.inputs.parameters[''available_at_forecast_columns'']}}"]}'
        - '{"Concat": ["--unavailable_at_forecast_columns=", "{{$.inputs.parameters[''unavailable_at_forecast_columns'']}}"]}'
        - '{"Concat": ["--quantiles=", "{{$.inputs.parameters[''quantiles'']}}"]}'
        - '{"Concat": ["--context_window=", "{{$.inputs.parameters[''context_window'']}}"]}'
        - '{"Concat": ["--forecast_horizon=", "{{$.inputs.parameters[''forecast_horizon'']}}"]}'
        - '{"Concat": ["--forecasting_model_type=", "{{$.inputs.parameters[''forecasting_model_type'']}}"]}'
        - '{"Concat": ["--forecasting_transformations_path=", "{{$.inputs.parameters[''forecasting_transformations_path'']}}"]}'
        - '{"IfPresent": {"InputName": "stage_1_deadline_hours", "Then": {"Concat":
          ["--stage_1_deadline_hours=", "{{$.inputs.parameters[''stage_1_deadline_hours'']}}"]}}}'
        - '{"IfPresent": {"InputName": "stage_2_deadline_hours", "Then": {"Concat":
          ["--stage_2_deadline_hours=", "{{$.inputs.parameters[''stage_2_deadline_hours'']}}"]}}}'
        image: us-docker.pkg.dev/vertex-ai/automl-tabular/feature-transform-engine:20230424_1325
    exec-xgboost-trainer:
      container:
        args:
        - --type
        - CustomJob
        - --project
        - '{{$.inputs.parameters[''project'']}}'
        - --location
        - '{{$.inputs.parameters[''location'']}}'
        - --gcp_resources
        - '{{$.outputs.parameters[''gcp_resources''].output_file}}'
        - --payload
        - '{"Concat": ["{\"display_name\": \"xgboost-trainer-{{$.pipeline_job_uuid}}-{{$.pipeline_task_uuid}}\",
          \"encryption_spec\": {\"kms_key_name\":\"", "{{$.inputs.parameters[''encryption_spec_key_name'']}}",
          "\"}, \"job_spec\": {\"worker_pool_specs\": ", "{{$.inputs.parameters[''worker_pool_specs'']}}",
          "}}"]}'
        command:
        - python3
        - -u
        - -m
        - google_cloud_pipeline_components.container.v1.custom_job.launcher
        image: gcr.io/ml-pipeline/google-cloud-pipeline-components:1.0.32
pipelineInfo:
  name: automl-tabular-xgboost-trainer
root:
  dag:
    outputs:
      artifacts:
        model-evaluation-evaluation_metrics:
          artifactSelectors:
          - outputArtifactKey: model-evaluation-evaluation_metrics
            producerSubtask: exit-handler-1
    tasks:
      automl-tabular-finalizer:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-automl-tabular-finalizer
        dependentTasks:
        - exit-handler-1
        inputs:
          parameters:
            location:
              componentInputParameter: location
            project:
              componentInputParameter: project
            root_dir:
              componentInputParameter: root_dir
        taskInfo:
          name: automl-tabular-finalizer
        triggerPolicy:
          strategy: ALL_UPSTREAM_TASKS_COMPLETED
      exit-handler-1:
        componentRef:
          name: comp-exit-handler-1
        inputs:
          parameters:
            pipelinechannel--base_score:
              componentInputParameter: base_score
            pipelinechannel--bigquery_staging_full_dataset_id:
              componentInputParameter: bigquery_staging_full_dataset_id
            pipelinechannel--booster:
              componentInputParameter: booster
            pipelinechannel--colsample_bylevel:
              componentInputParameter: colsample_bylevel
            pipelinechannel--colsample_bynode:
              componentInputParameter: colsample_bynode
            pipelinechannel--colsample_bytree:
              componentInputParameter: colsample_bytree
            pipelinechannel--data_source_bigquery_table_path:
              componentInputParameter: data_source_bigquery_table_path
            pipelinechannel--data_source_csv_filenames:
              componentInputParameter: data_source_csv_filenames
            pipelinechannel--dataflow_service_account:
              componentInputParameter: dataflow_service_account
            pipelinechannel--dataflow_subnetwork:
              componentInputParameter: dataflow_subnetwork
            pipelinechannel--dataflow_use_public_ips:
              componentInputParameter: dataflow_use_public_ips
            pipelinechannel--dataset_level_custom_transformation_definitions:
              componentInputParameter: dataset_level_custom_transformation_definitions
            pipelinechannel--dataset_level_transformations:
              componentInputParameter: dataset_level_transformations
            pipelinechannel--disable_default_eval_metric:
              componentInputParameter: disable_default_eval_metric
            pipelinechannel--early_stopping_rounds:
              componentInputParameter: early_stopping_rounds
            pipelinechannel--encryption_spec_key_name:
              componentInputParameter: encryption_spec_key_name
            pipelinechannel--eta:
              componentInputParameter: eta
            pipelinechannel--eval_metric:
              componentInputParameter: eval_metric
            pipelinechannel--evaluation_batch_predict_machine_type:
              componentInputParameter: evaluation_batch_predict_machine_type
            pipelinechannel--evaluation_batch_predict_max_replica_count:
              componentInputParameter: evaluation_batch_predict_max_replica_count
            pipelinechannel--evaluation_batch_predict_starting_replica_count:
              componentInputParameter: evaluation_batch_predict_starting_replica_count
            pipelinechannel--evaluation_dataflow_disk_size_gb:
              componentInputParameter: evaluation_dataflow_disk_size_gb
            pipelinechannel--evaluation_dataflow_machine_type:
              componentInputParameter: evaluation_dataflow_machine_type
            pipelinechannel--evaluation_dataflow_max_num_workers:
              componentInputParameter: evaluation_dataflow_max_num_workers
            pipelinechannel--evaluation_dataflow_starting_num_workers:
              componentInputParameter: evaluation_dataflow_starting_num_workers
            pipelinechannel--feature_selection_algorithm:
              componentInputParameter: feature_selection_algorithm
            pipelinechannel--feature_selector:
              componentInputParameter: feature_selector
            pipelinechannel--gamma:
              componentInputParameter: gamma
            pipelinechannel--grow_policy:
              componentInputParameter: grow_policy
            pipelinechannel--huber_slope:
              componentInputParameter: huber_slope
            pipelinechannel--interaction_constraints:
              componentInputParameter: interaction_constraints
            pipelinechannel--location:
              componentInputParameter: location
            pipelinechannel--max_bin:
              componentInputParameter: max_bin
            pipelinechannel--max_cat_to_onehot:
              componentInputParameter: max_cat_to_onehot
            pipelinechannel--max_delta_step:
              componentInputParameter: max_delta_step
            pipelinechannel--max_depth:
              componentInputParameter: max_depth
            pipelinechannel--max_leaves:
              componentInputParameter: max_leaves
            pipelinechannel--max_selected_features:
              componentInputParameter: max_selected_features
            pipelinechannel--min_child_weight:
              componentInputParameter: min_child_weight
            pipelinechannel--monotone_constraints:
              componentInputParameter: monotone_constraints
            pipelinechannel--normalize_type:
              componentInputParameter: normalize_type
            pipelinechannel--num_boost_round:
              componentInputParameter: num_boost_round
            pipelinechannel--num_parallel_tree:
              componentInputParameter: num_parallel_tree
            pipelinechannel--objective:
              componentInputParameter: objective
            pipelinechannel--one_drop:
              componentInputParameter: one_drop
            pipelinechannel--predefined_split_key:
              componentInputParameter: predefined_split_key
            pipelinechannel--process_type:
              componentInputParameter: process_type
            pipelinechannel--project:
              componentInputParameter: project
            pipelinechannel--rate_drop:
              componentInputParameter: rate_drop
            pipelinechannel--refresh_leaf:
              componentInputParameter: refresh_leaf
            pipelinechannel--reg_alpha:
              componentInputParameter: reg_alpha
            pipelinechannel--reg_lambda:
              componentInputParameter: reg_lambda
            pipelinechannel--root_dir:
              componentInputParameter: root_dir
            pipelinechannel--run_evaluation:
              componentInputParameter: run_evaluation
            pipelinechannel--run_feature_selection:
              componentInputParameter: run_feature_selection
            pipelinechannel--sample_type:
              componentInputParameter: sample_type
            pipelinechannel--sampling_method:
              componentInputParameter: sampling_method
            pipelinechannel--scale_pos_weight:
              componentInputParameter: scale_pos_weight
            pipelinechannel--seed:
              componentInputParameter: seed
            pipelinechannel--seed_per_iteration:
              componentInputParameter: seed_per_iteration
            pipelinechannel--skip_drop:
              componentInputParameter: skip_drop
            pipelinechannel--stratified_split_key:
              componentInputParameter: stratified_split_key
            pipelinechannel--subsample:
              componentInputParameter: subsample
            pipelinechannel--target_column:
              componentInputParameter: target_column
            pipelinechannel--test_fraction:
              componentInputParameter: test_fraction
            pipelinechannel--tf_auto_transform_features:
              componentInputParameter: tf_auto_transform_features
            pipelinechannel--tf_custom_transformation_definitions:
              componentInputParameter: tf_custom_transformation_definitions
            pipelinechannel--tf_transformations_path:
              componentInputParameter: tf_transformations_path
            pipelinechannel--top_k:
              componentInputParameter: top_k
            pipelinechannel--training_accelerator_count:
              componentInputParameter: training_accelerator_count
            pipelinechannel--training_accelerator_type:
              componentInputParameter: training_accelerator_type
            pipelinechannel--training_fraction:
              componentInputParameter: training_fraction
            pipelinechannel--training_machine_type:
              componentInputParameter: training_machine_type
            pipelinechannel--training_total_replica_count:
              componentInputParameter: training_total_replica_count
            pipelinechannel--transform_dataflow_disk_size_gb:
              componentInputParameter: transform_dataflow_disk_size_gb
            pipelinechannel--transform_dataflow_machine_type:
              componentInputParameter: transform_dataflow_machine_type
            pipelinechannel--transform_dataflow_max_num_workers:
              componentInputParameter: transform_dataflow_max_num_workers
            pipelinechannel--tree_method:
              componentInputParameter: tree_method
            pipelinechannel--tweedie_variance_power:
              componentInputParameter: tweedie_variance_power
            pipelinechannel--updater:
              componentInputParameter: updater
            pipelinechannel--validation_fraction:
              componentInputParameter: validation_fraction
            pipelinechannel--weight_column:
              componentInputParameter: weight_column
        taskInfo:
          name: exit-handler-1
  inputDefinitions:
    parameters:
      base_score:
        defaultValue: 0.5
        isOptional: true
        parameterType: NUMBER_DOUBLE
      bigquery_staging_full_dataset_id:
        defaultValue: ''
        isOptional: true
        parameterType: STRING
      booster:
        defaultValue: gbtree
        isOptional: true
        parameterType: STRING
      colsample_bylevel:
        defaultValue: 1.0
        isOptional: true
        parameterType: NUMBER_DOUBLE
      colsample_bynode:
        defaultValue: 1.0
        isOptional: true
        parameterType: NUMBER_DOUBLE
      colsample_bytree:
        defaultValue: 1.0
        isOptional: true
        parameterType: NUMBER_DOUBLE
      data_source_bigquery_table_path:
        defaultValue: ''
        isOptional: true
        parameterType: STRING
      data_source_csv_filenames:
        defaultValue: ''
        isOptional: true
        parameterType: STRING
      dataflow_service_account:
        defaultValue: ''
        isOptional: true
        parameterType: STRING
      dataflow_subnetwork:
        defaultValue: ''
        isOptional: true
        parameterType: STRING
      dataflow_use_public_ips:
        defaultValue: true
        isOptional: true
        parameterType: BOOLEAN
      dataset_level_custom_transformation_definitions:
        isOptional: true
        parameterType: LIST
      dataset_level_transformations:
        isOptional: true
        parameterType: LIST
      disable_default_eval_metric:
        defaultValue: 0.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      early_stopping_rounds:
        defaultValue: -1.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      encryption_spec_key_name:
        defaultValue: ''
        isOptional: true
        parameterType: STRING
      eta:
        defaultValue: 0.3
        isOptional: true
        parameterType: NUMBER_DOUBLE
      eval_metric:
        defaultValue: ''
        isOptional: true
        parameterType: STRING
      evaluation_batch_predict_machine_type:
        defaultValue: n1-highmem-8
        isOptional: true
        parameterType: STRING
      evaluation_batch_predict_max_replica_count:
        defaultValue: 20.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      evaluation_batch_predict_starting_replica_count:
        defaultValue: 20.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      evaluation_dataflow_disk_size_gb:
        defaultValue: 50.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      evaluation_dataflow_machine_type:
        defaultValue: n1-standard-4
        isOptional: true
        parameterType: STRING
      evaluation_dataflow_max_num_workers:
        defaultValue: 100.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      evaluation_dataflow_starting_num_workers:
        defaultValue: 10.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      feature_selection_algorithm:
        defaultValue: AMI
        isOptional: true
        parameterType: STRING
      feature_selector:
        defaultValue: cyclic
        isOptional: true
        parameterType: STRING
      gamma:
        defaultValue: 0.0
        isOptional: true
        parameterType: NUMBER_DOUBLE
      grow_policy:
        defaultValue: depthwise
        isOptional: true
        parameterType: STRING
      huber_slope:
        defaultValue: 1.0
        isOptional: true
        parameterType: NUMBER_DOUBLE
      interaction_constraints:
        defaultValue: ''
        isOptional: true
        parameterType: STRING
      location:
        parameterType: STRING
      max_bin:
        defaultValue: 256.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      max_cat_to_onehot:
        defaultValue: -1.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      max_delta_step:
        defaultValue: 0.0
        isOptional: true
        parameterType: NUMBER_DOUBLE
      max_depth:
        defaultValue: 6.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      max_leaves:
        defaultValue: 0.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      max_selected_features:
        defaultValue: -1.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      min_child_weight:
        defaultValue: 1.0
        isOptional: true
        parameterType: NUMBER_DOUBLE
      monotone_constraints:
        defaultValue: ''
        isOptional: true
        parameterType: STRING
      normalize_type:
        defaultValue: tree
        isOptional: true
        parameterType: STRING
      num_boost_round:
        defaultValue: 10.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      num_parallel_tree:
        defaultValue: 1.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      objective:
        parameterType: STRING
      one_drop:
        defaultValue: 0.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      predefined_split_key:
        defaultValue: ''
        isOptional: true
        parameterType: STRING
      process_type:
        defaultValue: default
        isOptional: true
        parameterType: STRING
      project:
        parameterType: STRING
      rate_drop:
        defaultValue: 0.0
        isOptional: true
        parameterType: NUMBER_DOUBLE
      refresh_leaf:
        defaultValue: 1.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      reg_alpha:
        defaultValue: 0.0
        isOptional: true
        parameterType: NUMBER_DOUBLE
      reg_lambda:
        defaultValue: 1.0
        isOptional: true
        parameterType: NUMBER_DOUBLE
      root_dir:
        parameterType: STRING
      run_evaluation:
        defaultValue: true
        isOptional: true
        parameterType: BOOLEAN
      run_feature_selection:
        defaultValue: false
        isOptional: true
        parameterType: BOOLEAN
      sample_type:
        defaultValue: uniform
        isOptional: true
        parameterType: STRING
      sampling_method:
        defaultValue: uniform
        isOptional: true
        parameterType: STRING
      scale_pos_weight:
        defaultValue: 1.0
        isOptional: true
        parameterType: NUMBER_DOUBLE
      seed:
        defaultValue: 0.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      seed_per_iteration:
        defaultValue: false
        isOptional: true
        parameterType: BOOLEAN
      skip_drop:
        defaultValue: 0.0
        isOptional: true
        parameterType: NUMBER_DOUBLE
      stratified_split_key:
        defaultValue: ''
        isOptional: true
        parameterType: STRING
      subsample:
        defaultValue: 1.0
        isOptional: true
        parameterType: NUMBER_DOUBLE
      target_column:
        parameterType: STRING
      test_fraction:
        defaultValue: -1.0
        isOptional: true
        parameterType: NUMBER_DOUBLE
      tf_auto_transform_features:
        isOptional: true
        parameterType: STRUCT
      tf_custom_transformation_definitions:
        isOptional: true
        parameterType: LIST
      tf_transformations_path:
        defaultValue: ''
        isOptional: true
        parameterType: STRING
      top_k:
        defaultValue: 0.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      training_accelerator_count:
        defaultValue: 0.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      training_accelerator_type:
        defaultValue: ''
        isOptional: true
        parameterType: STRING
      training_fraction:
        defaultValue: -1.0
        isOptional: true
        parameterType: NUMBER_DOUBLE
      training_machine_type:
        defaultValue: c2-standard-16
        isOptional: true
        parameterType: STRING
      training_total_replica_count:
        defaultValue: 1.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      transform_dataflow_disk_size_gb:
        defaultValue: 40.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      transform_dataflow_machine_type:
        defaultValue: n1-standard-16
        isOptional: true
        parameterType: STRING
      transform_dataflow_max_num_workers:
        defaultValue: 25.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      tree_method:
        defaultValue: auto
        isOptional: true
        parameterType: STRING
      tweedie_variance_power:
        defaultValue: 1.5
        isOptional: true
        parameterType: NUMBER_DOUBLE
      updater:
        defaultValue: ''
        isOptional: true
        parameterType: STRING
      validation_fraction:
        defaultValue: -1.0
        isOptional: true
        parameterType: NUMBER_DOUBLE
      weight_column:
        defaultValue: ''
        isOptional: true
        parameterType: STRING
  outputDefinitions:
    artifacts:
      model-evaluation-evaluation_metrics:
        artifactType:
          schemaTitle: system.Metrics
          schemaVersion: 0.0.1
schemaVersion: 2.1.0
sdkVersion: kfp-2.0.0-beta.13
