name: Automl import data from gcs
inputs:
- name: dataset_path
  type: String
- name: input_uris
  type: JsonArray
- name: retry
  optional: true
- name: timeout
  optional: true
- name: metadata
  type: JsonObject
  optional: true
outputs:
- name: dataset_path
  type: String
metadata:
  annotations:
    author: Alexey Volkov <alexey.volkov@ark-kun.com>
    canonical_location: 'https://raw.githubusercontent.com/Ark-kun/pipeline_components/master/components/gcp/automl/import_data_from_gcs/component.yaml'
implementation:
  container:
    image: python:3.7
    command:
    - python3
    - -u
    - -c
    - |
      from typing import NamedTuple

      def automl_import_data_from_gcs(
          dataset_path: str,
          input_uris: list,
          retry=None, #=google.api_core.gapic_v1.method.DEFAULT,
          timeout=None, #=google.api_core.gapic_v1.method.DEFAULT,
          metadata: dict = None,
      ) -> NamedTuple('Outputs', [('dataset_path', str)]):
          import sys
          import subprocess
          subprocess.run([sys.executable, '-m', 'pip', 'install', 'google-cloud-automl==0.4.0', '--quiet', '--no-warn-script-location'], env={'PIP_DISABLE_PIP_VERSION_CHECK': '1'}, check=True)

          import google
          from google.cloud import automl
          client = automl.AutoMlClient()
          input_config = {
              'gcs_source': {
                  'input_uris': input_uris,
              },
          }
          response = client.import_data(
              dataset_path,
              input_config,
              retry or google.api_core.gapic_v1.method.DEFAULT,
              timeout or google.api_core.gapic_v1.method.DEFAULT,
              metadata,
          )
          result = response.result()
          print(result)
          metadata = response.metadata
          print(metadata)
          return (dataset_path)

      import json
      import argparse
      _missing_arg = object()
      _parser = argparse.ArgumentParser(prog='Automl import data from gcs', description='')
      _parser.add_argument("--dataset-path", dest="dataset_path", type=str, required=True, default=_missing_arg)
      _parser.add_argument("--input-uris", dest="input_uris", type=json.loads, required=True, default=_missing_arg)
      _parser.add_argument("--retry", dest="retry", type=str, required=False, default=_missing_arg)
      _parser.add_argument("--timeout", dest="timeout", type=str, required=False, default=_missing_arg)
      _parser.add_argument("--metadata", dest="metadata", type=json.loads, required=False, default=_missing_arg)
      _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=1)
      _parsed_args = {k: v for k, v in vars(_parser.parse_args()).items() if v is not _missing_arg}
      _output_files = _parsed_args.pop("_output_paths", [])

      _outputs = automl_import_data_from_gcs(**_parsed_args)

      if not hasattr(_outputs, '__getitem__') or isinstance(_outputs, str):
          _outputs = [_outputs]

      import os
      for idx, output_file in enumerate(_output_files):
          try:
              os.makedirs(os.path.dirname(output_file))
          except OSError:
              pass
          with open(output_file, 'w') as f:
              f.write(str(_outputs[idx]))
    args:
    - --dataset-path
    - inputValue: dataset_path
    - --input-uris
    - inputValue: input_uris
    - if:
        cond:
          isPresent: retry
        then:
        - --retry
        - inputValue: retry
    - if:
        cond:
          isPresent: timeout
        then:
        - --timeout
        - inputValue: timeout
    - if:
        cond:
          isPresent: metadata
        then:
        - --metadata
        - inputValue: metadata
    - '----output-paths'
    - outputPath: dataset_path
