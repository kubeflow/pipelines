apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  creationTimestamp: null
  generateName: ray-integration-test-
spec:
  arguments:
    parameters:
    - name: components-ab6362d17392d031697a1f81979e93f9a8d78c38e52c2c3a396dbf3651f72681
      value: '{"executorLabel":"exec-ray-fn","outputDefinitions":{"parameters":{"Output":{"parameterType":"NUMBER_INTEGER"}}}}'
    - name: implementations-ab6362d17392d031697a1f81979e93f9a8d78c38e52c2c3a396dbf3651f72681
      value: '{"args":["--executor_input","{{$}}","--function_to_execute","ray_fn"],"command":["sh","-c","\nif
        ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3
        -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1
        python3 -m pip install --quiet --no-warn-script-location ''codeflare-sdk==0.32.2''  \u0026\u0026  python3
        -m pip install --quiet --no-warn-script-location ''kfp==2.15.2'' ''--no-deps''
        ''typing-extensions\u003e=3.7.4,\u003c5; python_version\u003c\"3.9\"'' \u0026\u0026
        \"$0\" \"$@\"\n","sh","-ec","program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\"
        \u003e \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3
        -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n","\nimport
        kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef
        ray_fn() -\u003e int:\n    import ray  # noqa: PLC0415\n    from codeflare_sdk
        import generate_cert  # noqa: PLC0415\n    from codeflare_sdk.ray.cluster
        import Cluster, ClusterConfiguration  # noqa: PLC0415\n\n    cluster = Cluster(\n        ClusterConfiguration(\n            name=\"raytest\",\n            num_workers=1,\n            head_cpu_requests=1,\n            head_cpu_limits=1,\n            head_memory_requests=4,\n            head_memory_limits=4,\n            worker_cpu_requests=1,\n            worker_cpu_limits=1,\n            worker_memory_requests=1,\n            worker_memory_limits=2,\n            image=\"quay.io/modh/ray@sha256:6d076aeb38ab3c34a6a2ef0f58dc667089aa15826fa08a73273c629333e12f1e\",\n            verify_tls=False\n        )\n    )\n\n    #
        Clean up any existing cluster with the same name first\n    print(\"Cleaning
        up any existing cluster resources...\")\n    try:\n        cluster.down()\n        print(\"Cleaned
        up existing cluster\")\n    except Exception as e:\n        print(f\"No existing
        cluster to clean up (expected): {e}\")\n\n    # Create and start the cluster
        using current best practice\n    print(\"Creating Ray cluster...\")\n    cluster.apply()\n\n    #
        Custom wait logic since wait_ready() can hang\n    print(\"Waiting for Ray
        cluster to be ready...\")\n    import time\n    max_wait_time = 300  # 5 minutes
        timeout\n    wait_interval = 10   # Check every 10 seconds\n    elapsed_time
        = 0\n\n    cluster_ready = False\n    while elapsed_time \u003c max_wait_time:\n        try:\n            print(f\"Checking
        cluster readiness... ({elapsed_time}s elapsed)\")\n\n            # Try to
        get cluster URIs as a readiness check\n            dashboard_uri = cluster.cluster_dashboard_uri()\n            cluster_uri
        = cluster.cluster_uri()\n\n            if dashboard_uri and cluster_uri:\n                print(f\"Cluster
        is ready! Dashboard: {dashboard_uri}\")\n                print(f\"Cluster
        URI: {cluster_uri}\")\n                cluster_ready = True\n                break\n            else:\n                print(\"Cluster
        URIs not ready yet, waiting...\")\n\n        except (ConnectionError, TimeoutError,
        RuntimeError, AttributeError) as e:\n            print(f\"Cluster not ready
        yet: {e}\")\n        except Exception as e:\n            print(f\"Unexpected
        error checking cluster readiness: {e}\")\n\n        time.sleep(wait_interval)\n        elapsed_time
        += wait_interval\n\n    if not cluster_ready:\n        print(\"Cluster details
        for debugging:\")\n        print(cluster.details())\n        raise RuntimeError(f\"Ray
        cluster failed to become ready within {max_wait_time} seconds\")\n\n    print(\"Cluster
        is fully ready!\")\n\n    # Get cluster connection info\n    ray_dashboard_uri
        = cluster.cluster_dashboard_uri()\n    ray_cluster_uri = cluster.cluster_uri()\n    print(f\"Ray
        dashboard URI: {ray_dashboard_uri}\")\n    print(f\"Ray cluster URI: {ray_cluster_uri}\")\n\n    #
        Verify cluster URI is available\n    assert ray_cluster_uri, \"Ray cluster
        URI is empty - cluster may not be ready\"\n\n    # Set up TLS and connect
        to Ray cluster\n    print(\"Attempting to connect to Ray cluster...\")\n\n    #
        Try TLS setup first, fall back to direct connection if it fails\n    tls_setup_successful
        = False\n    try:\n        print(\"Setting up TLS certificates...\")\n        generate_cert.generate_tls_cert(cluster.config.name,
        cluster.config.namespace)\n        generate_cert.export_env(cluster.config.name,
        cluster.config.namespace)\n        print(\"TLS certificates configured successfully\")\n        tls_setup_successful
        = True\n    except (OSError, PermissionError, ValueError, RuntimeError) as
        e:\n        print(f\"TLS setup failed (will try direct connection): {e}\")\n        print(\"Since
        cluster was configured with verify_tls=False, attempting direct connection...\")\n    except
        Exception as e:\n        print(f\"Unexpected TLS setup error (will try direct
        connection): {e}\")\n        print(\"Since cluster was configured with verify_tls=False,
        attempting direct connection...\")\n\n    # Connect to the Ray cluster\n    try:\n        ray.init(address=ray_cluster_uri,
        logging_level=\"DEBUG\")\n        print(f\"Ray cluster connected: {ray.is_initialized()}\")\n\n        if
        not ray.is_initialized():\n            raise RuntimeError(\"Ray failed to
        initialize\")\n\n    except (ConnectionError, TimeoutError, RuntimeError,
        OSError) as e:\n        print(f\"Ray connection failed: {e}\")\n        if
        tls_setup_successful:\n            print(\"Connection failed even with TLS
        setup\")\n        else:\n            print(\"Trying alternative connection
        approaches...\")\n\n            # Alternative: Try connecting without explicit
        address (auto-discovery)\n            try:\n                ray.shutdown()  #
        Clean any previous attempts\n                print(\"Attempting Ray auto-discovery
        connection...\")\n                ray.init(logging_level=\"DEBUG\")\n                print(f\"Ray
        auto-discovery connection: {ray.is_initialized()}\")\n            except (ConnectionError,
        TimeoutError, RuntimeError, OSError) as e2:\n                print(f\"Auto-discovery
        also failed: {e2}\")\n                raise RuntimeError(f\"All Ray connection
        attempts failed. Original error: {e}\")\n            except Exception as e2:\n                print(f\"Unexpected
        auto-discovery error: {e2}\")\n                raise RuntimeError(f\"All Ray
        connection attempts failed. Original error: {e}\")\n    except Exception as
        e:\n        print(f\"Unexpected Ray connection error: {e}\")\n        raise
        RuntimeError(f\"Ray connection failed with unexpected error: {e}\")\n\n    #
        Verify cluster resources\n    print(f\"Ray cluster resources: {ray.cluster_resources()}\")\n\n    #
        Define and run remote function\n    @ray.remote\n    def train_fn():\n        return
        100\n\n    print(\"Executing remote Ray function...\")\n    result = ray.get(train_fn.remote())\n    print(f\"Ray
        function result: {result}\")\n    assert result == 100, f\"Expected 100, got
        {result}\"\n\n    # Clean shutdown\n    print(\"Shutting down Ray connection...\")\n    ray.shutdown()\n\n    print(\"Cleaning
        up Ray cluster...\")\n    cluster.down()\n    print(\"Ray cluster cleanup
        completed\")\n\n    return result\n\n"],"image":"registry.access.redhat.com/ubi9/python-311:latest"}'
    - name: components-root
      value: '{"dag":{"tasks":{"ray-fn":{"cachingOptions":{},"componentRef":{"name":"comp-ray-fn"},"taskInfo":{"name":"ray-fn"}}}}}'
  entrypoint: entrypoint
  podMetadata:
    annotations:
      pipelines.kubeflow.org/v2_component: "true"
    labels:
      pipelines.kubeflow.org/v2_component: "true"
  serviceAccountName: pipeline-runner
  templates:
  - container:
      args:
      - --type
      - CONTAINER
      - --pipeline_name
      - ray-integration-test
      - --run_id
      - '{{workflow.uid}}'
      - --run_name
      - '{{workflow.name}}'
      - --run_display_name
      - ""
      - --dag_execution_id
      - '{{inputs.parameters.parent-dag-id}}'
      - --component
      - '{{inputs.parameters.component}}'
      - --task
      - '{{inputs.parameters.task}}'
      - --task_name
      - '{{inputs.parameters.task-name}}'
      - --container
      - '{{inputs.parameters.container}}'
      - --iteration_index
      - '{{inputs.parameters.iteration-index}}'
      - --cached_decision_path
      - '{{outputs.parameters.cached-decision.path}}'
      - --pod_spec_patch_path
      - '{{outputs.parameters.pod-spec-patch.path}}'
      - --condition_path
      - '{{outputs.parameters.condition.path}}'
      - --kubernetes_config
      - '{{inputs.parameters.kubernetes-config}}'
      - --http_proxy
      - ""
      - --https_proxy
      - ""
      - --no_proxy
      - ""
      - --ml_pipeline_server_address
      - ml-pipeline.kubeflow.svc.cluster.local
      - --ml_pipeline_server_port
      - "8887"
      - --mlmd_server_address
      - metadata-grpc-service.kubeflow.svc.cluster.local
      - --mlmd_server_port
      - "8080"
      command:
      - driver
      env:
      - name: KFP_POD_NAME
        valueFrom:
          fieldRef:
            fieldPath: metadata.name
      - name: KFP_POD_UID
        valueFrom:
          fieldRef:
            fieldPath: metadata.uid
      image: ghcr.io/kubeflow/kfp-driver:latest
      name: ""
      resources:
        limits:
          cpu: 500m
          memory: 512Mi
        requests:
          cpu: 100m
          memory: 64Mi
    inputs:
      parameters:
      - name: component
      - name: task
      - name: container
      - name: task-name
      - name: parent-dag-id
      - default: "-1"
        name: iteration-index
      - default: ""
        name: kubernetes-config
    metadata: {}
    name: system-container-driver
    outputs:
      parameters:
      - name: pod-spec-patch
        valueFrom:
          default: ""
          path: /tmp/outputs/pod-spec-patch
      - default: "false"
        name: cached-decision
        valueFrom:
          default: "false"
          path: /tmp/outputs/cached-decision
      - name: condition
        valueFrom:
          default: "true"
          path: /tmp/outputs/condition
  - dag:
      tasks:
      - arguments:
          parameters:
          - name: pod-spec-patch
            value: '{{inputs.parameters.pod-spec-patch}}'
        name: executor
        template: system-container-impl
        when: '{{inputs.parameters.cached-decision}} != true'
    inputs:
      parameters:
      - name: pod-spec-patch
      - default: "false"
        name: cached-decision
    metadata: {}
    name: system-container-executor
    outputs: {}
  - container:
      command:
      - should-be-overridden-during-runtime
      env:
      - name: KFP_POD_NAME
        valueFrom:
          fieldRef:
            fieldPath: metadata.name
      - name: KFP_POD_UID
        valueFrom:
          fieldRef:
            fieldPath: metadata.uid
      envFrom:
      - configMapRef:
          name: metadata-grpc-configmap
          optional: true
      image: gcr.io/ml-pipeline/should-be-overridden-during-runtime
      name: ""
      resources: {}
      volumeMounts:
      - mountPath: /kfp-launcher
        name: kfp-launcher
      - mountPath: /gcs
        name: gcs-scratch
      - mountPath: /s3
        name: s3-scratch
      - mountPath: /minio
        name: minio-scratch
      - mountPath: /.local
        name: dot-local-scratch
      - mountPath: /.cache
        name: dot-cache-scratch
      - mountPath: /.config
        name: dot-config-scratch
    initContainers:
    - args:
      - --copy
      - /kfp-launcher/launch
      command:
      - launcher-v2
      image: ghcr.io/kubeflow/kfp-launcher:latest
      name: kfp-launcher
      resources:
        limits:
          cpu: 500m
          memory: 128Mi
        requests:
          cpu: 100m
      volumeMounts:
      - mountPath: /kfp-launcher
        name: kfp-launcher
    inputs:
      parameters:
      - name: pod-spec-patch
    metadata: {}
    name: system-container-impl
    outputs: {}
    podSpecPatch: '{{inputs.parameters.pod-spec-patch}}'
    volumes:
    - emptyDir: {}
      name: kfp-launcher
    - emptyDir: {}
      name: gcs-scratch
    - emptyDir: {}
      name: s3-scratch
    - emptyDir: {}
      name: minio-scratch
    - emptyDir: {}
      name: dot-local-scratch
    - emptyDir: {}
      name: dot-cache-scratch
    - emptyDir: {}
      name: dot-config-scratch
  - dag:
      tasks:
      - arguments:
          parameters:
          - name: component
            value: '{{workflow.parameters.components-ab6362d17392d031697a1f81979e93f9a8d78c38e52c2c3a396dbf3651f72681}}'
          - name: task
            value: '{"cachingOptions":{},"componentRef":{"name":"comp-ray-fn"},"taskInfo":{"name":"ray-fn"}}'
          - name: container
            value: '{{workflow.parameters.implementations-ab6362d17392d031697a1f81979e93f9a8d78c38e52c2c3a396dbf3651f72681}}'
          - name: task-name
            value: ray-fn
          - name: parent-dag-id
            value: '{{inputs.parameters.parent-dag-id}}'
        name: ray-fn-driver
        template: system-container-driver
      - arguments:
          parameters:
          - name: pod-spec-patch
            value: '{{tasks.ray-fn-driver.outputs.parameters.pod-spec-patch}}'
          - default: "false"
            name: cached-decision
            value: '{{tasks.ray-fn-driver.outputs.parameters.cached-decision}}'
        depends: ray-fn-driver.Succeeded
        name: ray-fn
        template: system-container-executor
    inputs:
      parameters:
      - name: parent-dag-id
    metadata: {}
    name: root
    outputs: {}
  - container:
      args:
      - --type
      - '{{inputs.parameters.driver-type}}'
      - --pipeline_name
      - ray-integration-test
      - --run_id
      - '{{workflow.uid}}'
      - --run_name
      - '{{workflow.name}}'
      - --run_display_name
      - ""
      - --dag_execution_id
      - '{{inputs.parameters.parent-dag-id}}'
      - --component
      - '{{inputs.parameters.component}}'
      - --task
      - '{{inputs.parameters.task}}'
      - --task_name
      - '{{inputs.parameters.task-name}}'
      - --runtime_config
      - '{{inputs.parameters.runtime-config}}'
      - --iteration_index
      - '{{inputs.parameters.iteration-index}}'
      - --execution_id_path
      - '{{outputs.parameters.execution-id.path}}'
      - --iteration_count_path
      - '{{outputs.parameters.iteration-count.path}}'
      - --condition_path
      - '{{outputs.parameters.condition.path}}'
      - --http_proxy
      - ""
      - --https_proxy
      - ""
      - --no_proxy
      - ""
      - --ml_pipeline_server_address
      - ml-pipeline.kubeflow.svc.cluster.local
      - --ml_pipeline_server_port
      - "8887"
      - --mlmd_server_address
      - metadata-grpc-service.kubeflow.svc.cluster.local
      - --mlmd_server_port
      - "8080"
      command:
      - driver
      image: ghcr.io/kubeflow/kfp-driver:latest
      name: ""
      resources:
        limits:
          cpu: 500m
          memory: 512Mi
        requests:
          cpu: 100m
          memory: 64Mi
    inputs:
      parameters:
      - name: component
      - default: ""
        name: runtime-config
      - default: ""
        name: task
      - default: ""
        name: task-name
      - default: "0"
        name: parent-dag-id
      - default: "-1"
        name: iteration-index
      - default: DAG
        name: driver-type
    metadata: {}
    name: system-dag-driver
    outputs:
      parameters:
      - name: execution-id
        valueFrom:
          path: /tmp/outputs/execution-id
      - name: iteration-count
        valueFrom:
          default: "0"
          path: /tmp/outputs/iteration-count
      - name: condition
        valueFrom:
          default: "true"
          path: /tmp/outputs/condition
  - dag:
      tasks:
      - arguments:
          parameters:
          - name: component
            value: '{{workflow.parameters.components-root}}'
          - name: runtime-config
            value: '{}'
          - name: driver-type
            value: ROOT_DAG
        name: root-driver
        template: system-dag-driver
      - arguments:
          parameters:
          - name: parent-dag-id
            value: '{{tasks.root-driver.outputs.parameters.execution-id}}'
          - name: condition
            value: ""
        depends: root-driver.Succeeded
        name: root
        template: root
    inputs: {}
    metadata: {}
    name: entrypoint
    outputs: {}
status:
  finishedAt: null
  startedAt: null
