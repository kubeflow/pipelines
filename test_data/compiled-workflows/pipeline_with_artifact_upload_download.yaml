apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  creationTimestamp: null
  generateName: pipeline-with-datasets-
spec:
  arguments:
    parameters:
    - name: components-05e0c7c24c705bcaac86e732ffd5d85e67d9a184ae4703d789ccfe1715a452f2
      value: '{"executorLabel":"exec-download-dataset-and-upload-as-artifact","inputDefinitions":{"parameters":{"dataset_name":{"parameterType":"STRING"},"dataset_repo":{"parameterType":"STRING"}}},"outputDefinitions":{"artifacts":{"output_dataset":{"artifactType":{"schemaTitle":"system.Dataset","schemaVersion":"0.0.1"}}}}}'
    - name: implementations-05e0c7c24c705bcaac86e732ffd5d85e67d9a184ae4703d789ccfe1715a452f2
      value: '{"args":["--executor_input","{{$}}","--function_to_execute","download_dataset_and_upload_as_artifact"],"command":["sh","-c","\nif
        ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3
        -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1
        python3 -m pip install --quiet --no-warn-script-location ''datasets==4.0.0''  \u0026\u0026  python3
        -m pip install --quiet --no-warn-script-location ''kfp==2.14.3'' ''--no-deps''
        ''typing-extensions\u003e=3.7.4,\u003c5; python_version\u003c\"3.9\"'' \u0026\u0026
        \"$0\" \"$@\"\n","sh","-ec","program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\"
        \u003e \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3
        -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n","\nimport
        kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef
        download_dataset_and_upload_as_artifact(dataset_repo: str, dataset_name: str,
        output_dataset: Output[Dataset]):\n    from datasets import load_dataset\n    #
        Load data set from hugging face\n    ds = load_dataset(dataset_repo, dataset_name)\n    print(\"Downloaded
        Hugging Face data\")\n    print(f\"Now saving to {output_dataset.path}\")\n    ds.save_to_disk(output_dataset.path)\n    print(f\"Saved
        to {output_dataset.path}\")\n\n"],"image":"python:3.9"}'
    - name: components-d0f4b4d95b964a5d78a841aa20e3d529d81189e4c90f9b39a31332bb8c8d437c
      value: '{"executorLabel":"exec-print-dataset-info","inputDefinitions":{"artifacts":{"dataset":{"artifactType":{"schemaTitle":"system.Dataset","schemaVersion":"0.0.1"}}}}}'
    - name: implementations-d0f4b4d95b964a5d78a841aa20e3d529d81189e4c90f9b39a31332bb8c8d437c
      value: '{"args":["--executor_input","{{$}}","--function_to_execute","print_dataset_info"],"command":["sh","-c","\nif
        ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3
        -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1
        python3 -m pip install --quiet --no-warn-script-location ''kfp==2.14.3'' ''--no-deps''
        ''typing-extensions\u003e=3.7.4,\u003c5; python_version\u003c\"3.9\"'' \u0026\u0026
        \"$0\" \"$@\"\n","sh","-ec","program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\"
        \u003e \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3
        -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n","\nimport
        kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef
        print_dataset_info(dataset: Dataset):\n    print(''Information about the artifact'')\n    print(''Name:'',
        dataset.name)\n    print(''URI:'', dataset.uri)\n    assert \"download-dataset-and-upload-as-artifact\"
        in dataset.uri, \"The URI of the downloaded artifact does not match the expected
        function''s name that generated it\"\n\n"],"image":"python:3.9"}'
    - name: components-root
      value: '{"dag":{"tasks":{"download-dataset-and-upload-as-artifact":{"cachingOptions":{"enableCache":true},"componentRef":{"name":"comp-download-dataset-and-upload-as-artifact"},"inputs":{"parameters":{"dataset_name":{"componentInputParameter":"dataset_name"},"dataset_repo":{"componentInputParameter":"dataset_repo"}}},"taskInfo":{"name":"download-dataset-and-upload-as-artifact"}},"print-dataset-info":{"cachingOptions":{"enableCache":true},"componentRef":{"name":"comp-print-dataset-info"},"dependentTasks":["download-dataset-and-upload-as-artifact"],"inputs":{"artifacts":{"dataset":{"taskOutputArtifact":{"outputArtifactKey":"output_dataset","producerTask":"download-dataset-and-upload-as-artifact"}}}},"taskInfo":{"name":"print-dataset-info"}}}},"inputDefinitions":{"parameters":{"dataset_name":{"defaultValue":"","isOptional":true,"parameterType":"STRING"},"dataset_repo":{"defaultValue":"google/frames-benchmark","isOptional":true,"parameterType":"STRING"}}}}'
  entrypoint: entrypoint
  podMetadata:
    annotations:
      pipelines.kubeflow.org/v2_component: "true"
    labels:
      pipelines.kubeflow.org/v2_component: "true"
  serviceAccountName: pipeline-runner
  templates:
  - container:
      args:
      - --type
      - CONTAINER
      - --pipeline_name
      - pipeline-with-datasets
      - --run_id
      - '{{workflow.uid}}'
      - --run_name
      - '{{workflow.name}}'
      - --run_display_name
      - ""
      - --dag_execution_id
      - '{{inputs.parameters.parent-dag-id}}'
      - --component
      - '{{inputs.parameters.component}}'
      - --task
      - '{{inputs.parameters.task}}'
      - --task_name
      - '{{inputs.parameters.task-name}}'
      - --container
      - '{{inputs.parameters.container}}'
      - --iteration_index
      - '{{inputs.parameters.iteration-index}}'
      - --cached_decision_path
      - '{{outputs.parameters.cached-decision.path}}'
      - --pod_spec_patch_path
      - '{{outputs.parameters.pod-spec-patch.path}}'
      - --condition_path
      - '{{outputs.parameters.condition.path}}'
      - --kubernetes_config
      - '{{inputs.parameters.kubernetes-config}}'
      - --http_proxy
      - ""
      - --https_proxy
      - ""
      - --no_proxy
      - ""
      command:
      - driver
      image: ghcr.io/kubeflow/kfp-driver:latest
      name: ""
      resources:
        limits:
          cpu: 500m
          memory: 512Mi
        requests:
          cpu: 100m
          memory: 64Mi
    inputs:
      parameters:
      - name: component
      - name: task
      - name: container
      - name: task-name
      - name: parent-dag-id
      - default: "-1"
        name: iteration-index
      - default: ""
        name: kubernetes-config
    metadata: {}
    name: system-container-driver
    outputs:
      parameters:
      - name: pod-spec-patch
        valueFrom:
          default: ""
          path: /tmp/outputs/pod-spec-patch
      - default: "false"
        name: cached-decision
        valueFrom:
          default: "false"
          path: /tmp/outputs/cached-decision
      - name: condition
        valueFrom:
          default: "true"
          path: /tmp/outputs/condition
  - dag:
      tasks:
      - arguments:
          parameters:
          - name: pod-spec-patch
            value: '{{inputs.parameters.pod-spec-patch}}'
        name: executor
        template: system-container-impl
        when: '{{inputs.parameters.cached-decision}} != true'
    inputs:
      parameters:
      - name: pod-spec-patch
      - default: "false"
        name: cached-decision
    metadata: {}
    name: system-container-executor
    outputs: {}
  - container:
      command:
      - should-be-overridden-during-runtime
      env:
      - name: KFP_POD_NAME
        valueFrom:
          fieldRef:
            fieldPath: metadata.name
      - name: KFP_POD_UID
        valueFrom:
          fieldRef:
            fieldPath: metadata.uid
      envFrom:
      - configMapRef:
          name: metadata-grpc-configmap
          optional: true
      image: gcr.io/ml-pipeline/should-be-overridden-during-runtime
      name: ""
      resources: {}
      volumeMounts:
      - mountPath: /kfp-launcher
        name: kfp-launcher
      - mountPath: /gcs
        name: gcs-scratch
      - mountPath: /s3
        name: s3-scratch
      - mountPath: /minio
        name: minio-scratch
      - mountPath: /.local
        name: dot-local-scratch
      - mountPath: /.cache
        name: dot-cache-scratch
      - mountPath: /.config
        name: dot-config-scratch
    initContainers:
    - args:
      - --copy
      - /kfp-launcher/launch
      command:
      - launcher-v2
      image: ghcr.io/kubeflow/kfp-launcher:latest
      name: kfp-launcher
      resources:
        limits:
          cpu: 500m
          memory: 128Mi
        requests:
          cpu: 100m
      volumeMounts:
      - mountPath: /kfp-launcher
        name: kfp-launcher
    inputs:
      parameters:
      - name: pod-spec-patch
    metadata: {}
    name: system-container-impl
    outputs: {}
    podSpecPatch: '{{inputs.parameters.pod-spec-patch}}'
    volumes:
    - emptyDir: {}
      name: kfp-launcher
    - emptyDir: {}
      name: gcs-scratch
    - emptyDir: {}
      name: s3-scratch
    - emptyDir: {}
      name: minio-scratch
    - emptyDir: {}
      name: dot-local-scratch
    - emptyDir: {}
      name: dot-cache-scratch
    - emptyDir: {}
      name: dot-config-scratch
  - dag:
      tasks:
      - arguments:
          parameters:
          - name: component
            value: '{{workflow.parameters.components-05e0c7c24c705bcaac86e732ffd5d85e67d9a184ae4703d789ccfe1715a452f2}}'
          - name: task
            value: '{"cachingOptions":{"enableCache":true},"componentRef":{"name":"comp-download-dataset-and-upload-as-artifact"},"inputs":{"parameters":{"dataset_name":{"componentInputParameter":"dataset_name"},"dataset_repo":{"componentInputParameter":"dataset_repo"}}},"taskInfo":{"name":"download-dataset-and-upload-as-artifact"}}'
          - name: container
            value: '{{workflow.parameters.implementations-05e0c7c24c705bcaac86e732ffd5d85e67d9a184ae4703d789ccfe1715a452f2}}'
          - name: task-name
            value: download-dataset-and-upload-as-artifact
          - name: parent-dag-id
            value: '{{inputs.parameters.parent-dag-id}}'
        name: download-dataset-and-upload-as-artifact-driver
        template: system-container-driver
      - arguments:
          parameters:
          - name: pod-spec-patch
            value: '{{tasks.download-dataset-and-upload-as-artifact-driver.outputs.parameters.pod-spec-patch}}'
          - default: "false"
            name: cached-decision
            value: '{{tasks.download-dataset-and-upload-as-artifact-driver.outputs.parameters.cached-decision}}'
        depends: download-dataset-and-upload-as-artifact-driver.Succeeded
        name: download-dataset-and-upload-as-artifact
        template: system-container-executor
      - arguments:
          parameters:
          - name: component
            value: '{{workflow.parameters.components-d0f4b4d95b964a5d78a841aa20e3d529d81189e4c90f9b39a31332bb8c8d437c}}'
          - name: task
            value: '{"cachingOptions":{"enableCache":true},"componentRef":{"name":"comp-print-dataset-info"},"dependentTasks":["download-dataset-and-upload-as-artifact"],"inputs":{"artifacts":{"dataset":{"taskOutputArtifact":{"outputArtifactKey":"output_dataset","producerTask":"download-dataset-and-upload-as-artifact"}}}},"taskInfo":{"name":"print-dataset-info"}}'
          - name: container
            value: '{{workflow.parameters.implementations-d0f4b4d95b964a5d78a841aa20e3d529d81189e4c90f9b39a31332bb8c8d437c}}'
          - name: task-name
            value: print-dataset-info
          - name: parent-dag-id
            value: '{{inputs.parameters.parent-dag-id}}'
        depends: download-dataset-and-upload-as-artifact.Succeeded
        name: print-dataset-info-driver
        template: system-container-driver
      - arguments:
          parameters:
          - name: pod-spec-patch
            value: '{{tasks.print-dataset-info-driver.outputs.parameters.pod-spec-patch}}'
          - default: "false"
            name: cached-decision
            value: '{{tasks.print-dataset-info-driver.outputs.parameters.cached-decision}}'
        depends: print-dataset-info-driver.Succeeded
        name: print-dataset-info
        template: system-container-executor
    inputs:
      parameters:
      - name: parent-dag-id
    metadata: {}
    name: root
    outputs: {}
  - container:
      args:
      - --type
      - '{{inputs.parameters.driver-type}}'
      - --pipeline_name
      - pipeline-with-datasets
      - --run_id
      - '{{workflow.uid}}'
      - --run_name
      - '{{workflow.name}}'
      - --run_display_name
      - ""
      - --dag_execution_id
      - '{{inputs.parameters.parent-dag-id}}'
      - --component
      - '{{inputs.parameters.component}}'
      - --task
      - '{{inputs.parameters.task}}'
      - --task_name
      - '{{inputs.parameters.task-name}}'
      - --runtime_config
      - '{{inputs.parameters.runtime-config}}'
      - --iteration_index
      - '{{inputs.parameters.iteration-index}}'
      - --execution_id_path
      - '{{outputs.parameters.execution-id.path}}'
      - --iteration_count_path
      - '{{outputs.parameters.iteration-count.path}}'
      - --condition_path
      - '{{outputs.parameters.condition.path}}'
      - --http_proxy
      - ""
      - --https_proxy
      - ""
      - --no_proxy
      - ""
      command:
      - driver
      image: ghcr.io/kubeflow/kfp-driver:latest
      name: ""
      resources:
        limits:
          cpu: 500m
          memory: 512Mi
        requests:
          cpu: 100m
          memory: 64Mi
    inputs:
      parameters:
      - name: component
      - default: ""
        name: runtime-config
      - default: ""
        name: task
      - default: ""
        name: task-name
      - default: "0"
        name: parent-dag-id
      - default: "-1"
        name: iteration-index
      - default: DAG
        name: driver-type
    metadata: {}
    name: system-dag-driver
    outputs:
      parameters:
      - name: execution-id
        valueFrom:
          path: /tmp/outputs/execution-id
      - name: iteration-count
        valueFrom:
          default: "0"
          path: /tmp/outputs/iteration-count
      - name: condition
        valueFrom:
          default: "true"
          path: /tmp/outputs/condition
  - dag:
      tasks:
      - arguments:
          parameters:
          - name: component
            value: '{{workflow.parameters.components-root}}'
          - name: runtime-config
            value: '{"parameterValues":{"dataset_name":"","dataset_repo":"google/frames-benchmark"}}'
          - name: driver-type
            value: ROOT_DAG
        name: root-driver
        template: system-dag-driver
      - arguments:
          parameters:
          - name: parent-dag-id
            value: '{{tasks.root-driver.outputs.parameters.execution-id}}'
          - name: condition
            value: ""
        depends: root-driver.Succeeded
        name: root
        template: root
    inputs: {}
    metadata: {}
    name: entrypoint
    outputs: {}
status:
  finishedAt: null
  startedAt: null
