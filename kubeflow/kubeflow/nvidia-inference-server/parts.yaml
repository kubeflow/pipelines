{
   "name": "nvidia-inference-server",
   "apiVersion": "0.0.1",
   "kind": "ksonnet.io/parts",
   "description": "NVIDIA Inference Server.\n",
   "author": "NVIDIA",
   "contributors": [
      {
         "name": "David Goodwin",
         "email": "davidg@nvidia.com"
      }
   ],
   "repository": {
      "type": "git",
      "url": "https://github.com/kubeflow/kubeflow"
   },
   "bugs": {
      "url": "https://github.com/kubeflow/kubeflow/issues"
   },
   "keywords": [
      "kubeflow",
      "inference",
      "gpu",
      "tensorrt",
      "tensorflow",
      "caffe2"
   ],
   "quickStart": {
      "prototype": "io.ksonnet.pkg.nvidia-inference-server",
      "componentName": "nvidia-inference-server",
      "flags": {
         "name": "nvidia-inference-server",
         "namespace": "default"
      },
      "comment": "NVIDIA Inference Server"
   },
   "license": "Apache 2.0"
}
